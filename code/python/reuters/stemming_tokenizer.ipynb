{
 "metadata": {
  "name": "",
  "signature": "sha256:bf8620b2bfb9405105265e230321507129b215e3fcb7423e8ccb96fbf03061d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tokenizer with Stemmer"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "A tokenizer that stem tokenized documents text using nltk porter stemmer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# alphanumeric tokenizer\n",
      "from nltk.stem import PorterStemmer\n",
      "from nltk import RegexpTokenizer\n",
      "class RawStemmingTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.stemmer = PorterStemmer()\n",
      "        self.tokenizer = RegexpTokenizer(u'(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
      "    def __call__(self, doc):\n",
      "        return [self.stemmer.stem(tokens.lower()) for tokens in self.tokenizer.tokenize(doc)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# alphabetic tokenizer\n",
      "from nltk.stem import PorterStemmer\n",
      "from nltk import RegexpTokenizer\n",
      "class StemmingTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.stemmer = PorterStemmer()\n",
      "        self.tokenizer = RegexpTokenizer(u'(?u)\\\\b[a-z]+\\\\-*[a-z]+|\\\\b(?u)\\\\b[a-z]\\\\b')\n",
      "    def __call__(self, doc):\n",
      "        return [self.stemmer.stem(tokens.lower()) for tokens in self.tokenizer.tokenize(doc)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}