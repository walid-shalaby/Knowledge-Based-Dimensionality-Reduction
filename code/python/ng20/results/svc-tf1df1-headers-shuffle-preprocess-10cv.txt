IPython Notebookng20_classifier-cv Last Checkpoint: Dec 24 16:50 (autosaved)
File
Edit
View
Insert
Cell
Kernel
Help
 Cell Toolbar:
Classify 20ng docs
Classifiy 20ng docs using unigrams and bigrams features with different classifiers and report classification results
In [424]:

def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = CountVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    # generate tfidf vectors
    transformer = TfidfTransformer()
    corpus_tfidf_vectors = transformer.fit_transform(corpus_vectors)
 
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-424-743655218ee8>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
In [425]:

def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import TfidfVectorizer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = TfidfVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_tfidf_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-425-f88374f887f0>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
In [426]:

# given classifier predictions probabilities, return predictions with top n probabilities > 0.5 for each instance or greatest one if all are <=0.5
def get_max_n_pred(pred_proba, n_pred, threshold):
    import heapq
    import numpy
    max_n_pred = numpy.ndarray(shape=pred_proba.shape)
    for i in range(len(pred_proba)):
        largest_n_proba = heapq.nlargest(n_pred,pred_proba[i])
        max_n_pred[i] = numpy.array(((pred_proba[i]>threshold) & (pred_proba[i]>=largest_n_proba[len(largest_n_proba)-1]) & 1))
        if max_n_pred[i].sum(axis=0)==0: # at least one label should be returned
            max_n_pred[i] = numpy.array(((pred_proba[i]>=max(pred_proba[i])) & 1))
    return max_n_pred
In [427]:

# reference: http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification
def classify(x_train,y_train,x_test,y_test,max_labels):
    from sklearn.preprocessing import MultiLabelBinarizer
    from sklearn.multiclass import OneVsRestClassifier
    from sklearn.svm import SVC
    from sklearn.svm import LinearSVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.preprocessing import binarize
    from sklearn.cross_validation import train_test_split
    from sklearn import metrics
    import numpy
    from numpy import mean
    import scipy
    from sklearn.cross_validation import cross_val_score
    from sklearn.metrics import make_scorer
    from sklearn.metrics import precision_score
    from sklearn.metrics import recall_score
    from sklearn.metrics import f1_score
    
    # combine train and test vectors
    #print 'merging training and testing samples x({0}),x({1})'.format(x_train.shape,x_test.shape)
    #print 'merging training and testing samples y({0}),y({1})'.format(len(y_train),len(y_test))
    x = scipy.sparse.vstack((x_train,x_test))
    y = y_train + y_test
    #print 'merged into x({0})'.format(x.shape)
    #print 'merged into y({0})'.format(len(y))
    # binarize the labels
    #mlb = MultiLabelBinarizer()
    #y_train_binarized = mlb.fit_transform(y_train)
    
    # train/test split
    #corpus_tfidf_vectors, labels_binarized = shuffle(corpus_tfidf_vectors, labels_binarized)
    #x_train, x_test, y_train, y_test = train_test_split(corpus_tfidf_vectors, labels_binarized, test_size=test_size, random_state=1)
    
    # classify
    #cls = OneVsRestClassifier(LogisticRegression(class_weight='auto'))
    #cls = OneVsRestClassifier(LogisticRegression())
    #cls = MultinomialNB(alpha=0.01)
    #cls = OneVsRestClassifier(BernoulliNB()need binarize(x_train and x_test))
    #cls = OneVsRestClassifier(SVC(kernel='linear',probability=True,max_iter=1000))
    cls = LinearSVC()
    acc_scores = cross_val_score(cls,x,y,scoring='accuracy',cv=10,n_jobs=-1)
    print 'accuracy scores = {0},{1}'.format(acc_scores,mean(acc_scores))
    macro_p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro precision scores = {0},{1}'.format(macro_p_scores,mean(macro_p_scores))
    macro_r_scores = cross_val_score(cls,x,y,scoring=make_scorer(recall_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro recall scores = {0},{1}'.format(macro_r_scores,mean(macro_r_scores))
    macro_f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro f1 scores = {0},{1}'.format(macro_f1_scores,mean(macro_f1_scores))
    p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average precision scores = {0},{1}'.format(p_scores,mean(p_scores))
    r_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average recall scores = {0},{1}'.format(r_scores,mean(r_scores))
    f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted f1 scores = {0},{1}'.format(f1_scores,mean(f1_scores))
   
    return {'precision':mean(macro_p_scores),
            'recall':mean(macro_r_scores),
            'f1':mean(macro_f1_scores)}
In [428]:

import sklearn
from sklearn.svm import LinearSVC
c = LinearSVC()
print sklearn.__version__
0.15.2
In [429]:

def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_unigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-429-5bcc0f6a848c>:1: SyntaxWarning: import * only allowed at module level
  def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [430]:

def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-430-094e349cf724>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [431]:

def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_bigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-431-c28207c92f80>:1: SyntaxWarning: import * only allowed at module level
  def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [432]:

def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-432-781cd4f52dc5>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [433]:

def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    from sklearn.decomposition import TruncatedSVD
    from scipy import sparse
    import numpy
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # apply LSA
    #print numpy.max(corpus_train_tfidf_vectors)
    #print numpy.min(corpus_train_tfidf_vectors)
    lsa = TruncatedSVD(n_components=num_components)
    lsa.fit(corpus_train_tfidf_vectors)
    #corpus_train_tfidf_vectors = numpy.dot(corpus_train_tfidf_vectors,pca.components_.transpose())
    corpus_train_tfidf_vectors = lsa.transform(corpus_train_tfidf_vectors)
    corpus_test_tfidf_vectors = lsa.transform(corpus_test_tfidf_vectors)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print 'LSA ^' , vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-433-0ae0e12f66cc>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
In [434]:

def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)    
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-434-d27651528d70>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [435]:

def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-435-8129eac551f8>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [436]:

def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-436-180bdc332cbe>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [437]:

def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-437-cd1ea993b277>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [438]:

def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-438-98c5bdcd6b4f>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [439]:

def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-439-1c5602c28486>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [440]:

def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-440-c5ecc72d6e7c>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [441]:

def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-441-60ce875247ce>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [442]:

def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-442-2010f39a430e>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [443]:

def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-443-a08ffa055f62>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [444]:

def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-444-781d3020ecf2>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [445]:

def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-445-69e08236a4c4>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [446]:

def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-446-bdd713c1f2ac>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [447]:

def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-447-6b79430f2923>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [448]:

def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'stem')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-448-a650503cc609>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [449]:

def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-449-3444b80fb7e1>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [450]:

def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-450-dd4a635e1842>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [451]:

def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-451-ce43e0732809>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [452]:

def test():
    from ng20_corpus_loader import load_corpus_and_labels
    from ng20_corpus_loader import load_corpus_with_labels_mappings
    
    # load 20ng docs with class lables from DB
    corpus_train_data = load_corpus_and_labels('train')
    print 'done loading {0} train records and {1} labels.'.format(len(corpus_train_data['corpus']),len(corpus_train_data['labels_dic']))
 
    corpus_test_data = load_corpus_with_labels_mappings('test',corpus_train_data['labels_dic'])
    print 'done loading {0} test records.'.format(len(corpus_test_data['corpus']))
    
    stopwords_removal_mask = 1
    chi_features_mask = 2
    raw_tokens_mask = 4
    for i in range(4,6): # test w/o stopword removal and w/o chi square features and w/o raw tokens
        stopwords_removal = i&stopwords_removal_mask==stopwords_removal_mask
        use_chi_features = i&chi_features_mask==chi_features_mask
        use_raw_tokens = i&raw_tokens_mask==raw_tokens_mask
        
        test_all_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        #test_lemmatized_bigrams_with_LSA({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
        #                         {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
        #                         stopwords_removal,use_chi_features,use_raw_tokens,113240)
        
        test_lemmatized_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
In [453]:

# test using all vocabulary
test()
 
print 'done!'
loaded 11314 records.
done loading 11314 train records and 20 labels.
loaded 7532 records.
done loading 7532 test records.
loaded (122770) terms
vectorizing done, 122770 terms vocabulary tokenized
vectorizing done, 122770 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.90322581  0.93386243  0.93326271  0.92311771  0.91768455
  0.934644    0.90851064  0.91054313  0.89445629],0.914144256912
macro precision scores = [ 0.87991894  0.90622594  0.93572939  0.93409757  0.92428505  0.91729061
  0.93539126  0.90823242  0.91026098  0.89532265],0.914675481894
macro recall scores = [ 0.87607489  0.90017201  0.93136264  0.93269184  0.9208604   0.91562879
  0.93307654  0.90430549  0.90804198  0.89128483],0.911349941046
macro f1 scores = [ 0.87665651  0.90175906  0.93270425  0.93309043  0.92155299  0.91569928
  0.93394954  0.90525316  0.90871824  0.89214618],0.912152965401
weighted average precision scores = [ 0.88154895  0.90539326  0.93463634  0.93430136  0.92344343  0.91835609
  0.93507345  0.90904224  0.91141808  0.89728719],0.915050038647
weighted average recall scores = [ 0.88154895  0.90539326  0.93463634  0.93430136  0.92344343  0.91835609
  0.93507345  0.90904224  0.91141808  0.89728719],0.915050038647
weighted f1 scores = [ 0.88073692  0.90315455  0.93352736  0.93348321  0.92243496  0.9172917
  0.93460876  0.90795595  0.91055968  0.89471867],0.913847176702
ng20_raw_unigrams  -->  precision  0.914675481894 recall  0.911349941046 f1  0.912152965401
loaded (1469366) terms
vectorizing done, 1469366 terms vocabulary tokenized
vectorizing done, 1469366 terms vocabulary tokenized
accuracy scores = [ 0.89006342  0.91115812  0.93915344  0.93961864  0.92735949  0.92511949
  0.93942614  0.91861702  0.91853035  0.89925373],0.920829985319
macro precision scores = [ 0.89076261  0.91440611  0.94149267  0.94052292  0.92926437  0.9247248
  0.94028693  0.91858644  0.92013597  0.90042582],0.922060864472
macro recall scores = [ 0.88198     0.90772555  0.9374363   0.93879047  0.92598407  0.92296209
  0.93729947  0.91458301  0.91629147  0.8963311 ],0.917938353909
macro f1 scores = [ 0.88278036  0.90941097  0.93883376  0.93939545  0.92687882  0.92316848
  0.93827926  0.9157371   0.91752574  0.89718231],0.918919223352
weighted average precision scores = [ 0.89131795  0.91346499  0.93989145  0.94025867  0.92862351  0.92615361
  0.94019757  0.91954497  0.91997596  0.90216634],0.922159502329
weighted average recall scores = [ 0.89131795  0.91346499  0.93989145  0.94025867  0.92862351  0.92615361
  0.94019757  0.91954497  0.91997596  0.90216634],0.922159502329
weighted f1 scores = [ 0.88795323  0.91102504  0.93897632  0.93968213  0.92731233  0.92497912
  0.93934193  0.91834081  0.9186141   0.89957183],0.920579685391
ng20_raw_bigrams  -->  precision  0.922060864472 recall  0.917938353909 f1  0.918919223352
loaded (115473) terms
vectorizing done, 115473 terms vocabulary tokenized
vectorizing done, 115473 terms vocabulary tokenized
accuracy scores = [ 0.87473573  0.89899524  0.93544974  0.93220339  0.92417815  0.91821561
  0.9325186   0.90691489  0.91054313  0.89445629],0.912821077531
macro precision scores = [ 0.87161535  0.90262873  0.93679099  0.93274967  0.92566087  0.91660631
  0.93328371  0.90672706  0.91079907  0.89448765],0.913134941004
macro recall scores = [ 0.86698895  0.89604551  0.93384261  0.93137579  0.92246404  0.9158541
  0.93031531  0.90208924  0.9076298   0.89146691],0.909807224792
macro f1 scores = [ 0.86747721  0.89773678  0.93475369  0.93177281  0.92309746  0.91549724
  0.93127364  0.90310923  0.90851032  0.89217467],0.910540303901
weighted average precision scores = [ 0.8741869   0.9015627   0.93595253  0.93294149  0.92464485  0.91907189
  0.93323683  0.90789863  0.91210256  0.89660086],0.913819922171
weighted average recall scores = [ 0.8741869   0.9015627   0.93595253  0.93294149  0.92464485  0.91907189
  0.93323683  0.90789863  0.91210256  0.89660086],0.913819922171
weighted f1 scores = [ 0.87299609  0.89900885  0.93518542  0.9322774   0.92355684  0.91795875
  0.93241257  0.90632915  0.91065604  0.89471629],0.912509740659
ng20_raw_lemmas_unigrams_df1_tf1  -->  precision  0.913134941004 recall  0.909807224792 f1  0.910540303901
loaded (1397637) terms
vectorizing done, 1397637 terms vocabulary tokenized
vectorizing done, 1397637 terms vocabulary tokenized
accuracy scores = [ 0.88477801  0.90904283  0.94021164  0.93961864  0.93107105  0.92405736
  0.94261424  0.91489362  0.91693291  0.90191898],0.920513927765
macro precision scores = [ 0.88168587  0.91189738  0.9424348   0.94098734  0.93259918  0.92444914
  0.94303233  0.91544367  0.91843121  0.90250006],0.92134609724
macro recall scores = [ 0.87569222  0.90564162  0.9384577   0.93895396  0.92955165  0.92162885
  0.94021661  0.91062093  0.9146583   0.89930603],0.917472788503
macro f1 scores = [ 0.87540138  0.90703651  0.93982489  0.93966746  0.93044814  0.92215366
  0.94120276  0.91196609  0.91581706  0.89970456],0.918322251271
weighted average precision scores = [ 0.88446672  0.91143273  0.94075219  0.94052808  0.93204528  0.92588654
  0.94310118  0.91610561  0.91823692  0.90475747],0.921731272551
weighted average recall scores = [ 0.88446672  0.91143273  0.94075219  0.94052808  0.93204528  0.92588654
  0.94310118  0.91610561  0.91823692  0.90475747],0.921731272551
weighted f1 scores = [ 0.88200027  0.90883876  0.93994396  0.93977715  0.93100272  0.92409443
  0.94248733  0.91459304  0.91692212  0.90219264],0.920185241238
ng20_raw_lemmas_bigrams_df1_tf1  -->  precision  0.92134609724 recall  0.917472788503 f1  0.918322251271
loaded (168948) terms
done loading vocabulary
vectorizing done, 168948 terms vocabulary tokenized
vectorizing done, 168948 terms vocabulary tokenized
accuracy scores = [ 0.88530655  0.91168694  0.93597884  0.93379237  0.92417815  0.91821561
  0.93411265  0.9106383   0.91373802  0.89712154],0.916476896745
macro precision scores = [ 0.88376288  0.91517235  0.93716147  0.93484035  0.92521793  0.91636794
  0.93452903  0.91130177  0.91450526  0.89763309],0.917049206498
macro recall scores = [ 0.87810804  0.9079306   0.93407409  0.93274787  0.92244072  0.9159037
  0.93186719  0.90651946  0.91148612  0.89462636],0.913570414703
macro f1 scores = [ 0.87876254  0.90963611  0.93504723  0.93348444  0.92310384  0.91545926
  0.93275725  0.90770273  0.91231596  0.89525976],0.914352912594
weighted average precision scores = [ 0.88524847  0.91447209  0.93662028  0.93489655  0.92452591  0.91940041
  0.93455396  0.91174507  0.91489186  0.89973152],0.91760861009
weighted average recall scores = [ 0.88524847  0.91447209  0.93662028  0.93489655  0.92452591  0.91940041
  0.93455396  0.91174507  0.91489186  0.89973152],0.91760861009
weighted f1 scores = [ 0.88355468  0.91154329  0.9357648   0.93403898  0.92371724  0.91815659
  0.93395388  0.91022517  0.91368736  0.89753237],0.916217435484
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.917049206498 recall  0.913570414703 f1  0.914352912594
loaded (53475) terms
extended to (71921) terms
done loading vocabulary
vectorizing done, 71921 terms vocabulary tokenized
vectorizing done, 71921 terms vocabulary tokenized
accuracy scores = [ 0.85623679  0.89212057  0.91640212  0.91684322  0.90827147  0.91502921
  0.92242295  0.89042553  0.89669862  0.87100213],0.898545261103
macro precision scores = [ 0.85398886  0.89494285  0.91796993  0.91707795  0.90794882  0.91555252
  0.923253    0.89147763  0.89606133  0.86979387],0.898806675854
macro recall scores = [ 0.8492971   0.88915039  0.91352226  0.91544     0.9055377   0.91324316
  0.91933316  0.88482545  0.89425523  0.86702578],0.895163022072
macro f1 scores = [ 0.84916054  0.89061547  0.91491891  0.91589099  0.90603306  0.91333375
  0.92040368  0.88618857  0.89469629  0.86742033],0.89586615789
weighted average precision scores = [ 0.85610855  0.89443916  0.91752063  0.91733907  0.90840721  0.91753065
  0.92309068  0.89172383  0.89736442  0.87262783],0.899615202294
weighted average recall scores = [ 0.85610855  0.89443916  0.91752063  0.91733907  0.90840721  0.91753065
  0.92309068  0.89172383  0.89736442  0.87262783],0.899615202294
weighted f1 scores = [ 0.85402355  0.89210438  0.9162133   0.91673046  0.90774034  0.9151854
  0.92205976  0.88955504  0.89659079  0.87082413],0.898102714354
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.898806675854 recall  0.895163022072 f1  0.89586615789
loaded (126586) terms
done loading vocabulary
vectorizing done, 126586 terms vocabulary tokenized
vectorizing done, 126586 terms vocabulary tokenized
accuracy scores = [ 0.88054968  0.90375463  0.93386243  0.93167373  0.92417815  0.91556028
  0.934644    0.9106383   0.9142705   0.89498934],0.914412103689
macro precision scores = [ 0.87837916  0.9078429   0.93501053  0.93229901  0.92599693  0.91451388
  0.93490019  0.91144313  0.91401588  0.89496848],0.914937009668
macro recall scores = [ 0.8731058   0.90019314  0.93190192  0.93081308  0.92217544  0.91334379
  0.93234603  0.90622788  0.91168419  0.8916868 ],0.911347807212
macro f1 scores = [ 0.87375876  0.90216416  0.93292419  0.93128491  0.92289989  0.91312643
  0.93314444  0.90746109  0.91230159  0.89252714],0.912159260002
weighted average precision scores = [ 0.88043236  0.90684053  0.93432821  0.93250012  0.92469118  0.91693136
  0.93519811  0.91176125  0.91531625  0.89720356],0.915520292439
weighted average recall scores = [ 0.88043236  0.90684053  0.93432821  0.93250012  0.92469118  0.91693136
  0.93519811  0.91176125  0.91531625  0.89720356],0.915520292439
weighted f1 scores = [ 0.87892084  0.90381704  0.93360294  0.93181311  0.92341709  0.91548931
  0.93448468  0.91010193  0.91428476  0.89528684],0.914121854456
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.914937009668 recall  0.911347807212 f1  0.912159260002
loaded (11113) terms
extended to (17035) terms
done loading vocabulary
vectorizing done, 17035 terms vocabulary tokenized
vectorizing done, 17035 terms vocabulary tokenized
accuracy scores = [ 0.78435518  0.82231623  0.86137566  0.85699153  0.8457052   0.85767392
  0.87300744  0.83829787  0.82694356  0.80063966],0.836730624913
macro precision scores = [ 0.78151203  0.82742958  0.86066527  0.85537825  0.84578641  0.85556349
  0.87300917  0.8372268   0.8255744   0.79984728],0.836199268026
macro recall scores = [ 0.77611527  0.81746395  0.85764644  0.8545434   0.84429682  0.85492847
  0.87074725  0.83186609  0.82398495  0.79377237],0.832536503122
macro f1 scores = [ 0.77520626  0.819467    0.85831243  0.85462564  0.84388889  0.85412326
  0.87109186  0.83251316  0.82340845  0.79509351],0.832773045704
weighted average precision scores = [ 0.78416619  0.8261466   0.8620999   0.85764364  0.84563655  0.85647502
  0.87387487  0.83867241  0.82782088  0.80490774],0.837744379689
weighted average recall scores = [ 0.78416619  0.8261466   0.8620999   0.85764364  0.84563655  0.85647502
  0.87387487  0.83867241  0.82782088  0.80490774],0.837744379689
weighted f1 scores = [ 0.78143107  0.82197925  0.86093233  0.85697411  0.84451651  0.85601981
  0.87274962  0.83677852  0.82600692  0.80109518],0.835848332437
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.836199268026 recall  0.832536503122 f1  0.832773045704
loaded (146950) terms
vectorizing done, 146950 terms vocabulary tokenized
vectorizing done, 146950 terms vocabulary tokenized
accuracy scores = [ 0.87632135  0.90481227  0.93650794  0.93008475  0.9252386   0.92033988
  0.9335813   0.9106383   0.91373802  0.89498934],0.914625173991
macro precision scores = [ 0.87222389  0.90847929  0.93733981  0.93089681  0.92662593  0.91836485
  0.93446135  0.9110501   0.91372582  0.89510492],0.914827276859
macro recall scores = [ 0.86873098  0.90140282  0.93472553  0.92931098  0.9232123   0.91791411
  0.9314696   0.90617733  0.91086483  0.89212174],0.911593022624
macro f1 scores = [ 0.86895508  0.90336184  0.93554938  0.92979666  0.92391074  0.9175538
  0.93246624  0.90733958  0.91175375  0.89275899],0.912344606208
weighted average precision scores = [ 0.87559231  0.90747018  0.93685282  0.9309162   0.92571123  0.9211563
  0.93444052  0.91161933  0.91512808  0.89722822],0.915611520325
weighted average recall scores = [ 0.87559231  0.90747018  0.93685282  0.9309162   0.92571123  0.9211563
  0.93444052  0.91161933  0.91512808  0.89722822],0.915611520325
weighted f1 scores = [ 0.87466601  0.90489453  0.93623416  0.93019025  0.92460543  0.92019697
  0.9335709   0.91008398  0.91391846  0.89523505],0.914359574268
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.914827276859 recall  0.911593022624 f1  0.912344606208
loaded (31477) terms
extended to (39578) terms
done loading vocabulary
vectorizing done, 39578 terms vocabulary tokenized
vectorizing done, 39578 terms vocabulary tokenized
accuracy scores = [ 0.82610994  0.86197779  0.90687831  0.89194915  0.87751856  0.88528943
  0.90116897  0.8712766   0.86634718  0.84328358],0.873179949994
macro precision scores = [ 0.82549958  0.86376484  0.90818006  0.89219009  0.87691413  0.88248397
  0.90220625  0.86917386  0.86444469  0.84383884],0.872869631211
macro recall scores = [ 0.81855726  0.85872368  0.9050743   0.88993456  0.87528471  0.88131932
  0.89757924  0.865031    0.86212593  0.83776962],0.869139961854
macro f1 scores = [ 0.81877318  0.86017241  0.90615389  0.89065681  0.87511424  0.8811916
  0.89874486  0.8658678   0.86259516  0.83889245],0.869816241489
weighted average precision scores = [ 0.82733031  0.86429323  0.90755932  0.89260648  0.8774567   0.88520085
  0.90247767  0.87159065  0.86741095  0.8473561 ],0.874328226005
weighted average recall scores = [ 0.82733031  0.86429323  0.90755932  0.89260648  0.8774567   0.88520085
  0.90247767  0.87159065  0.86741095  0.8473561 ],0.874328226005
weighted f1 scores = [ 0.82418994  0.86221175  0.90678375  0.89187726  0.87651922  0.8845834
  0.90092503  0.87037649  0.86622613  0.84348913],0.872718209074
ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.872869631211 recall  0.869139961854 f1  0.869816241489
loaded (171969) terms
vectorizing done, 171969 terms vocabulary tokenized
vectorizing done, 171969 terms vocabulary tokenized
accuracy scores = [ 0.88477801  0.90957166  0.93597884  0.93167373  0.92417815  0.91768455
  0.93304995  0.91170213  0.91160809  0.89605544],0.915628053879
macro precision scores = [ 0.88274893  0.91330955  0.93734916  0.93273714  0.92506481  0.91620108
  0.9330625   0.91228627  0.91211714  0.89677564],0.91616522162
macro recall scores = [ 0.87769457  0.9059205   0.93435238  0.93069555  0.92243952  0.91511025
  0.93069711  0.90751826  0.90930605  0.89346681],0.912720100497
macro f1 scores = [ 0.87822141  0.90767064  0.93533064  0.93142185  0.92308335  0.91483892
  0.93151111  0.90867409  0.90996673  0.89420271],0.913492145431
weighted average precision scores = [ 0.88459987  0.91252903  0.93648846  0.93273898  0.92453314  0.91911835
  0.93336801  0.91287925  0.91268471  0.89874722],0.916768702784
weighted average recall scores = [ 0.88459987  0.91252903  0.93648846  0.93273898  0.92453314  0.91911835
  0.93336801  0.91287925  0.91268471  0.89874722],0.916768702784
weighted f1 scores = [ 0.88307878  0.90948419  0.93575253  0.93191689  0.92378182  0.91763097
  0.93288812  0.91130208  0.91145946  0.89646153],0.915375636398
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.91616522162 recall  0.912720100497 f1  0.913492145431
loaded (56496) terms
extended to (75380) terms
done loading vocabulary
vectorizing done, 75380 terms vocabulary tokenized
vectorizing done, 75380 terms vocabulary tokenized
accuracy scores = [ 0.85729387  0.89159175  0.91640212  0.91684322  0.90615058  0.91396707
  0.9218916   0.89148936  0.89243876  0.87046908],0.89785374273
macro precision scores = [ 0.85537825  0.8941301   0.91822741  0.91692337  0.90570219  0.91464796
  0.92300086  0.89170802  0.89158493  0.86987048],0.89811735709
macro recall scores = [ 0.85002881  0.88889469  0.91385021  0.91536193  0.90382462  0.91194458
  0.91908525  0.8854635   0.88953687  0.86623673],0.894422719031
macro f1 scores = [ 0.84995577  0.89023954  0.9152678   0.91580653  0.90414592  0.91212093
  0.9202208   0.88667609  0.88991445  0.86681708],0.89511649147
weighted average precision scores = [ 0.85716436  0.89378437  0.91728704  0.91739801  0.9059629   0.91647785
  0.92255038  0.89239587  0.89331821  0.87256933],0.898890832282
weighted average recall scores = [ 0.85716436  0.89378437  0.91728704  0.91739801  0.9059629   0.91647785
  0.92255038  0.89239587  0.89331821  0.87256933],0.898890832282
weighted f1 scores = [ 0.85497373  0.89162206  0.91616163  0.91679493  0.90552979  0.9140207
  0.92156225  0.89046388  0.89226738  0.87030009],0.897369643158
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.89811735709 recall  0.894422719031 f1  0.89511649147
loaded (185472) terms
vectorizing done, 185472 terms vocabulary tokenized
vectorizing done, 185472 terms vocabulary tokenized
accuracy scores = [ 0.88319239  0.90798519  0.93597884  0.93379237  0.92629905  0.91874668
  0.9325186   0.90851064  0.9142705   0.89658849],0.915788273952
macro precision scores = [ 0.88109035  0.91143474  0.93702788  0.93481959  0.92737235  0.91704451
  0.93312692  0.90929414  0.91520459  0.89717337],0.916358843311
macro recall scores = [ 0.87589597  0.90437453  0.93406894  0.93274787  0.92447123  0.91612551
  0.93003724  0.90431768  0.91187296  0.89413261],0.912804452392
macro f1 scores = [ 0.87638651  0.90602903  0.93498777  0.93348765  0.92517474  0.91582133
  0.93107513  0.90561867  0.91271593  0.89488453],0.913618129266
weighted average precision scores = [ 0.88300099  0.91060685  0.93647184  0.93486555  0.92675463  0.91998894
  0.93312315  0.90965584  0.91575609  0.8988788 ],0.916910268354
weighted average recall scores = [ 0.88300099  0.91060685  0.93647184  0.93486555  0.92675463  0.91998894
  0.93312315  0.90965584  0.91575609  0.8988788 ],0.916910268354
weighted f1 scores = [ 0.88141422  0.90780108  0.93570089  0.93403757  0.92586946  0.9186519
  0.93239339  0.90813439  0.91426006  0.8969476 ],0.915521055677
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.916358843311 recall  0.912804452392 f1  0.913618129266
loaded (69999) terms
extended to (89202) terms
done loading vocabulary
vectorizing done, 89202 terms vocabulary tokenized
vectorizing done, 89202 terms vocabulary tokenized
accuracy scores = [ 0.86099366  0.89317821  0.91798942  0.91737288  0.91304348  0.91502921
  0.9229543   0.89308511  0.90149095  0.87420043],0.900933764098
macro precision scores = [ 0.85874136  0.89754622  0.91932296  0.91819652  0.91279834  0.91532483
  0.92331317  0.89336594  0.90089808  0.87340172],0.901290913211
macro recall scores = [ 0.85369561  0.89028121  0.91514673  0.91588202  0.91015417  0.91302408
  0.91941377  0.88767043  0.89947123  0.87038873],0.897512797939
macro f1 scores = [ 0.85355403  0.89224825  0.91641032  0.91660711  0.9106081   0.91304619
  0.92050168  0.88889893  0.89959703  0.87082551],0.898229714637
weighted average precision scores = [ 0.86080073  0.89610313  0.91907886  0.91839466  0.91314271  0.91747383
  0.92334705  0.89401289  0.90251389  0.87619736],0.902106510993
weighted average recall scores = [ 0.86080073  0.89610313  0.91907886  0.91839466  0.91314271  0.91747383
  0.92334705  0.89401289  0.90251389  0.87619736],0.902106510993
weighted f1 scores = [ 0.85866025  0.89331119  0.91776801  0.91746304  0.9123605   0.91509925
  0.92247746  0.89227328  0.90144456  0.87413241],0.900498996673
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.901290913211 recall  0.897512797939 f1  0.898229714637
loaded (153867) terms
vectorizing done, 153867 terms vocabulary tokenized
vectorizing done, 153867 terms vocabulary tokenized
accuracy scores = [ 0.88107822  0.90586991  0.93756614  0.93273305  0.92629905  0.91609134
  0.93411265  0.9106383   0.91586794  0.89392324],0.915417984137
macro precision scores = [ 0.87927269  0.9096488   0.93921542  0.93358688  0.92753007  0.91463905
  0.93449622  0.91124686  0.91581262  0.89405688],0.915950546882
macro recall scores = [ 0.87360075  0.90223407  0.9356046   0.93174216  0.9240745   0.91344039
  0.93184077  0.90661869  0.91354581  0.89099158],0.912369331722
macro f1 scores = [ 0.87418676  0.90414694  0.93678594  0.93234492  0.92473393  0.91330833
  0.9326993   0.9077189   0.91410971  0.89171274],0.913174748359
weighted average precision scores = [ 0.88095     0.90873336  0.9382782   0.93370688  0.92663151  0.91736879
  0.93476889  0.911705    0.91721493  0.89592457],0.916528210715
weighted average recall scores = [ 0.88095     0.90873336  0.9382782   0.93370688  0.92663151  0.91736879
  0.93476889  0.911705    0.91721493  0.89592457],0.916528210715
weighted f1 scores = [ 0.87922843  0.90588332  0.93735337  0.93290032  0.92556758  0.9160398
  0.93401408  0.91016065  0.91601781  0.89410374],0.915126911271
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.915950546882 recall  0.912369331722 f1  0.913174748359
loaded (38394) terms
extended to (48487) terms
done loading vocabulary
vectorizing done, 48487 terms vocabulary tokenized
vectorizing done, 48487 terms vocabulary tokenized
accuracy scores = [ 0.82188161  0.86779482  0.91481481  0.89300847  0.88865323  0.90228359
  0.90276302  0.87978723  0.8743344   0.84648188],0.879180306482
macro precision scores = [ 0.81899407  0.86956149  0.916664    0.89318685  0.88907844  0.9012589
  0.90304741  0.87809298  0.87316781  0.84715826],0.879021021272
macro recall scores = [ 0.81367755  0.8639509   0.91197049  0.8914458   0.8866619   0.8992651
  0.89978277  0.87356932  0.87115868  0.84080646],0.875228896936
macro f1 scores = [ 0.81305688  0.86533081  0.91334446  0.89184716  0.88693008  0.89940167
  0.90054208  0.87443495  0.87126579  0.8418269 ],0.87579807766
weighted average precision scores = [ 0.82184626  0.86977025  0.91576837  0.89379956  0.88886905  0.90308334
  0.90339     0.88001174  0.87528411  0.85036641],0.880218907683
weighted average recall scores = [ 0.82184626  0.86977025  0.91576837  0.89379956  0.88886905  0.90308334
  0.90339     0.88001174  0.87528411  0.85036641],0.880218907683
weighted f1 scores = [ 0.81924683  0.86761219  0.91446037  0.89292996  0.88787666  0.90183642
  0.90235199  0.87878047  0.87397339  0.84633821],0.878540647966
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.879021021272 recall  0.875228896936 f1  0.87579807766
loaded (188338) terms
vectorizing done, 188338 terms vocabulary tokenized
vectorizing done, 188338 terms vocabulary tokenized
accuracy scores = [ 0.88742072  0.90904283  0.93756614  0.93326271  0.92364793  0.91715348
  0.93304995  0.9106383   0.91320554  0.89658849],0.916157608203
macro precision scores = [ 0.88584273  0.91272823  0.93882381  0.93436685  0.92456951  0.91565229
  0.93359141  0.91131655  0.91410465  0.8975514 ],0.916854742366
macro recall scores = [ 0.88049692  0.90541545  0.93600866  0.93223679  0.92194587  0.91418272
  0.93040861  0.90649775  0.91085245  0.89429497],0.913234019073
macro f1 scores = [ 0.88110285  0.90716032  0.93691284  0.93296213  0.92250928  0.9140301
  0.93148208  0.90769727  0.9116729   0.89503851],0.914056827655
weighted average precision scores = [ 0.88742145  0.9119114   0.93800398  0.93443129  0.92390256  0.91869736
  0.93363288  0.91186849  0.91459836  0.89914779],0.917361557512
weighted average recall scores = [ 0.88742145  0.9119114   0.93800398  0.93443129  0.92390256  0.91869736
  0.93363288  0.91186849  0.91459836  0.89914779],0.917361557512
weighted f1 scores = [ 0.88578591  0.90894516  0.93731678  0.93351037  0.92311681  0.91709742
  0.93290517  0.91028368  0.91316669  0.89696767],0.91590956754
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.916854742366 recall  0.913234019073 f1  0.914056827655
loaded (72865) terms
extended to (92479) terms
done loading vocabulary
vectorizing done, 92479 terms vocabulary tokenized
vectorizing done, 92479 terms vocabulary tokenized
accuracy scores = [ 0.8615222   0.89582232  0.92169312  0.91790254  0.91092259  0.91715348
  0.9218916   0.89148936  0.8972311   0.87313433],0.900876263666
macro precision scores = [ 0.85964454  0.89932992  0.92298767  0.91863448  0.91087528  0.91797373
  0.92301722  0.89138242  0.89605374  0.87301604],0.901291503753
macro recall scores = [ 0.85417994  0.89306633  0.9190027   0.91652316  0.90839122  0.91479197
  0.91851857  0.8859156   0.89465259  0.8692841 ],0.897432617134
macro f1 scores = [ 0.85414162  0.89483391  0.92018343  0.9172228   0.90892189  0.91496509
  0.91969814  0.88716439  0.89487515  0.86994082],0.898194724334
weighted average precision scores = [ 0.86150657  0.8981789   0.92244721  0.91900244  0.91099799  0.92023998
  0.92256677  0.8920015   0.89783775  0.87562278],0.902040189376
weighted average recall scores = [ 0.86150657  0.8981789   0.92244721  0.91900244  0.91099799  0.92023998
  0.92256677  0.8920015   0.89783775  0.87562278],0.902040189376
weighted f1 scores = [ 0.85923174  0.89590689  0.92132313  0.91810623  0.910362    0.91726446
  0.92138741  0.89060832  0.89706349  0.87317787],0.900443154793
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.901291503753 recall  0.897432617134 f1  0.898194724334
loaded (98451) terms
vectorizing done, 98451 terms vocabulary tokenized
vectorizing done, 98451 terms vocabulary tokenized
accuracy scores = [ 0.87579281  0.90163934  0.93333333  0.93008475  0.92205726  0.91556028
  0.9325186   0.90585106  0.91001065  0.88965885],0.911650693471
macro precision scores = [ 0.87211771  0.9042171   0.93425375  0.93066105  0.92390283  0.91460598
  0.93283344  0.90698122  0.91068768  0.89070622],0.912096699158
macro recall scores = [ 0.86759544  0.89873952  0.93168525  0.92912612  0.91973109  0.91258037
  0.93099572  0.90152555  0.90730535  0.88648614],0.908577054989
macro f1 scores = [ 0.86746541  0.90026813  0.93253348  0.9296182   0.92070516  0.9127805
  0.93159201  0.90276682  0.90843548  0.88750941],0.909367460671
weighted average precision scores = [ 0.87498356  0.90338541  0.93367607  0.93095199  0.92253516  0.91570744
  0.93328512  0.90716822  0.91156715  0.89263633],0.912589645477
weighted average recall scores = [ 0.87498356  0.90338541  0.93367607  0.93095199  0.92253516  0.91570744
  0.93328512  0.90716822  0.91156715  0.89263633],0.912589645477
weighted f1 scores = [ 0.87353141  0.90154212  0.93310641  0.93023959  0.9213924   0.91493463
  0.9325866   0.90528372  0.9102652   0.89006108],0.911294315738
ng20_raw_stems_unigrams_df1_tf1  -->  precision  0.912096699158 recall  0.908577054989 f1  0.909367460671
loaded (1294667) terms
vectorizing done, 1294667 terms vocabulary tokenized
vectorizing done, 1294667 terms vocabulary tokenized
accuracy scores = [ 0.88424947  0.91221576  0.93809524  0.94226695  0.9321315   0.92724376
  0.93942614  0.91595745  0.91906283  0.89712154],0.920777062994
macro precision scores = [ 0.88315525  0.91538653  0.94061286  0.94333373  0.93367675  0.92866631
  0.93999137  0.91728364  0.92019424  0.89877528],0.922107595292
macro recall scores = [ 0.87489075  0.90840429  0.93599112  0.94102207  0.93039869  0.92502076
  0.93683774  0.91150777  0.91704351  0.89512381],0.917624049662
macro f1 scores = [ 0.87449985  0.91006126  0.93747498  0.94187484  0.9314585   0.92575324
  0.93790126  0.91299451  0.9179731   0.89549079],0.918548231861
weighted average precision scores = [ 0.88452696  0.91487039  0.93891396  0.94298731  0.93324359  0.93020275
  0.94015089  0.91766995  0.92038404  0.90049498],0.922344483012
weighted average recall scores = [ 0.88452696  0.91487039  0.93891396  0.94298731  0.93324359  0.93020275
  0.94015089  0.91766995  0.92038404  0.90049498],0.922344483012
weighted f1 scores = [ 0.88100277  0.91210695  0.93779368  0.94233571  0.93218282  0.9276355
  0.93933808  0.91563409  0.91912307  0.897415  ],0.920456767497
ng20_raw_stems_bigrams_df1_tf1  -->  precision  0.922107595292 recall  0.917624049662 f1  0.918548231861
loaded (155942) terms
vectorizing done, 155942 terms vocabulary tokenized
vectorizing done, 155942 terms vocabulary tokenized
accuracy scores = [ 0.88319239  0.9132734   0.92962963  0.93167373  0.92788971  0.91980882
  0.934644    0.90904255  0.91320554  0.89072495],0.915308471061
macro precision scores = [ 0.88223609  0.91597078  0.93081147  0.93298295  0.92878277  0.91918764
  0.93493613  0.90958441  0.9140007   0.89233503],0.916082796169
macro recall scores = [ 0.87465108  0.91005929  0.92754462  0.93075004  0.92573898  0.91666705
  0.93235383  0.90462713  0.91058319  0.88790597],0.912088118385
macro f1 scores = [ 0.87503474  0.91162771  0.92855067  0.93145842  0.92640481  0.91692417
  0.93325981  0.9059636   0.91166082  0.88891505],0.912979979299
weighted average precision scores = [ 0.88327306  0.91554068  0.93024819  0.93318157  0.92842317  0.92053418
  0.93500833  0.91010262  0.91470457  0.89402302],0.91650393908
weighted average recall scores = [ 0.88327306  0.91554068  0.93024819  0.93318157  0.92842317  0.92053418
  0.93500833  0.91010262  0.91470457  0.89402302],0.91650393908
weighted f1 scores = [ 0.88068635  0.91328181  0.92936095  0.93202097  0.92741363  0.91930556
  0.93450157  0.90862225  0.9133736   0.8911882 ],0.914975487899
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.916082796169 recall  0.912088118385 f1  0.912979979299
loaded (57491) terms
extended to (74114) terms
done loading vocabulary
vectorizing done, 74114 terms vocabulary tokenized
vectorizing done, 74114 terms vocabulary tokenized
accuracy scores = [ 0.85940803  0.88947647  0.91428571  0.91207627  0.90986214  0.91768455
  0.92454835  0.88882979  0.8887114   0.86993603],0.897481874408
macro precision scores = [ 0.85661791  0.89278816  0.91697728  0.91211173  0.91114151  0.91903533
  0.9250531   0.88883522  0.88795167  0.86961797],0.898012989586
macro recall scores = [ 0.85198078  0.88607009  0.91104567  0.91059918  0.90774505  0.91553253
  0.92213705  0.88341823  0.88551909  0.865526  ],0.893957367845
macro f1 scores = [ 0.85198122  0.88778415  0.91284727  0.91108634  0.90833763  0.91612746
  0.92296944  0.88468333  0.88604668  0.86632747],0.894819097836
weighted average precision scores = [ 0.85901267  0.89187595  0.91622274  0.9130271   0.91089925  0.92010715
  0.92504148  0.88942429  0.89008023  0.87239709],0.898808795616
weighted average recall scores = [ 0.85901267  0.89187595  0.91622274  0.9130271   0.91089925  0.92010715
  0.92504148  0.88942429  0.89008023  0.87239709],0.898808795616
weighted f1 scores = [ 0.85737131  0.88934944  0.91419244  0.91228135  0.90941016  0.91773946
  0.9242744   0.88797615  0.88873472  0.86992517],0.897125460571
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.898012989586 recall  0.893957367845 f1  0.894819097836
loaded (109557) terms
vectorizing done, 109557 terms vocabulary tokenized
vectorizing done, 109557 terms vocabulary tokenized
accuracy scores = [ 0.87632135  0.90216816  0.93227513  0.93273305  0.92258749  0.91449814
  0.934644    0.90904255  0.90947817  0.89072495],0.912447299309
macro precision scores = [ 0.87362808  0.90572037  0.93356773  0.9332087   0.9245418   0.91383191
  0.93507015  0.91004291  0.90937652  0.89233209],0.913132025444
macro recall scores = [ 0.86800224  0.89897659  0.93017372  0.93180434  0.92037169  0.91131249
  0.93325057  0.90493852  0.90684698  0.88759769],0.909327481783
macro f1 scores = [ 0.8684002   0.9007759   0.93125876  0.93209633  0.92113114  0.91151384
  0.93378919  0.90630006  0.90753657  0.88886793],0.910166992791
weighted average precision scores = [ 0.87574942  0.90482683  0.93262961  0.93396297  0.92326576  0.91503542
  0.93523056  0.91023846  0.91072717  0.8940605 ],0.913572670432
weighted average recall scores = [ 0.87574942  0.90482683  0.93262961  0.93396297  0.92326576  0.91503542
  0.93523056  0.91023846  0.91072717  0.8940605 ],0.913572670432
weighted f1 scores = [ 0.87419678  0.90222509  0.93190899  0.93293382  0.92180199  0.91384113
  0.93458024  0.90868122  0.90956392  0.89129152],0.912102470738
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.913132025444 recall  0.909327481783 f1  0.910166992791
loaded (11106) terms
extended to (16350) terms
done loading vocabulary
vectorizing done, 16350 terms vocabulary tokenized
vectorizing done, 16350 terms vocabulary tokenized
accuracy scores = [ 0.78752643  0.83130619  0.86402116  0.86917373  0.85577943  0.86192246
  0.87194474  0.84521277  0.82747604  0.80010661],0.841446955235
macro precision scores = [ 0.78397457  0.83626114  0.86704661  0.87042099  0.85754112  0.86184432
  0.87221585  0.8443583   0.8260824   0.8000667 ],0.841981200254
macro recall scores = [ 0.77887556  0.8272815   0.85922596  0.86653558  0.85238091  0.85900021
  0.86918687  0.83885695  0.82414419  0.79502821],0.837051593241
macro f1 scores = [ 0.77680234  0.8296576   0.86073208  0.86794073  0.85312049  0.8590295
  0.86978309  0.8396238   0.82410657  0.7957098 ],0.837650599702
weighted average precision scores = [ 0.78661554  0.83541122  0.86578265  0.87096645  0.8572879   0.86208793
  0.87237682  0.84556597  0.82793799  0.80393279],0.842796525776
weighted average recall scores = [ 0.78661554  0.83541122  0.86578265  0.87096645  0.8572879   0.86208793
  0.87237682  0.84556597  0.82793799  0.80393279],0.842796525776
weighted f1 scores = [ 0.78356607  0.83164063  0.86299401  0.86954819  0.85485451  0.86075454
  0.87137533  0.84369459  0.82672996  0.8001936 ],0.840535143155
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.841981200254 recall  0.837051593241 f1  0.837650599702
loaded (134473) terms
vectorizing done, 134473 terms vocabulary tokenized
vectorizing done, 134473 terms vocabulary tokenized
accuracy scores = [ 0.87632135  0.90428345  0.93280423  0.92902542  0.92311771  0.91768455
  0.93304995  0.90744681  0.91001065  0.89232409],0.91260682117
macro precision scores = [ 0.87303526  0.90672218  0.93368745  0.92948881  0.9246809   0.91647054
  0.9334626   0.90830175  0.91111373  0.89318205],0.91301452649
macro recall scores = [ 0.86794936  0.90074963  0.93071079  0.92795672  0.92117664  0.91416746
  0.93092368  0.90352493  0.90759602  0.8891604 ],0.909391562459
macro f1 scores = [ 0.86779693  0.90226163  0.931679    0.92840788  0.92193713  0.91432292
  0.9317175   0.90476652  0.90876961  0.8901321 ],0.91017912288
weighted average precision scores = [ 0.87536785  0.90654555  0.93305513  0.93022342  0.92355053  0.91784836
  0.93408862  0.90877124  0.91162617  0.89470368],0.913578055201
weighted average recall scores = [ 0.87536785  0.90654555  0.93305513  0.93022342  0.92355053  0.91784836
  0.93408862  0.90877124  0.91162617  0.89470368],0.913578055201
weighted f1 scores = [ 0.87375301  0.90423084  0.93246334  0.92931149  0.92248101  0.91693608
  0.93311599  0.90711781  0.91028525  0.89247801],0.912217283312
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.91301452649 recall  0.909391562459 f1  0.91017912288
loaded (36022) terms
extended to (43618) terms
done loading vocabulary
vectorizing done, 43618 terms vocabulary tokenized
vectorizing done, 43618 terms vocabulary tokenized
accuracy scores = [ 0.82241015  0.86303543  0.90634921  0.89141949  0.87804878  0.88847584
  0.90223167  0.87446809  0.87273695  0.84008529],0.873926088937
macro precision scores = [ 0.81756755  0.86278534  0.90812713  0.89122484  0.87814958  0.88801346
  0.90238871  0.87239298  0.87048522  0.84057081],0.87317056286
macro recall scores = [ 0.81414249  0.85774371  0.90413149  0.88893332  0.87612375  0.88469137
  0.89901578  0.86753133  0.86892028  0.83490199],0.869613552086
macro f1 scores = [ 0.81333319  0.85896715  0.90550621  0.88965579  0.87609496  0.88523294
  0.89970448  0.86823191  0.86897628  0.83564939],0.870135229719
weighted average precision scores = [ 0.82207159  0.86430241  0.90724267  0.89231716  0.87800067  0.89029636
  0.90289128  0.87495462  0.87322738  0.84379468],0.874909881715
weighted average recall scores = [ 0.82207159  0.86430241  0.90724267  0.89231716  0.87800067  0.89029636
  0.90289128  0.87495462  0.87322738  0.84379468],0.874909881715
weighted f1 scores = [ 0.82010055  0.86264233  0.90627002  0.89145128  0.87701136  0.88836484
  0.90178755  0.87319958  0.87229358  0.83993691],0.873305800129
ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.87317056286 recall  0.869613552086 f1  0.870135229719
loaded (158605) terms
vectorizing done, 158605 terms vocabulary tokenized
vectorizing done, 158605 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.91115812  0.93121693  0.93220339  0.92895016  0.91927775
  0.9357067   0.90744681  0.9142705   0.89179104],0.915415670116
macro precision scores = [ 0.87942403  0.91434887  0.93245464  0.93338918  0.92970985  0.91863445
  0.936228    0.90812231  0.91450717  0.89405535],0.916087384783
macro recall scores = [ 0.87372225  0.90790893  0.92906492  0.93125015  0.92674371  0.91635127
  0.93349429  0.90285737  0.91189458  0.88892649],0.912221396175
macro f1 scores = [ 0.87378862  0.90971584  0.93012635  0.93187459  0.92753918  0.91658937
  0.9344458   0.90423425  0.91262108  0.89007049],0.913100555185
weighted average precision scores = [ 0.88126382  0.91343246  0.93180197  0.93363725  0.92936218  0.92020497
  0.93602976  0.90859334  0.91534     0.89574552],0.916541127225
weighted average recall scores = [ 0.88126382  0.91343246  0.93180197  0.93363725  0.92936218  0.92020497
  0.93602976  0.90859334  0.91534     0.89574552],0.916541127225
weighted f1 scores = [ 0.87959614  0.91116551  0.9309303   0.9324752   0.92858878  0.91892447
  0.93553411  0.90698731  0.91427195  0.89236227],0.915083604052
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.916087384783 recall  0.912221396175 f1  0.913100555185
loaded (60154) terms
extended to (77021) terms
done loading vocabulary
vectorizing done, 77021 terms vocabulary tokenized
vectorizing done, 77021 terms vocabulary tokenized
accuracy scores = [ 0.85887949  0.89212057  0.91746032  0.91631356  0.91145281  0.91715348
  0.924017    0.89148936  0.88977636  0.87100213],0.89896650841
macro precision scores = [ 0.85691647  0.89502553  0.91949425  0.91655672  0.91215945  0.91860844
  0.92429524  0.89066822  0.8890872   0.87081827],0.89936297878
macro recall scores = [ 0.85101752  0.88887406  0.91429747  0.91469243  0.90935865  0.91510612
  0.92096072  0.88617878  0.88683554  0.86669608],0.895401736285
macro f1 scores = [ 0.85111844  0.89041296  0.91588264  0.9152523   0.90980492  0.9156735
  0.92197819  0.88726729  0.88733321  0.86745157],0.896217499747
weighted average precision scores = [ 0.8588996   0.89449607  0.9189531   0.917533    0.91194127  0.91991817
  0.92464558  0.8923319   0.89089233  0.87346801],0.900307904205
weighted average recall scores = [ 0.8588996   0.89449607  0.9189531   0.917533    0.91194127  0.91991817
  0.92464558  0.8923319   0.89089233  0.87346801],0.900307904205
weighted f1 scores = [ 0.85662663  0.89203273  0.91727898  0.91654991  0.91088395  0.91735462
  0.92380674  0.89092397  0.88973587  0.87092363],0.898611702595
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.89936297878 recall  0.895401736285 f1  0.896217499747
loaded (175332) terms
vectorizing done, 175332 terms vocabulary tokenized
vectorizing done, 175332 terms vocabulary tokenized
accuracy scores = [ 0.88372093  0.91168694  0.93121693  0.93167373  0.92682927  0.92087095
  0.934644    0.90851064  0.91373802  0.88965885],0.915255024912
macro precision scores = [ 0.8824287   0.91440161  0.93232214  0.93262436  0.92777054  0.91992066
  0.93449544  0.90947092  0.9150332   0.89156992],0.916003748786
macro recall scores = [ 0.87515098  0.90853383  0.92907008  0.93071606  0.92469732  0.91757793
  0.93223914  0.90417153  0.91120293  0.88658932],0.911994910093
macro f1 scores = [ 0.87531395  0.91011012  0.93006061  0.93133565  0.92542757  0.91779577
  0.933031    0.90564169  0.91241366  0.88779212],0.912892215839
weighted average precision scores = [ 0.88357786  0.91388671  0.93183878  0.93281651  0.92735774  0.92162502
  0.93488626  0.90987808  0.91532334  0.89329117],0.916448145868
weighted average recall scores = [ 0.88357786  0.91388671  0.93183878  0.93281651  0.92735774  0.92162502
  0.93488626  0.90987808  0.91532334  0.89329117],0.916448145868
weighted f1 scores = [ 0.8810267   0.91169239  0.93094192  0.93191515  0.92640259  0.92040141
  0.93447372  0.90820414  0.91388673  0.89020263],0.914914738263
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.916003748786 recall  0.911994910093 f1  0.912892215839
loaded (76881) terms
extended to (94100) terms
done loading vocabulary
vectorizing done, 94100 terms vocabulary tokenized
vectorizing done, 94100 terms vocabulary tokenized
accuracy scores = [ 0.86257928  0.89053411  0.91851852  0.9157839   0.91039236  0.91821561
  0.924017    0.89202128  0.8972311   0.87153518],0.900082834305
macro precision scores = [ 0.85855351  0.89422825  0.92077845  0.91615585  0.91120921  0.91990886
  0.92419001  0.89260148  0.89692311  0.87128158],0.900583032117
macro recall scores = [ 0.85495174  0.88739279  0.91528014  0.91441502  0.9080831   0.9160912
  0.9213537   0.88748956  0.89436334  0.86706198],0.896648257183
macro f1 scores = [ 0.8546302   0.88916574  0.91689097  0.91493679  0.90862872  0.91679125
  0.9220666   0.88894069  0.89493647  0.86786763],0.897485505692
weighted average precision scores = [ 0.86158389  0.8930165   0.92027609  0.91695664  0.91097612  0.92111218
  0.92475556  0.89301264  0.89886392  0.87406131],0.901461484855
weighted average recall scores = [ 0.86158389  0.8930165   0.92027609  0.91695664  0.91097612  0.92111218
  0.92475556  0.89301264  0.89886392  0.87406131],0.901461484855
weighted f1 scores = [ 0.86032048  0.89045415  0.918339    0.91602981  0.90980217  0.91847474
  0.92378634  0.89160305  0.89737649  0.87150133],0.899768755066
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.900583032117 recall  0.896648257183 f1  0.897485505692
loaded (141098) terms
vectorizing done, 141098 terms vocabulary tokenized
vectorizing done, 141098 terms vocabulary tokenized
accuracy scores = [ 0.87737844  0.90534109  0.93174603  0.93008475  0.92152704  0.91874668
  0.934644    0.90691489  0.91267306  0.89232409],0.913138006421
macro precision scores = [ 0.87376549  0.90901745  0.93299256  0.93108992  0.92270726  0.91810742
  0.93475047  0.90736967  0.91352058  0.89325056],0.913657138561
macro recall scores = [ 0.86871385  0.90162397  0.92983656  0.92927099  0.91904679  0.91538897
  0.9330418   0.90242601  0.91038821  0.88914977],0.909888692918
macro f1 scores = [ 0.86877751  0.90342729  0.93087486  0.92976335  0.91970725  0.91570201
  0.93357133  0.90364716  0.91133042  0.89019125],0.910699242871
weighted average precision scores = [ 0.87638889  0.90810395  0.93199579  0.93162419  0.92183491  0.91946746
  0.93525114  0.90797633  0.91406584  0.89501188],0.914172037678
weighted average recall scores = [ 0.87638889  0.90810395  0.93199579  0.93162419  0.92183491  0.91946746
  0.93525114  0.90797633  0.91406584  0.89501188],0.914172037678
weighted f1 scores = [ 0.87496489  0.90522481  0.93139907  0.93043512  0.92071345  0.91819245
  0.93462989  0.90642133  0.91279192  0.89265962],0.912743255738
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.913657138561 recall  0.909888692918 f1  0.910699242871
loaded (42647) terms
extended to (51619) terms
done loading vocabulary
vectorizing done, 51619 terms vocabulary tokenized
vectorizing done, 51619 terms vocabulary tokenized
accuracy scores = [ 0.81659619  0.87149656  0.90793651  0.89883475  0.88865323  0.90069039
  0.90435707  0.87978723  0.87167199  0.84221748],0.878224140939
macro precision scores = [ 0.81090757  0.87148974  0.91099153  0.89937789  0.88906068  0.90139829
  0.90421867  0.8789509   0.87045393  0.84171214],0.877856134757
macro recall scores = [ 0.80815132  0.86589617  0.90409668  0.89792776  0.88694018  0.89705158
  0.9011864   0.87434194  0.86844554  0.83739127],0.874142883252
macro f1 scores = [ 0.8072297   0.86700194  0.90611544  0.89831423  0.88722775  0.89781881
  0.90188247  0.87542874  0.86870254  0.8379348 ],0.874765639964
weighted average precision scores = [ 0.81616036  0.87328966  0.9095092   0.89996681  0.8884371   0.90282539
  0.9048229   0.88022319  0.87303585  0.84522056],0.879349101549
weighted average recall scores = [ 0.81616036  0.87328966  0.9095092   0.89996681  0.8884371   0.90282539
  0.9048229   0.88022319  0.87303585  0.84522056],0.879349101549
weighted f1 scores = [ 0.81436641  0.87100443  0.90758205  0.89906854  0.88783515  0.90047414
  0.9039195   0.87897134  0.87163982  0.84213732],0.877699869655
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.877856134757 recall  0.874142883252 f1  0.874765639964
loaded (177813) terms
vectorizing done, 177813 terms vocabulary tokenized
vectorizing done, 177813 terms vocabulary tokenized
accuracy scores = [ 0.88319239  0.9106293   0.93227513  0.93061441  0.92629905  0.91980882
  0.9357067   0.90691489  0.91320554  0.8891258 ],0.914777201205
macro precision scores = [ 0.88105702  0.91385312  0.93382718  0.93161312  0.92719514  0.91903706
  0.93567176  0.90780828  0.91381033  0.89091897],0.915479199966
macro recall scores = [ 0.87486832  0.90751352  0.93008018  0.92966177  0.92417638  0.91656257
  0.93332994  0.90235737  0.91056752  0.88596703],0.91150845941
macro f1 scores = [ 0.87494087  0.90927087  0.93125362  0.93019865  0.92498017  0.9168432
  0.93414117  0.90377424  0.91153236  0.887073  ],0.912400815045
weighted average precision scores = [ 0.88266691  0.91287526  0.93292682  0.93203081  0.92676383  0.92070314
  0.93592151  0.90827822  0.91449416  0.89290591],0.915956656728
weighted average recall scores = [ 0.88266691  0.91287526  0.93292682  0.93203081  0.92676383  0.92070314
  0.93592151  0.90827822  0.91449416  0.89290591],0.915956656728
weighted f1 scores = [ 0.88066682  0.91062992  0.93197205  0.93088773  0.92594592  0.91940659
  0.9355145   0.90650885  0.91325171  0.88966262],0.914444671715
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.915479199966 recall  0.91150845941 f1  0.912400815045
loaded (79362) terms
extended to (96804) terms
done loading vocabulary
vectorizing done, 96804 terms vocabulary tokenized
vectorizing done, 96804 terms vocabulary tokenized
accuracy scores = [ 0.86205074  0.89159175  0.92222222  0.91790254  0.91092259  0.91715348
  0.9282678   0.88989362  0.89563365  0.87100213],0.900664052318
macro precision scores = [ 0.85949756  0.8951348   0.92398672  0.9184432   0.91210353  0.91897952
  0.92900344  0.88902232  0.89509358  0.87097814],0.901224281644
macro recall scores = [ 0.85403278  0.88842382  0.91935442  0.91648292  0.90880175  0.91522334
  0.92532139  0.88490278  0.89282747  0.86667447],0.897204513309
macro f1 scores = [ 0.85406177  0.89012296  0.9207407   0.9170464   0.90948443  0.91586121
  0.92643319  0.88596865  0.89335905  0.86744398],0.898052232426
weighted average precision scores = [ 0.86181392  0.89397675  0.92358652  0.91933175  0.91149907  0.92041245
  0.92905534  0.89059938  0.89686518  0.87382837],0.902096872582
weighted average recall scores = [ 0.86181392  0.89397675  0.92358652  0.91933175  0.91149907  0.92041245
  0.92905534  0.89059938  0.89686518  0.87382837],0.902096872582
weighted f1 scores = [ 0.85974175  0.89145107  0.92203329  0.91820596  0.91041872  0.91753538
  0.9280901   0.88939639  0.89567733  0.8710185 ],0.900356849251
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.901224281644 recall  0.897204513309 f1  0.898052232426
loaded (122412) terms
vectorizing done, 122412 terms vocabulary tokenized
vectorizing done, 122412 terms vocabulary tokenized
accuracy scores = [ 0.88107822  0.90586991  0.93174603  0.93538136  0.92364793  0.91449814
  0.934644    0.91170213  0.91160809  0.89552239],0.914569820046
macro precision scores = [ 0.88167227  0.9084977   0.93362837  0.93658375  0.92506584  0.91354148
  0.93560385  0.91101472  0.91047495  0.89712009],0.915320303182
macro recall scores = [ 0.87497851  0.90323714  0.92968082  0.93483241  0.92170252  0.91243915
  0.9322897   0.90649115  0.9085314   0.89325224],0.911743503427
macro f1 scores = [ 0.8761983   0.90450002  0.93098949  0.93542495  0.92245164  0.91227686
  0.93346935  0.90744507  0.909197    0.89405848],0.91260111601
weighted average precision scores = [ 0.88190834  0.90789229  0.93225273  0.93641895  0.92412395  0.91503049
  0.93508896  0.91250925  0.91233135  0.89852418],0.915608047994
weighted average recall scores = [ 0.88190834  0.90789229  0.93225273  0.93641895  0.92412395  0.91503049
  0.93508896  0.91250925  0.91233135  0.89852418],0.915608047994
weighted f1 scores = [ 0.87976918  0.90577965  0.93145513  0.93562062  0.92309564  0.91407805
  0.93446872  0.91106187  0.91168207  0.89587997],0.914289089573
ng20_raw_unigrams_stopwords  -->  precision  0.915320303182 recall  0.911743503427 f1  0.91260111601
loaded (1533239) terms
vectorizing done, 1533239 terms vocabulary tokenized
vectorizing done, 1533239 terms vocabulary tokenized
accuracy scores = [ 0.8884778   0.90957166  0.94126984  0.94014831  0.92576882  0.91821561
  0.93783209  0.91382979  0.9142705   0.89978678],0.918917120079
macro precision scores = [ 0.88930136  0.91231737  0.94321144  0.94086143  0.92784469  0.91774091
  0.93822491  0.91350041  0.9149866   0.90098171],0.919897082685
macro recall scores = [ 0.88240982  0.90685922  0.94058798  0.93961611  0.92459235  0.91548535
  0.93570967  0.91046004  0.91198859  0.89741468],0.916512380978
macro f1 scores = [ 0.88370747  0.90820646  0.94140178  0.94000215  0.92537787  0.9157099
  0.93660221  0.91127187  0.91295475  0.89822127],0.917345573413
weighted average precision scores = [ 0.88939981  0.91175     0.9418375   0.94078766  0.92677927  0.91909757
  0.9381282   0.91431379  0.91533609  0.90222022],0.919965011212
weighted average recall scores = [ 0.88939981  0.91175     0.9418375   0.94078766  0.92677927  0.91909757
  0.9381282   0.91431379  0.91533609  0.90222022],0.919965011212
weighted f1 scores = [ 0.8872102   0.90954235  0.94108452  0.94022979  0.92552427  0.91784174
  0.93767626  0.9134496   0.91431006  0.90004924],0.918691803122
ng20_raw_bigrams_stopwords  -->  precision  0.919897082685 recall  0.916512380978 f1  0.917345573413
loaded (115123) terms
vectorizing done, 115123 terms vocabulary tokenized
vectorizing done, 115123 terms vocabulary tokenized
accuracy scores = [ 0.8794926   0.90005288  0.93492063  0.93008475  0.92417815  0.91502921
  0.9335813   0.90425532  0.91160809  0.89658849],0.912979142221
macro precision scores = [ 0.87736346  0.90415077  0.93650971  0.93094849  0.92562445  0.91356331
  0.93335578  0.90377145  0.91181096  0.89726639],0.913436477326
macro recall scores = [ 0.87273181  0.89763358  0.9335812   0.92926984  0.92257207  0.91322009
  0.93104012  0.89926048  0.90888586  0.89400923],0.910220427246
macro f1 scores = [ 0.87354013  0.89954827  0.93451338  0.92971636  0.92328107  0.91278794
  0.93178914  0.90020133  0.90987717  0.89476569],0.911002048146
weighted average precision scores = [ 0.87987115  0.90263936  0.9354547   0.93078433  0.92453821  0.91571971
  0.93399915  0.90517899  0.91265772  0.89905941],0.913990274041
weighted average recall scores = [ 0.87987115  0.90263936  0.9354547   0.93078433  0.92453821  0.91571971
  0.93399915  0.90517899  0.91265772  0.89905941],0.913990274041
weighted f1 scores = [ 0.87837589  0.90025566  0.93470201  0.93004202  0.92365836  0.91479475
  0.93342297  0.90366642  0.91170106  0.8969326 ],0.912755175387
ng20_raw_lemmas_unigrams_stopwords_df1_tf1  -->  precision  0.913436477326 recall  0.910220427246 f1  0.911002048146
loaded (1464182) terms
vectorizing done, 1464182 terms vocabulary tokenized
vectorizing done, 1464182 terms vocabulary tokenized
accuracy scores = [ 0.88794926  0.91010048  0.94074074  0.93697034  0.92895016  0.92087095
  0.93942614  0.90744681  0.91640043  0.89552239],0.918437769034
macro precision scores = [ 0.88783534  0.91258956  0.94241038  0.9380501   0.93079018  0.92048635
  0.94035675  0.90751117  0.917606    0.896543  ],0.919417881905
macro recall scores = [ 0.88163549  0.90710759  0.93967031  0.93617726  0.92731872  0.91870392
  0.93724291  0.90341548  0.91427566  0.89322784],0.915877518899
macro f1 scores = [ 0.8827095   0.90858472  0.94047708  0.93678858  0.92823411  0.9189436
  0.93840585  0.90448592  0.915396    0.89385917],0.916788451788
weighted average precision scores = [ 0.88875891  0.91182625  0.94138815  0.93771912  0.93006096  0.92171223
  0.93989737  0.90796045  0.91768451  0.89781546],0.919482341083
weighted average recall scores = [ 0.88875891  0.91182625  0.94138815  0.93771912  0.93006096  0.92171223
  0.93989737  0.90796045  0.91768451  0.89781546],0.919482341083
weighted f1 scores = [ 0.88668157  0.90996005  0.94052836  0.93702107  0.92880811  0.92067413
  0.93935108  0.90688797  0.91653815  0.8956381 ],0.918208859587
ng20_raw_lemmas_bigrams_stopwords_df1_tf1  -->  precision  0.919417881905 recall  0.915877518899 f1  0.916788451788
loaded (164528) terms
done loading vocabulary
vectorizing done, 164528 terms vocabulary tokenized
vectorizing done, 164528 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.90904283  0.93756614  0.93167373  0.92948038  0.91715348
  0.93304995  0.90957447  0.91480298  0.89392324],0.915840250545
macro precision scores = [ 0.88018767  0.91176849  0.93922396  0.93250283  0.9308913   0.91563798
  0.93283651  0.90890891  0.91589179  0.89458767],0.916243711825
macro recall scores = [ 0.87510021  0.9054055   0.93617827  0.93047829  0.92806271  0.91437953
  0.93053496  0.90502392  0.91231569  0.8912807 ],0.912875979856
macro f1 scores = [ 0.87588692  0.90707163  0.93709355  0.93112516  0.92879468  0.91430184
  0.93132584  0.90594828  0.91360433  0.89192953],0.913708176913
weighted average precision scores = [ 0.88209881  0.91117771  0.93810207  0.93244926  0.92988365  0.91823855
  0.93341838  0.91016914  0.9162864   0.89644981],0.916827376951
weighted average recall scores = [ 0.88209881  0.91117771  0.93810207  0.93244926  0.92988365  0.91823855
  0.93341838  0.91016914  0.9162864   0.89644981],0.916827376951
weighted f1 scores = [ 0.88065827  0.90891646  0.93727266  0.93169996  0.9290967   0.91705569
  0.93291716  0.90905143  0.91508792  0.89415582],0.915591206268
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.916243711825 recall  0.912875979856 f1  0.913708176913
loaded (49405) terms
extended to (66588) terms
done loading vocabulary
vectorizing done, 66588 terms vocabulary tokenized
vectorizing done, 66588 terms vocabulary tokenized
accuracy scores = [ 0.86099366  0.88841883  0.91746032  0.91101695  0.90986214  0.91556028
  0.91657811  0.88670213  0.89403621  0.87366738],0.897429599058
macro precision scores = [ 0.85950287  0.89007658  0.91903443  0.91081825  0.91032357  0.91404261
  0.91630847  0.88555852  0.89382032  0.87336886],0.89728544825
macro recall scores = [ 0.85559807  0.88569872  0.91545168  0.90845529  0.90818901  0.91432792
  0.91302863  0.88122785  0.8910581   0.86946171],0.894249700166
macro f1 scores = [ 0.85625505  0.88684966  0.91659741  0.90925972  0.90869328  0.91363449
  0.91397297  0.88214111  0.89193882  0.87024982],0.89495923302
weighted average precision scores = [ 0.86132151  0.89033039  0.91842616  0.91120386  0.91028514  0.91613958
  0.91685673  0.88637562  0.89586868  0.87568646],0.898249412774
weighted average recall scores = [ 0.86132151  0.89033039  0.91842616  0.91120386  0.91028514  0.91613958
  0.91685673  0.88637562  0.89586868  0.87568646],0.898249412774
weighted f1 scores = [ 0.85996253  0.88849252  0.91734694  0.91075956  0.90955945  0.91529775
  0.91615233  0.88552089  0.89447056  0.87351225],0.897107477301
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.89728544825 recall  0.894249700166 f1  0.89495923302
loaded (123271) terms
done loading vocabulary
vectorizing done, 123271 terms vocabulary tokenized
vectorizing done, 123271 terms vocabulary tokenized
accuracy scores = [ 0.87896406  0.90322581  0.93386243  0.93061441  0.92576882  0.91609134
  0.93198725  0.90797872  0.91214058  0.89552239],0.913615580695
macro precision scores = [ 0.8758618   0.90646078  0.93493662  0.93149337  0.9270168   0.91441165
  0.93240857  0.90727003  0.91273087  0.89620248],0.913879297546
macro recall scores = [ 0.871771    0.90066816  0.93217976  0.92974122  0.92381418  0.91424597
  0.9297685   0.90309496  0.90934627  0.89296603],0.910759605578
macro f1 scores = [ 0.8724237   0.90242928  0.93308478  0.9302122   0.92451271  0.91382717
  0.93065706  0.90404085  0.91046079  0.89367931],0.911532784529
weighted average precision scores = [ 0.87882417  0.90539255  0.93413135  0.93135495  0.92605119  0.9165884
  0.93232979  0.90846902  0.91344036  0.89794838],0.914453015334
weighted average recall scores = [ 0.87882417  0.90539255  0.93413135  0.93135495  0.92605119  0.9165884
  0.93232979  0.90846902  0.91344036  0.89794838],0.914453015334
weighted f1 scores = [ 0.87767707  0.90340783  0.93356431  0.93057993  0.92515121  0.91586597
  0.93180716  0.90730952  0.91226222  0.89580843],0.913343365992
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.913879297546 recall  0.910759605578 f1  0.911532784529
loaded (8148) terms
extended to (13314) terms
done loading vocabulary
vectorizing done, 13314 terms vocabulary tokenized
vectorizing done, 13314 terms vocabulary tokenized
accuracy scores = [ 0.78488372  0.82125859  0.85396825  0.85010593  0.84146341  0.8385555
  0.86609989  0.8287234   0.80830671  0.79104478],0.828441019499
macro precision scores = [ 0.78141402  0.82438238  0.85418091  0.84992344  0.84172685  0.83521771
  0.86489527  0.82694333  0.80744006  0.7890725 ],0.827519646012
macro recall scores = [ 0.7777814   0.81687912  0.85076666  0.84699224  0.83993688  0.83539129
  0.86204573  0.8215288   0.80427152  0.78437801],0.823997165187
macro f1 scores = [ 0.77707722  0.81907275  0.85146093  0.84785559  0.83975136  0.83431151
  0.86273687  0.82181861  0.80451939  0.7851748 ],0.824377903806
weighted average precision scores = [ 0.78471834  0.82461847  0.85557452  0.85062525  0.84291569  0.83774335
  0.86593193  0.82837966  0.80995893  0.79490257],0.829536871941
weighted average recall scores = [ 0.78471834  0.82461847  0.85557452  0.85062525  0.84291569  0.83774335
  0.86593193  0.82837966  0.80995893  0.79490257],0.829536871941
weighted f1 scores = [ 0.78278799  0.82166097  0.85376583  0.84977904  0.84108482  0.83715235
  0.86537453  0.82657895  0.80780331  0.79143373],0.827742151396
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.827519646012 recall  0.823997165187 f1  0.824377903806
loaded (156323) terms
vectorizing done, 156323 terms vocabulary tokenized
vectorizing done, 156323 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.90692755  0.93544974  0.9279661   0.9252386   0.91980882
  0.93304995  0.90691489  0.91746539  0.89712154],0.915207787556
macro precision scores = [ 0.88023133  0.9098629   0.93648575  0.9287628   0.92668614  0.91816459
  0.93339245  0.90643106  0.91791216  0.89720842],0.915513760066
macro recall scores = [ 0.87539912  0.90395229  0.93427202  0.92689296  0.92328809  0.91751333
  0.93079406  0.90219517  0.91502645  0.89464663],0.912398013813
macro f1 scores = [ 0.87620631  0.90560124  0.93494642  0.9274538   0.92408368  0.91732661
  0.93163479  0.90312657  0.91603718  0.89513171],0.913154831565
weighted average precision scores = [ 0.88229937  0.90888016  0.9356939   0.92882068  0.92576861  0.9205831
  0.9336777   0.90752884  0.91890155  0.89907719],0.916123110853
weighted average recall scores = [ 0.88229937  0.90888016  0.9356939   0.92882068  0.92576861  0.9205831
  0.9336777   0.90752884  0.91890155  0.89907719],0.916123110853
weighted f1 scores = [ 0.88086323  0.90687594  0.93516209  0.92802019  0.9247457   0.91972069
  0.93296245  0.9062635   0.91778197  0.89727808],0.914967382773
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.915513760066 recall  0.912398013813 f1  0.913154831565
loaded (41200) terms
extended to (49568) terms
done loading vocabulary
vectorizing done, 49568 terms vocabulary tokenized
vectorizing done, 49568 terms vocabulary tokenized
accuracy scores = [ 0.82716702  0.86197779  0.9021164   0.89036017  0.88335101  0.88688263
  0.89691817  0.86861702  0.86954207  0.83955224],0.872648451995
macro precision scores = [ 0.82454963  0.86363275  0.90311207  0.89031863  0.88344635  0.88540592
  0.89639522  0.8682636   0.8686751   0.83863384],0.872243310325
macro recall scores = [ 0.81968869  0.85953192  0.90063227  0.88828083  0.88154684  0.88356025
  0.89333985  0.86250708  0.86613608  0.83473102],0.868995483529
macro f1 scores = [ 0.81955339  0.860783    0.90136555  0.88889646  0.88159954  0.88380501
  0.8942522   0.86382706  0.86679019  0.83538881],0.869626121287
weighted average precision scores = [ 0.82746338  0.86418019  0.90292702  0.89103585  0.88323072  0.88719225
  0.89809176  0.86936541  0.87085857  0.84205259],0.873639772569
weighted average recall scores = [ 0.82746338  0.86418019  0.90292702  0.89103585  0.88323072  0.88719225
  0.89809176  0.86936541  0.87085857  0.84205259],0.873639772569
weighted f1 scores = [ 0.82519332  0.8623665   0.90203195  0.8902998   0.88242056  0.88643486
  0.8969599   0.86771159  0.86962901  0.83953543],0.872258289805
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.872243310325 recall  0.868995483529 f1  0.869626121287
loaded (165583) terms
vectorizing done, 165583 terms vocabulary tokenized
vectorizing done, 165583 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90904283  0.93703704  0.93220339  0.92895016  0.91715348
  0.93304995  0.90851064  0.91480298  0.89392324],0.915628047223
macro precision scores = [ 0.87971895  0.91176113  0.93865061  0.9330609   0.93032538  0.9155567
  0.93278942  0.90786202  0.91589179  0.89461005],0.916022694802
macro recall scores = [ 0.87459001  0.9054055   0.93567322  0.93098334  0.92755766  0.91437953
  0.9305297   0.90388346  0.91231569  0.8912807 ],0.912659882022
macro f1 scores = [ 0.87539833  0.9070395   0.93657149  0.93165887  0.92826721  0.91428624
  0.93133226  0.90484889  0.91360433  0.89195148],0.913495860507
weighted average precision scores = [ 0.88160922  0.91126429  0.93750141  0.93303976  0.92928947  0.91815481
  0.93337003  0.90908677  0.9162864   0.89646854],0.916607070443
weighted average recall scores = [ 0.88160922  0.91126429  0.93750141  0.93303976  0.92928947  0.91815481
  0.93337003  0.90908677  0.9162864   0.89646854],0.916607070443
weighted f1 scores = [ 0.88015     0.90893729  0.93672573  0.93226228  0.92854289  0.91703962
  0.93292678  0.90797168  0.91508792  0.89417617],0.915382035347
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.916022694802 recall  0.912659882022 f1  0.913495860507
loaded (50460) terms
extended to (67859) terms
done loading vocabulary
vectorizing done, 67859 terms vocabulary tokenized
vectorizing done, 67859 terms vocabulary tokenized
accuracy scores = [ 0.85887949  0.88947647  0.91904762  0.91048729  0.90933192  0.91449814
  0.91498406  0.88776596  0.89243876  0.87473348],0.897164318501
macro precision scores = [ 0.85748271  0.89111964  0.92065981  0.91032763  0.9098851   0.91313702
  0.91456658  0.88738704  0.89233509  0.87423788],0.897113850531
macro recall scores = [ 0.85346297  0.88670903  0.91713492  0.90796045  0.9076788   0.91317857
  0.91148739  0.88228751  0.88954306  0.87048212],0.893992482327
macro f1 scores = [ 0.85405003  0.88789418  0.91821308  0.90876202  0.90819426  0.91258663
  0.91235146  0.88335188  0.89039876  0.87123095],0.894703324177
weighted average precision scores = [ 0.85957098  0.89142142  0.92013727  0.91087323  0.90981465  0.91520495
  0.91519102  0.88777538  0.89435366  0.87675027],0.898109284179
weighted average recall scores = [ 0.85957098  0.89142142  0.92013727  0.91087323  0.90981465  0.91520495
  0.91519102  0.88777538  0.89435366  0.87675027],0.898109284179
weighted f1 scores = [ 0.85789535  0.88958559  0.9189457   0.91031625  0.90903335  0.91427937
  0.91453913  0.8865626   0.89287406  0.87460806],0.896863946234
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.897113850531 recall  0.893992482327 f1  0.894703324177
loaded (189246) terms
vectorizing done, 189246 terms vocabulary tokenized
vectorizing done, 189246 terms vocabulary tokenized
accuracy scores = [ 0.88107822  0.90851401  0.93809524  0.93273305  0.92841994  0.91927775
  0.934644    0.90744681  0.91746539  0.89285714],0.916053154727
macro precision scores = [ 0.87998078  0.91102133  0.93958509  0.93362161  0.92988594  0.91756499
  0.93479827  0.90694698  0.91807145  0.89341397],0.916489042247
macro recall scores = [ 0.87422598  0.90489014  0.93669374  0.93178194  0.9273309   0.91642067
  0.93216996  0.90295417  0.91485563  0.89012115],0.913144427187
macro f1 scores = [ 0.87528354  0.9065242   0.93755865  0.93236862  0.92797575  0.91636548
  0.93306717  0.90387133  0.91604189  0.89081053],0.913986718246
weighted average precision scores = [ 0.88154589  0.91054148  0.93846497  0.93355661  0.92866705  0.92025593
  0.93516403  0.90822741  0.9186736   0.89527474],0.917037172881
weighted average recall scores = [ 0.88154589  0.91054148  0.93846497  0.93355661  0.92866705  0.92025593
  0.93516403  0.90822741  0.9186736   0.89527474],0.917037172881
weighted f1 scores = [ 0.87982953  0.90840608  0.93774686  0.93281449  0.92798425  0.91920846
  0.93454599  0.90695499  0.9176855   0.89309127],0.915826740747
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.916489042247 recall  0.913144427187 f1  0.913986718246
loaded (74123) terms
extended to (92329) terms
done loading vocabulary
vectorizing done, 92329 terms vocabulary tokenized
vectorizing done, 92329 terms vocabulary tokenized
accuracy scores = [ 0.8551797   0.89000529  0.92116402  0.91631356  0.9135737   0.91768455
  0.91710946  0.89042553  0.89563365  0.88006397],0.899715342825
macro precision scores = [ 0.85364711  0.89143577  0.92201457  0.91576554  0.91439946  0.91588703
  0.91676966  0.89014272  0.89578997  0.87917862],0.899503045078
macro recall scores = [ 0.84919863  0.8870677   0.91915018  0.91363387  0.91186623  0.91601346
  0.91327501  0.88524839  0.89361682  0.87610341],0.896517369842
macro f1 scores = [ 0.84985553  0.8881768   0.92000764  0.91433503  0.91249853  0.91533465
  0.91428423  0.88634114  0.89411731  0.87657807],0.897152893784
weighted average precision scores = [ 0.85556737  0.89191984  0.92181701  0.91690036  0.91392429  0.91834614
  0.91724431  0.89065121  0.89769661  0.88195383],0.900602096529
weighted average recall scores = [ 0.85556737  0.89191984  0.92181701  0.91690036  0.91392429  0.91834614
  0.91724431  0.89065121  0.89769661  0.88195383],0.900602096529
weighted f1 scores = [ 0.85395021  0.89004036  0.92094324  0.9162471   0.91320817  0.91739315
  0.91658829  0.88944939  0.8961111   0.87992844],0.899385946703
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.899503045078 recall  0.896517369842 f1  0.897152893784
loaded (160095) terms
vectorizing done, 160095 terms vocabulary tokenized
vectorizing done, 160095 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90851401  0.93492063  0.93061441  0.92629905  0.92033988
  0.9325186   0.90638298  0.91799787  0.89658849],0.915578268172
macro precision scores = [ 0.88010695  0.91134111  0.93594496  0.93129369  0.9275059   0.91873012
  0.93287405  0.90594061  0.91859463  0.89665216],0.915898417645
macro recall scores = [ 0.87474145  0.90575089  0.93377212  0.92971733  0.92429819  0.9180288
  0.93028385  0.90168497  0.91566208  0.89412065],0.912806033218
macro f1 scores = [ 0.87557708  0.90739563  0.9343923   0.93012534  0.92501399  0.91785038
  0.93112482  0.90260204  0.91669845  0.89459359],0.913537360273
weighted average precision scores = [ 0.88189091  0.91028166  0.93512646  0.93142655  0.92662979  0.92117101
  0.933133    0.9070169   0.91932512  0.89849888],0.916450027873
weighted average recall scores = [ 0.88189091  0.91028166  0.93512646  0.93142655  0.92662979  0.92117101
  0.933133    0.9070169   0.91932512  0.89849888],0.916450027873
weighted f1 scores = [ 0.88023271  0.90849377  0.93457847  0.93064208  0.9257229   0.92026279
  0.93242889  0.90571641  0.91826327  0.89672538],0.915306666324
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.915898417645 recall  0.912806033218 f1  0.913537360273
loaded (44972) terms
extended to (54679) terms
done loading vocabulary
vectorizing done, 54679 terms vocabulary tokenized
vectorizing done, 54679 terms vocabulary tokenized
accuracy scores = [ 0.83086681  0.86885246  0.90899471  0.89512712  0.88653234  0.89166224
  0.90116897  0.87712766  0.87167199  0.84328358],0.877528788128
macro precision scores = [ 0.8285574   0.87025763  0.90938718  0.8955003   0.8882063   0.88944369
  0.90101475  0.87668971  0.87088147  0.84161524],0.877155366396
macro recall scores = [ 0.82394688  0.86553523  0.90697764  0.89288417  0.88483272  0.88794934
  0.89780112  0.8708701   0.86822812  0.8376899 ],0.873671521928
macro f1 scores = [ 0.82413913  0.86675602  0.90757791  0.89375383  0.88561088  0.88790958
  0.89880192  0.87221883  0.8689021   0.83819548],0.874386568265
weighted average precision scores = [ 0.83124758  0.87110501  0.90972629  0.89602391  0.88706239  0.89196702
  0.9022656   0.87760257  0.87273378  0.84495299],0.878468714126
weighted average recall scores = [ 0.83124758  0.87110501  0.90972629  0.89602391  0.88706239  0.89196702
  0.9022656   0.87760257  0.87273378  0.84495299],0.878468714126
weighted f1 scores = [ 0.82927016  0.86900586  0.90878701  0.89514808  0.88597251  0.89107685
  0.90119512  0.87612054  0.87159074  0.84272666],0.877089352651
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.877155366396 recall  0.873671521928 f1  0.874386568265
loaded (190103) terms
vectorizing done, 190103 terms vocabulary tokenized
vectorizing done, 190103 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90904283  0.93862434  0.93273305  0.92841994  0.91927775
  0.934644    0.90691489  0.91853035  0.89285714],0.916265105759
macro precision scores = [ 0.88042911  0.91143468  0.94012742  0.93362161  0.92988594  0.91756499
  0.93476834  0.90641588  0.91928421  0.89341397],0.916694617099
macro recall scores = [ 0.87473103  0.90540034  0.93719879  0.93178194  0.9273309   0.91642067
  0.93218574  0.9024387   0.91603689  0.89012115],0.913364616142
macro f1 scores = [ 0.87575308  0.90698087  0.93806929  0.93236862  0.92797575  0.91636548
  0.93308598  0.90335641  0.91724088  0.89081053],0.914200688988
weighted average precision scores = [ 0.88201093  0.91106792  0.93902794  0.93355661  0.92866705  0.92025593
  0.93512622  0.90766956  0.91974407  0.89527474],0.917240097562
weighted average recall scores = [ 0.88201093  0.91106792  0.93902794  0.93355661  0.92866705  0.92025593
  0.93512622  0.90766956  0.91974407  0.89527474],0.917240097562
weighted f1 scores = [ 0.88031872  0.90893559  0.93827941  0.93281449  0.92798425  0.91920846
  0.93455411  0.90641861  0.91875436  0.89309127],0.916035925221
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.916694617099 recall  0.913364616142 f1  0.914200688988
loaded (74980) terms
extended to (93374) terms
done loading vocabulary
vectorizing done, 93374 terms vocabulary tokenized
vectorizing done, 93374 terms vocabulary tokenized
accuracy scores = [ 0.85623679  0.89053411  0.92116402  0.91472458  0.9135737   0.91662241
  0.91710946  0.88829787  0.89403621  0.87793177],0.899023091366
macro precision scores = [ 0.8546679   0.8918923   0.92220769  0.91414865  0.91445937  0.91479293
  0.91678673  0.88823562  0.89414619  0.87723034],0.898856771918
macro recall scores = [ 0.84992023  0.88757801  0.91915533  0.91210799  0.91190032  0.91471981
  0.91326975  0.88279529  0.89193061  0.87393978],0.895731712242
macro f1 scores = [ 0.85052429  0.88868069  0.92002345  0.91279951  0.9124913   0.91411638
  0.91428769  0.88398891  0.89242711  0.87447975],0.896381908167
weighted average precision scores = [ 0.85664547  0.89239799  0.92200758  0.91521103  0.91397958  0.91729099
  0.91725811  0.8887475   0.89613706  0.88005575],0.899973105682
weighted average recall scores = [ 0.85664547  0.89239799  0.92200758  0.91521103  0.91397958  0.91729099
  0.91725811  0.8887475   0.89613706  0.88005575],0.899973105682
weighted f1 scores = [ 0.85487051  0.89056496  0.92095181  0.91464563  0.91317952  0.91631079
  0.91659265  0.88730032  0.89450593  0.8778691 ],0.898679122363
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.898856771918 recall  0.895731712242 f1  0.896381908167
loaded (98215) terms
vectorizing done, 98215 terms vocabulary tokenized
vectorizing done, 98215 terms vocabulary tokenized
accuracy scores = [ 0.87684989  0.89952406  0.93280423  0.93114407  0.92311771  0.91396707
  0.93198725  0.90531915  0.90894569  0.8880597 ],0.911171882443
macro precision scores = [ 0.87700786  0.90239969  0.933697    0.93197066  0.92470545  0.91253261
  0.93185537  0.90536987  0.9102584   0.88961315],0.911941006519
macro recall scores = [ 0.86908977  0.89676184  0.93112142  0.93015804  0.92114494  0.91059603
  0.92972388  0.90100351  0.90614011  0.88552471],0.90812642455
macro f1 scores = [ 0.86985467  0.89832225  0.93196745  0.93079354  0.92193669  0.91064558
  0.93038243  0.90204305  0.90754412  0.88654592],0.909003569835
weighted average precision scores = [ 0.87776571  0.90200766  0.93304653  0.93200466  0.92348769  0.91410073
  0.93249042  0.90645422  0.91090136  0.89064513],0.912290411447
weighted average recall scores = [ 0.87776571  0.90200766  0.93304653  0.93200466  0.92348769  0.91410073
  0.93249042  0.90645422  0.91090136  0.89064513],0.912290411447
weighted f1 scores = [ 0.87489567  0.89970667  0.93253423  0.93130046  0.92249235  0.91326654
  0.93187081  0.90489767  0.90931648  0.88832512],0.910860599425
ng20_raw_stems_unigrams_stopwords_df1_tf1  -->  precision  0.911941006519 recall  0.90812642455 f1  0.909003569835
loaded (1390308) terms
vectorizing done, 1390308 terms vocabulary tokenized
vectorizing done, 1390308 terms vocabulary tokenized
accuracy scores = [ 0.88636364  0.90851401  0.93915344  0.9375      0.9300106   0.91980882
  0.93730074  0.90851064  0.91320554  0.89285714],0.917322457229
macro precision scores = [ 0.88545496  0.910762    0.94063917  0.93819297  0.93133672  0.91946699
  0.9384447   0.90891253  0.91487048  0.89526372],0.918334423579
macro recall scores = [ 0.87868445  0.90526524  0.93813511  0.9364876   0.92826092  0.91677691
  0.93514533  0.90436497  0.91105457  0.89082933],0.914500442971
macro f1 scores = [ 0.87957446  0.90669493  0.93890924  0.9370975   0.92916196  0.91715118
  0.93633621  0.90564903  0.91230127  0.89182218],0.9154697962
weighted average precision scores = [ 0.88652017  0.91019588  0.93947028  0.93818626  0.9309552   0.92054653
  0.93796119  0.90943101  0.9146272   0.89613653],0.918403023615
weighted average recall scores = [ 0.88652017  0.91019588  0.93947028  0.93818626  0.9309552   0.92054653
  0.93796119  0.90943101  0.9146272   0.89613653],0.918403023615
weighted f1 scores = [ 0.88448706  0.90828673  0.93886574  0.93759934  0.9299424   0.9193494
  0.93723432  0.90814337  0.91331525  0.89328863],0.917051223446
ng20_raw_stems_bigrams_stopwords_df1_tf1  -->  precision  0.918334423579 recall  0.914500442971 f1  0.9154697962
loaded (154264) terms
vectorizing done, 154264 terms vocabulary tokenized
vectorizing done, 154264 terms vocabulary tokenized
accuracy scores = [ 0.87843552  0.90692755  0.93439153  0.93008475  0.9252386   0.91768455
  0.93411265  0.90904255  0.90947817  0.8891258 ],0.913452166298
macro precision scores = [ 0.87681112  0.90934288  0.93493311  0.93087813  0.92678109  0.91596115
  0.93360127  0.90900201  0.9100777   0.89025772],0.913764616244
macro recall scores = [ 0.87007254  0.90371632  0.93315743  0.92894661  0.92346755  0.91401285
  0.93169463  0.90528295  0.90624169  0.8862837 ],0.910287627217
macro f1 scores = [ 0.87016755  0.90524909  0.93367393  0.92964246  0.92424729  0.91416355
  0.93229583  0.90626045  0.90757721  0.88719488],0.911047224168
weighted average precision scores = [ 0.87852617  0.90892996  0.93459044  0.93093906  0.92549537  0.91763424
  0.93450537  0.90984089  0.91112558  0.8916024 ],0.914318948076
weighted average recall scores = [ 0.87852617  0.90892996  0.93459044  0.93093906  0.92549537  0.91763424
  0.93450537  0.90984089  0.91112558  0.8916024 ],0.914318948076
weighted f1 scores = [ 0.87602552  0.90688864  0.93413668  0.93024432  0.92463732  0.91697417
  0.93398321  0.90870275  0.90976536  0.88929399],0.913065196493
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.913764616244 recall  0.910287627217 f1  0.911047224168
loaded (56049) terms
extended to (71625) terms
done loading vocabulary
vectorizing done, 71625 terms vocabulary tokenized
vectorizing done, 71625 terms vocabulary tokenized
accuracy scores = [ 0.85835095  0.89000529  0.92116402  0.9157839   0.91092259  0.91662241
  0.92082891  0.88882979  0.88764643  0.86833689],0.897849116961
macro precision scores = [ 0.85735848  0.89176562  0.92315361  0.91616341  0.91233602  0.91628401
  0.9216193   0.889046    0.88873846  0.86824014],0.898470505627
macro recall scores = [ 0.85172861  0.88693094  0.91890093  0.91408804  0.90971501  0.91400138
  0.9176164   0.88389885  0.88503381  0.86399913],0.894591310207
macro f1 scores = [ 0.85230167  0.88820745  0.92021225  0.91468773  0.91018291  0.9141729
  0.91877618  0.88505688  0.88621393  0.86481256],0.895462446014
weighted average precision scores = [ 0.8590914   0.89195431  0.92198205  0.91704655  0.91134907  0.91761377
  0.92164642  0.89015778  0.89014622  0.87118413],0.899217169924
weighted average recall scores = [ 0.8590914   0.89195431  0.92198205  0.91704655  0.91134907  0.91761377
  0.92164642  0.89015778  0.89014622  0.87118413],0.899217169924
weighted f1 scores = [ 0.85685927  0.89001957  0.9208433   0.9159805   0.91038214  0.91620706
  0.92054597  0.88824457  0.88824991  0.86845252],0.897578479187
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.898470505627 recall  0.894591310207 f1  0.895462446014
loaded (107010) terms
vectorizing done, 107010 terms vocabulary tokenized
vectorizing done, 107010 terms vocabulary tokenized
accuracy scores = [ 0.87579281  0.90322581  0.93227513  0.93114407  0.92364793  0.91662241
  0.9314559   0.90851064  0.90841321  0.88859275],0.911968065389
macro precision scores = [ 0.87563853  0.90522428  0.93285053  0.93183984  0.92525984  0.91514972
  0.93137183  0.90936039  0.90974404  0.89021589],0.91266548881
macro recall scores = [ 0.8682323   0.89944696  0.93067679  0.93001154  0.92166556  0.91300285
  0.92907958  0.90423293  0.90564053  0.88603491],0.908802395292
macro f1 scores = [ 0.86913417  0.90090878  0.93135041  0.93065927  0.92243762  0.91311759
  0.92978137  0.90548637  0.9069891   0.88716666],0.909703133619
weighted average precision scores = [ 0.87644338  0.90552438  0.9324792   0.93189626  0.92405264  0.91668852
  0.93199727  0.90975785  0.91052804  0.89113481],0.913050235073
weighted average recall scores = [ 0.87644338  0.90552438  0.9324792   0.93189626  0.92405264  0.91668852
  0.93199727  0.90975785  0.91052804  0.89113481],0.913050235073
weighted f1 scores = [ 0.87396168  0.90320614  0.93200029  0.9312539   0.92300195  0.91586745
  0.93132056  0.9080523   0.90882044  0.88890612],0.911639082762
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.91266548881 recall  0.908802395292 f1  0.909703133619
loaded (8795) terms
extended to (13569) terms
done loading vocabulary
vectorizing done, 13569 terms vocabulary tokenized
vectorizing done, 13569 terms vocabulary tokenized
accuracy scores = [ 0.77854123  0.82866208  0.85396825  0.85699153  0.83828208  0.84439724
  0.86344315  0.83670213  0.81309904  0.79051173],0.830459844795
macro precision scores = [ 0.77726256  0.83094457  0.85407982  0.85647886  0.83855076  0.84319089
  0.8628984   0.8362425   0.81327378  0.79101568],0.830393782222
macro recall scores = [ 0.77139358  0.82451692  0.84978702  0.85434987  0.83657872  0.84179337
  0.85933404  0.82906629  0.80964386  0.7845024 ],0.82609660633
macro f1 scores = [ 0.77112358  0.82615805  0.85065889  0.85509587  0.83638929  0.84157302
  0.86024397  0.82995225  0.81002226  0.78569777],0.826691493644
weighted average precision scores = [ 0.77883083  0.83177726  0.85466731  0.85740007  0.83806811  0.84378539
  0.86430504  0.83710755  0.81504113  0.79540703],0.831638972285
weighted average recall scores = [ 0.77883083  0.83177726  0.85466731  0.85740007  0.83806811  0.84378539
  0.86430504  0.83710755  0.81504113  0.79540703],0.831638972285
weighted f1 scores = [ 0.7761456   0.82886366  0.85316862  0.85688775  0.83709181  0.84321279
  0.86312797  0.83481651  0.81266309  0.79090048],0.829687828465
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.830393782222 recall  0.82609660633 f1  0.826691493644
loaded (146536) terms
vectorizing done, 146536 terms vocabulary tokenized
vectorizing done, 146536 terms vocabulary tokenized
accuracy scores = [ 0.87473573  0.90692755  0.93439153  0.92955508  0.92576882  0.91715348
  0.93304995  0.90691489  0.90894569  0.89072495],0.912816767556
macro precision scores = [ 0.8740337   0.90961635  0.93529912  0.93050068  0.92748956  0.91583753
  0.93260527  0.90771064  0.91027484  0.89289554],0.913626323155
macro recall scores = [ 0.86709861  0.90343287  0.93262463  0.92875125  0.92356602  0.91347303
  0.9304751   0.90295409  0.90627926  0.88835652],0.909701138085
macro f1 scores = [ 0.86769023  0.9050176   0.93344143  0.92934392  0.92456104  0.91373924
  0.93113946  0.90416896  0.90764227  0.88949015],0.910623430309
weighted average precision scores = [ 0.87496088  0.909074    0.93473602  0.93069595  0.92625912  0.9172143
  0.93363676  0.90804702  0.91073631  0.89387805],0.913923840293
weighted average recall scores = [ 0.87496088  0.909074    0.93473602  0.93069595  0.92625912  0.9172143
  0.93363676  0.90804702  0.91073631  0.89387805],0.913923840293
weighted f1 scores = [ 0.87267136  0.90679478  0.93408417  0.9298433   0.92522439  0.91643817
  0.93296697  0.90651928  0.90925611  0.89115526],0.912495378135
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.913626323155 recall  0.909701138085 f1  0.910623430309
loaded (48321) terms
extended to (56168) terms
done loading vocabulary
vectorizing done, 56168 terms vocabulary tokenized
vectorizing done, 56168 terms vocabulary tokenized
accuracy scores = [ 0.81712474  0.86462189  0.90740741  0.89036017  0.88069989  0.88635157
  0.90170032  0.87659574  0.87220447  0.84488273],0.874194893196
macro precision scores = [ 0.81379926  0.86561927  0.90966487  0.88993222  0.88206828  0.88490157
  0.90198667  0.87637476  0.87072527  0.84642502],0.874149717385
macro recall scores = [ 0.80756422  0.86023134  0.90483813  0.88844344  0.87952457  0.88358898
  0.8986036   0.87116582  0.86853803  0.84064943],0.870314755557
macro f1 scores = [ 0.80619895  0.86160559  0.90645877  0.88884916  0.87958739  0.88347951
  0.89936903  0.87249371  0.86904172  0.84165387],0.870873770689
weighted average precision scores = [ 0.81747901  0.86703806  0.90888279  0.89120054  0.88107289  0.88676886
  0.90285177  0.87724995  0.87362484  0.848764  ],0.875493270038
weighted average recall scores = [ 0.81747901  0.86703806  0.90888279  0.89120054  0.88107289  0.88676886
  0.90285177  0.87724995  0.87362484  0.848764  ],0.875493270038
weighted f1 scores = [ 0.81373174  0.8647068   0.90745818  0.89043691  0.87972498  0.88583986
  0.90151255  0.87584461  0.87233683  0.84496334],0.873655581555
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.874149717385 recall  0.870314755557 f1  0.870873770689
loaded (155386) terms
vectorizing done, 155386 terms vocabulary tokenized
vectorizing done, 155386 terms vocabulary tokenized
accuracy scores = [ 0.87896406  0.90745637  0.93439153  0.93008475  0.92629905  0.91768455
  0.93411265  0.90904255  0.91001065  0.8891258 ],0.913717195169
macro precision scores = [ 0.8777722   0.90977322  0.93493311  0.93091424  0.92782981  0.91596115
  0.93350195  0.90900201  0.91083473  0.89058706],0.914110948445
macro recall scores = [ 0.87114964  0.90422652  0.93315743  0.92894146  0.92448796  0.91401285
  0.93165023  0.90528295  0.90688588  0.88656932],0.910636424365
macro f1 scores = [ 0.87158059  0.90571891  0.93367393  0.92965273  0.92535516  0.91416355
  0.93222515  0.90626045  0.90828861  0.88748675],0.911440581068
weighted average precision scores = [ 0.87922647  0.90937978  0.93459044  0.9309779   0.92657906  0.91763424
  0.93451832  0.90984089  0.91160934  0.89176868],0.914612513496
weighted average recall scores = [ 0.87922647  0.90937978  0.93459044  0.9309779   0.92657906  0.91763424
  0.93451832  0.90984089  0.91160934  0.89176868],0.914612513496
weighted f1 scores = [ 0.87691269  0.90737763  0.93413668  0.9302582   0.92578576  0.91697417
  0.93398996  0.90870275  0.91028766  0.88936289],0.913378838696
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.914110948445 recall  0.910636424365 f1  0.911440581068
loaded (57171) terms
extended to (72894) terms
done loading vocabulary
vectorizing done, 72894 terms vocabulary tokenized
vectorizing done, 72894 terms vocabulary tokenized
accuracy scores = [ 0.85623679  0.89000529  0.92063492  0.9157839   0.90986214  0.91715348
  0.92029756  0.88829787  0.88711395  0.87153518],0.897692107459
macro precision scores = [ 0.85535459  0.89186124  0.92273767  0.91599893  0.91120164  0.91664892
  0.92050401  0.8892357   0.88795503  0.87194711],0.898344483195
macro recall scores = [ 0.84944161  0.8869363   0.91840608  0.91409341  0.90868934  0.91480544
  0.91727485  0.88336945  0.88424314  0.86778629],0.894504592461
macro f1 scores = [ 0.85009646  0.88823327  0.91973264  0.9146774   0.90911385  0.91482463
  0.91822114  0.88472537  0.88546384  0.8684912 ],0.895357979991
weighted average precision scores = [ 0.85749758  0.89175252  0.92154546  0.91687423  0.91016618  0.91830263
  0.92095044  0.88991547  0.88951174  0.87448595],0.899100219704
weighted average recall scores = [ 0.85749758  0.89175252  0.92154546  0.91687423  0.91016618  0.91830263
  0.92095044  0.88991547  0.88951174  0.87448595],0.899100219704
weighted f1 scores = [ 0.85488447  0.88991361  0.92033513  0.91596653  0.90927163  0.91685717
  0.92005649  0.88773487  0.88770087  0.87164986],0.897437062509
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.898344483195 recall  0.894504592461 f1  0.895357979991
loaded (183740) terms
vectorizing done, 183740 terms vocabulary tokenized
vectorizing done, 183740 terms vocabulary tokenized
accuracy scores = [ 0.88054968  0.90798519  0.93597884  0.93432203  0.92576882  0.91874668
  0.9357067   0.90904255  0.91107561  0.88965885],0.914883495867
macro precision scores = [ 0.87895145  0.91025248  0.93657977  0.93562718  0.9276028   0.91709334
  0.93538352  0.90918041  0.91180512  0.89113661],0.915361267275
macro recall scores = [ 0.87237124  0.90473157  0.93467258  0.93343253  0.92410858  0.91518303
  0.93316033  0.90528295  0.90790629  0.88678339],0.911763249568
macro f1 scores = [ 0.87261526  0.90621156  0.93524151  0.93420663  0.92496664  0.91544248
  0.93386915  0.90631123  0.90927624  0.88782738],0.912596806575
weighted average precision scores = [ 0.8805343   0.90989139  0.93617029  0.93552305  0.92630607  0.9186367
  0.93617759  0.9100358   0.91261815  0.89254962],0.915844295784
weighted average recall scores = [ 0.8805343   0.90989139  0.93617029  0.93552305  0.92630607  0.9186367
  0.93617759  0.9100358   0.91261815  0.89254962],0.915844295784
weighted f1 scores = [ 0.87825344  0.90789831  0.93570872  0.93459621  0.92529603  0.9181078
  0.93557824  0.90876035  0.91131635  0.88997511],0.914549057104
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.915361267275 recall  0.911763249568 f1  0.912596806575
loaded (85525) terms
extended to (101923) terms
done loading vocabulary
vectorizing done, 101923 terms vocabulary tokenized
vectorizing done, 101923 terms vocabulary tokenized
accuracy scores = [ 0.85887949  0.89370703  0.92275132  0.91525424  0.91781548  0.91927775
  0.9218916   0.88882979  0.89084132  0.87366738],0.900291540659
macro precision scores = [ 0.85923102  0.89622689  0.92450702  0.91544905  0.91922563  0.91809467
  0.92244267  0.88954796  0.89190556  0.87395264],0.901058311232
macro recall scores = [ 0.85193002  0.89070707  0.92013789  0.91343411  0.91611288  0.91643474
  0.91895171  0.88459942  0.88823098  0.86956495],0.897010376749
macro f1 scores = [ 0.85253403  0.89220743  0.92146908  0.91400806  0.9168173   0.91651997
  0.91997625  0.88585944  0.88936769  0.87030954],0.897906879129
weighted average precision scores = [ 0.86039182  0.89565282  0.9234226   0.91649886  0.91820796  0.91969572
  0.92276267  0.89004713  0.89343272  0.87663969],0.901675198293
weighted average recall scores = [ 0.86039182  0.89565282  0.9234226   0.91649886  0.91820796  0.91969572
  0.92276267  0.89004713  0.89343272  0.87663969],0.901675198293
weighted f1 scores = [ 0.85712543  0.89365845  0.92234019  0.91545417  0.91730774  0.91878111
  0.92172345  0.88837227  0.89145635  0.87371273],0.899993187676
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.901058311232 recall  0.897010376749 f1  0.897906879129
loaded (150588) terms
vectorizing done, 150588 terms vocabulary tokenized
vectorizing done, 150588 terms vocabulary tokenized
accuracy scores = [ 0.87526427  0.90904283  0.93227513  0.93167373  0.92735949  0.91768455
  0.9335813   0.90638298  0.91001065  0.88965885],0.913293377656
macro precision scores = [ 0.87432555  0.91131276  0.932926    0.93263325  0.92909334  0.91640169
  0.93304578  0.90704105  0.9113614   0.89127788],0.913941869628
macro recall scores = [ 0.86760903  0.90533256  0.93054961  0.93064063  0.92523808  0.9139885
  0.93098531  0.9021759   0.90744944  0.88690071],0.910086977276
macro f1 scores = [ 0.86806292  0.90685914  0.93127446  0.93130899  0.92616569  0.91428662
  0.93165386  0.90336579  0.90881172  0.88799879],0.91097879833
weighted average precision scores = [ 0.87549695  0.91114974  0.93254799  0.93296947  0.92791981  0.91776565
  0.93410989  0.90759008  0.91182276  0.89262889],0.914400122525
weighted average recall scores = [ 0.87549695  0.91114974  0.93254799  0.93296947  0.92791981  0.91776565
  0.93410989  0.90759008  0.91182276  0.89262889],0.914400122525
weighted f1 scores = [ 0.87317149  0.90891633  0.93198483  0.93199438  0.92681582  0.91698597
  0.93351003  0.90597921  0.9103657   0.89004894],0.912977269538
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.913941869628 recall  0.910086977276 f1  0.91097879833
loaded (52373) terms
extended to (61221) terms
done loading vocabulary
vectorizing done, 61221 terms vocabulary tokenized
vectorizing done, 61221 terms vocabulary tokenized
accuracy scores = [ 0.81976744  0.86409307  0.91058201  0.89036017  0.88971368  0.89219331
  0.90010627  0.88138298  0.87380192  0.84328358],0.876528443035
macro precision scores = [ 0.81760054  0.86637154  0.91195891  0.89012748  0.89138222  0.89083163
  0.90015093  0.88096189  0.87344043  0.84335151],0.876617707799
macro recall scores = [ 0.81144079  0.86017685  0.90786797  0.88832324  0.88816396  0.88892925
  0.89666083  0.8765456   0.87013989  0.83810692],0.872635530639
macro f1 scores = [ 0.81095291  0.86190756  0.90928174  0.88894916  0.88857897  0.88888178
  0.8975221   0.87771251  0.87100718  0.83889265],0.873368654987
weighted average precision scores = [ 0.82065662  0.86712196  0.91158801  0.89126218  0.89000012  0.89267292
  0.90116936  0.8819117   0.87562872  0.84595721],0.877796880324
weighted average recall scores = [ 0.82065662  0.86712196  0.91158801  0.89126218  0.89000012  0.89267292
  0.90116936  0.8819117   0.87562872  0.84595721],0.877796880324
weighted f1 scores = [ 0.81725747  0.86444003  0.91053462  0.89053419  0.88879374  0.89150157
  0.89993609  0.8807385   0.87396725  0.8428222 ],0.876052567136
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.876617707799 recall  0.872635530639 f1  0.873368654987
loaded (184632) terms
vectorizing done, 184632 terms vocabulary tokenized
vectorizing done, 184632 terms vocabulary tokenized
accuracy scores = [ 0.88107822  0.90745637  0.93597884  0.93432203  0.92629905  0.91874668
  0.93623804  0.90904255  0.91160809  0.89072495],0.915149483093
macro precision scores = [ 0.87972796  0.90966679  0.93657977  0.93562718  0.92814097  0.91713424
  0.93583428  0.90918041  0.9123428   0.89239485],0.915662925223
macro recall scores = [ 0.87316489  0.90422652  0.93467258  0.93343253  0.92461363  0.91518303
  0.93367579  0.90528295  0.9084165   0.88810004],0.912076847017
macro f1 scores = [ 0.87359071  0.90567714  0.93524151  0.93420663  0.92547821  0.91546676
  0.93436702  0.90631123  0.90980928  0.88910054],0.912924902
weighted average precision scores = [ 0.88113961  0.90928814  0.93617029  0.93552305  0.92686584  0.91866873
  0.93664651  0.9100358   0.91317931  0.89367636],0.91611936411
weighted average recall scores = [ 0.88113961  0.90928814  0.93617029  0.93552305  0.92686584  0.91866873
  0.93664651  0.9100358   0.91317931  0.89367636],0.91611936411
weighted f1 scores = [ 0.87895125  0.90734377  0.93570872  0.93459621  0.92583059  0.918128
  0.9360937   0.90876035  0.91187267  0.89105861],0.914834387421
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.915662925223 recall  0.912076847017 f1  0.912924902
loaded (86417) terms
extended to (102936) terms
done loading vocabulary
vectorizing done, 102936 terms vocabulary tokenized
vectorizing done, 102936 terms vocabulary tokenized
accuracy scores = [ 0.85729387  0.89370703  0.92275132  0.91790254  0.91781548  0.91980882
  0.91976621  0.88882979  0.88817891  0.87473348],0.90007874482
macro precision scores = [ 0.85747824  0.89622671  0.92463016  0.91836418  0.91925733  0.91896922
  0.92015173  0.88973186  0.88961715  0.87524084],0.900966742694
macro recall scores = [ 0.85012111  0.89071233  0.92014294  0.91608477  0.91615213  0.91693979
  0.91674107  0.88430807  0.88552492  0.87084195],0.896756909564
macro f1 scores = [ 0.8505207   0.89221357  0.92152219  0.91675936  0.91682215  0.91703868
  0.91777437  0.88564616  0.88682812  0.8716368 ],0.897676210026
weighted average precision scores = [ 0.85890246  0.89563761  0.92355047  0.91927837  0.91823448  0.92082543
  0.92054862  0.88987282  0.89085128  0.8776473 ],0.901534883911
weighted average recall scores = [ 0.85890246  0.89563761  0.92355047  0.91927837  0.91823448  0.92082543
  0.92054862  0.88987282  0.89085128  0.8776473 ],0.901534883911
weighted f1 scores = [ 0.85540402  0.89365453  0.92239293  0.91812854  0.91728927  0.91944596
  0.91960459  0.88819461  0.88880056  0.87478768],0.899770269096
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.900966742694 recall  0.896756909564 f1  0.897676210026
done!

