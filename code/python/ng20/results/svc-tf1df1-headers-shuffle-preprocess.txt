IPython Notebookng20_classifier Last Checkpoint: Dec 24 16:51 (autosaved)
File
Edit
View
Insert
Cell
Kernel
Help
 Cell Toolbar:
Classify 20ng docs
Classifiy 20ng docs using unigrams and bigrams features with different classifiers and report classification results
In [91]:

def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = CountVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    # generate tfidf vectors
    transformer = TfidfTransformer()
    corpus_tfidf_vectors = transformer.fit_transform(corpus_vectors)
 
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-91-743655218ee8>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
In [92]:

def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import TfidfVectorizer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = TfidfVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_tfidf_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-92-f88374f887f0>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
In [93]:

# given classifier predictions probabilities, return predictions with top n probabilities > 0.5 for each instance or greatest one if all are <=0.5
def get_max_n_pred(pred_proba, n_pred, threshold):
    import heapq
    import numpy
    max_n_pred = numpy.ndarray(shape=pred_proba.shape)
    for i in range(len(pred_proba)):
        largest_n_proba = heapq.nlargest(n_pred,pred_proba[i])
        max_n_pred[i] = numpy.array(((pred_proba[i]>threshold) & (pred_proba[i]>=largest_n_proba[len(largest_n_proba)-1]) & 1))
        if max_n_pred[i].sum(axis=0)==0: # at least one label should be returned
            max_n_pred[i] = numpy.array(((pred_proba[i]>=max(pred_proba[i])) & 1))
    return max_n_pred
In [94]:

# reference: http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification
def classify(x_train,y_train,x_test,y_test,max_labels):
    from sklearn.preprocessing import MultiLabelBinarizer
    from sklearn.multiclass import OneVsRestClassifier
    from sklearn.svm import SVC
    from sklearn.svm import LinearSVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.preprocessing import binarize
    from sklearn.cross_validation import train_test_split
    from sklearn import metrics
    import numpy
        
    # binarize the labels
    #mlb = MultiLabelBinarizer()
    #y_train_binarized = mlb.fit_transform(y_train)
    
    # train/test split
    #corpus_tfidf_vectors, labels_binarized = shuffle(corpus_tfidf_vectors, labels_binarized)
    #x_train, x_test, y_train, y_test = train_test_split(corpus_tfidf_vectors, labels_binarized, test_size=test_size, random_state=1)
    
    # classify
    #cls = OneVsRestClassifier(LogisticRegression(class_weight='auto'))
    #cls = OneVsRestClassifier(LogisticRegression())
    #cls = MultinomialNB(alpha=0.01)
    #cls = OneVsRestClassifier(BernoulliNB()need binarize(x_train and x_test))
    #cls = OneVsRestClassifier(SVC(kernel='linear',probability=True,max_iter=1000))
    #cls = OneVsRestClassifier(SVC(kernel='linear'))
    cls = LinearSVC()
    cls.fit(x_train, y_train)
    y_train_pred = cls.predict(x_train)
    print 'training F1: ', metrics.f1_score(y_train, y_train_pred, average='micro')
    print 'training accuracy: ', metrics.accuracy_score(y_train, y_train_pred)
    #pred_proba = 1/(1+numpy.exp(-1*cls.decision_function(x_test)))
    #threshold = 0.45#1/(1+numpy.exp(-1))
    #y_pred = mlb.inverse_transform(get_max_n_pred(pred_proba, max_labels,threshold))
    #y_pred = mlb.inverse_transform(cls.predict(x_test))
    y_pred = cls.predict(x_test)
    print 'testing accuracy: ', metrics.f1_score(y_test, y_pred)
    # evaluate
    #pred_proba = cls.predict_proba(x_test)
    #print len(pred_proba[0]) # make sure it is 121
    #actual_labels = mlb.inverse_transform(y_test)
    #precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred, pos_label=0)
    #print precision
    #print recall
    #print thresholds
    return {'precision':metrics.precision_score(y_test, y_pred, average='micro'),
            'recall':metrics.recall_score(y_test, y_pred, average='micro'),
            'f1':metrics.f1_score(y_test, y_pred, average='micro')}
In [95]:

import sklearn
from sklearn.svm import LinearSVC
c = LinearSVC()
print sklearn.__version__
0.15.2
In [96]:

def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_unigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-96-5bcc0f6a848c>:1: SyntaxWarning: import * only allowed at module level
  def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [97]:

def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-97-094e349cf724>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [98]:

def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_bigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-98-c28207c92f80>:1: SyntaxWarning: import * only allowed at module level
  def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [99]:

def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-99-781cd4f52dc5>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [100]:

def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    from sklearn.decomposition import TruncatedSVD
    from scipy import sparse
    import numpy
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # apply LSA
    #print numpy.max(corpus_train_tfidf_vectors)
    #print numpy.min(corpus_train_tfidf_vectors)
    lsa = TruncatedSVD(n_components=num_components)
    lsa.fit(corpus_train_tfidf_vectors)
    #corpus_train_tfidf_vectors = numpy.dot(corpus_train_tfidf_vectors,pca.components_.transpose())
    corpus_train_tfidf_vectors = lsa.transform(corpus_train_tfidf_vectors)
    corpus_test_tfidf_vectors = lsa.transform(corpus_test_tfidf_vectors)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print 'LSA ^' , vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-100-0ae0e12f66cc>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
In [101]:

def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)    
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-101-d27651528d70>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [102]:

def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-102-8129eac551f8>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [103]:

def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-103-180bdc332cbe>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [104]:

def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-104-cd1ea993b277>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [105]:

def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-105-98c5bdcd6b4f>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [106]:

def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-106-1c5602c28486>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [107]:

def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-107-c5ecc72d6e7c>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [108]:

def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-108-60ce875247ce>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [109]:

def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-109-2010f39a430e>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [110]:

def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-110-a08ffa055f62>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [111]:

def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-111-781d3020ecf2>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [112]:

def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-112-69e08236a4c4>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [113]:

def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-113-bdd713c1f2ac>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [114]:

def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-114-6b79430f2923>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [115]:

def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'stem')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-115-a650503cc609>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [116]:

def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-116-3444b80fb7e1>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [117]:

def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-117-dd4a635e1842>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [118]:

def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-118-ce43e0732809>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [119]:

def test():
    from ng20_corpus_loader import load_corpus_and_labels
    from ng20_corpus_loader import load_corpus_with_labels_mappings
    
    # load 20ng docs with class lables from DB
    corpus_train_data = load_corpus_and_labels('train')
    print 'done loading {0} train records and {1} labels.'.format(len(corpus_train_data['corpus']),len(corpus_train_data['labels_dic']))
 
    corpus_test_data = load_corpus_with_labels_mappings('test',corpus_train_data['labels_dic'])
    print 'done loading {0} test records.'.format(len(corpus_test_data['corpus']))
    
    stopwords_removal_mask = 1
    chi_features_mask = 2
    raw_tokens_mask = 4
    for i in range(4,6): # test w/o stopword removal and w/o chi square features and w/o raw tokens
        stopwords_removal = i&stopwords_removal_mask==stopwords_removal_mask
        use_chi_features = i&chi_features_mask==chi_features_mask
        use_raw_tokens = i&raw_tokens_mask==raw_tokens_mask
        
        test_all_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        #test_lemmatized_bigrams_with_LSA({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
        #                         {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
        #                         stopwords_removal,use_chi_features,use_raw_tokens,113240)
        
        test_lemmatized_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
In [120]:

# test using all vocabulary
test()
 
print 'done!'
loaded 11314 records.
done loading 11314 train records and 20 labels.
loaded 7532 records.
done loading 7532 test records.
loaded (130080) terms
vectorizing done, 130080 terms vocabulary tokenized
vectorizing done, 130080 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.848838905467
ng20_raw_unigrams  -->  precision  0.849973446628 recall  0.849973446628 f1  0.849973446628
loaded (1181775) terms
vectorizing done, 1181775 terms vocabulary tokenized
vectorizing done, 1181775 terms vocabulary tokenized
training F1:  0.999558069648
training accuracy:  0.999558069648
testing accuracy:  0.854631948301
ng20_raw_bigrams  -->  precision  0.855815188529 recall  0.855815188529 f1  0.855815188529
loaded (123923) terms
vectorizing done, 123923 terms vocabulary tokenized
vectorizing done, 123923 terms vocabulary tokenized
training F1:  0.998850981085
training accuracy:  0.998850981085
testing accuracy:  0.850827786398
ng20_raw_lemmas_unigrams_df1_tf1  -->  precision  0.851964949549 recall  0.851964949549 f1  0.851964949549
loaded (1134637) terms
vectorizing done, 1134637 terms vocabulary tokenized
vectorizing done, 1134637 terms vocabulary tokenized
training F1:  0.999469683578
training accuracy:  0.999469683578
testing accuracy:  0.855244935585
ng20_raw_lemmas_bigrams_df1_tf1  -->  precision  0.856479022836 recall  0.856479022836 f1  0.856479022836
loaded (166749) terms
done loading vocabulary
vectorizing done, 166749 terms vocabulary tokenized
vectorizing done, 166749 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.853333844434
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.854487519915 recall  0.854487519915 f1  0.854487519915
loaded (42826) terms
extended to (58589) terms
done loading vocabulary
vectorizing done, 58589 terms vocabulary tokenized
vectorizing done, 58589 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.827669804411
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.828730748805 recall  0.828730748805 f1  0.828730748805
loaded (133031) terms
done loading vocabulary
vectorizing done, 133031 terms vocabulary tokenized
vectorizing done, 133031 terms vocabulary tokenized
training F1:  0.998939367156
training accuracy:  0.998939367156
testing accuracy:  0.851162962621
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.852230483271 recall  0.852230483271 f1  0.852230483271
loaded (9108) terms
extended to (14178) terms
done loading vocabulary
vectorizing done, 14178 terms vocabulary tokenized
vectorizing done, 14178 terms vocabulary tokenized
training F1:  0.992752342231
training accuracy:  0.992752342231
testing accuracy:  0.74724599698
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.748406797663 recall  0.748406797663 f1  0.748406797663
loaded (147177) terms
vectorizing done, 147177 terms vocabulary tokenized
vectorizing done, 147177 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.853117974723
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.854089219331 recall  0.854089219331 f1  0.854089219331
loaded (23254) terms
extended to (30184) terms
done loading vocabulary
vectorizing done, 30184 terms vocabulary tokenized
vectorizing done, 30184 terms vocabulary tokenized
training F1:  0.996199398975
training accuracy:  0.996199398975
testing accuracy:  0.792961355603
ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.794211364843 recall  0.794211364843 f1  0.794211364843
loaded (169295) terms
vectorizing done, 169295 terms vocabulary tokenized
vectorizing done, 169295 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.853044342653
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.854089219331 recall  0.854089219331 f1  0.854089219331
loaded (45372) terms
extended to (61512) terms
done loading vocabulary
vectorizing done, 61512 terms vocabulary tokenized
vectorizing done, 61512 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.827997932709
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.829129049389 recall  0.829129049389 f1  0.829129049389
loaded (178442) terms
vectorizing done, 178442 terms vocabulary tokenized
vectorizing done, 178442 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.853829992567
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.855018587361 recall  0.855018587361 f1  0.855018587361
loaded (54519) terms
extended to (70907) terms
done loading vocabulary
vectorizing done, 70907 terms vocabulary tokenized
vectorizing done, 70907 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.830714598808
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.831784386617 recall  0.831784386617 f1  0.831784386617
loaded (152914) terms
vectorizing done, 152914 terms vocabulary tokenized
vectorizing done, 152914 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.853171746389
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.854221986192 recall  0.854221986192 f1  0.854221986192
loaded (28991) terms
extended to (37620) terms
done loading vocabulary
vectorizing done, 37620 terms vocabulary tokenized
vectorizing done, 37620 terms vocabulary tokenized
training F1:  0.997083259678
training accuracy:  0.997083259678
testing accuracy:  0.801911088478
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.802973977695 recall  0.802973977695 f1  0.802973977695
loaded (180871) terms
vectorizing done, 180871 terms vocabulary tokenized
vectorizing done, 180871 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.854600864179
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.855682421668 recall  0.855682421668 f1  0.855682421668
loaded (56948) terms
extended to (73692) terms
done loading vocabulary
vectorizing done, 73692 terms vocabulary tokenized
vectorizing done, 73692 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.830733073722
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.831917153478 recall  0.831917153478 f1  0.831917153478
loaded (110621) terms
vectorizing done, 110621 terms vocabulary tokenized
vectorizing done, 110621 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.845393308785
ng20_raw_stems_unigrams_df1_tf1  -->  precision  0.846654275093 recall  0.846654275093 f1  0.846654275093
loaded (1067610) terms
vectorizing done, 1067610 terms vocabulary tokenized
vectorizing done, 1067610 terms vocabulary tokenized
training F1:  0.999558069648
training accuracy:  0.999558069648
testing accuracy:  0.855055208111
ng20_raw_stems_bigrams_df1_tf1  -->  precision  0.856213489113 recall  0.856213489113 f1  0.856213489113
loaded (156475) terms
vectorizing done, 156475 terms vocabulary tokenized
vectorizing done, 156475 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.849995892198
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.851035581519 recall  0.851035581519 f1  0.851035581519
loaded (45854) terms
extended to (60119) terms
done loading vocabulary
vectorizing done, 60119 terms vocabulary tokenized
vectorizing done, 60119 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.827631747944
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.828597981944 recall  0.828597981944 f1  0.828597981944
loaded (119732) terms
vectorizing done, 119732 terms vocabulary tokenized
vectorizing done, 119732 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.848808084134
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.850106213489 recall  0.850106213489 f1  0.850106213489
loaded (9111) terms
extended to (13638) terms
done loading vocabulary
vectorizing done, 13638 terms vocabulary tokenized
vectorizing done, 13638 terms vocabulary tokenized
training F1:  0.99248718402
training accuracy:  0.99248718402
testing accuracy:  0.757051670373
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.758098778545 recall  0.758098778545 f1  0.758098778545
loaded (137246) terms
vectorizing done, 137246 terms vocabulary tokenized
vectorizing done, 137246 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.849663366431
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.850770047796 recall  0.850770047796 f1  0.850770047796
loaded (26625) terms
extended to (33168) terms
done loading vocabulary
vectorizing done, 33168 terms vocabulary tokenized
vectorizing done, 33168 terms vocabulary tokenized
training F1:  0.996906487538
training accuracy:  0.996906487538
testing accuracy:  0.795373461171
ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.796070100903 recall  0.796070100903 f1  0.796070100903
loaded (158743) terms
vectorizing done, 158743 terms vocabulary tokenized
vectorizing done, 158743 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.848735365373
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.849840679766 recall  0.849840679766 f1  0.849840679766
loaded (48122) terms
extended to (62601) terms
done loading vocabulary
vectorizing done, 62601 terms vocabulary tokenized
vectorizing done, 62601 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.828623569859
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.829660116835 recall  0.829660116835 f1  0.829660116835
loaded (170251) terms
vectorizing done, 170251 terms vocabulary tokenized
vectorizing done, 170251 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.851042751836
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.85209771641 recall  0.85209771641 f1  0.85209771641
loaded (59630) terms
extended to (74402) terms
done loading vocabulary
vectorizing done, 74402 terms vocabulary tokenized
vectorizing done, 74402 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.831076359673
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.83204992034 recall  0.83204992034 f1  0.83204992034
loaded (142775) terms
vectorizing done, 142775 terms vocabulary tokenized
vectorizing done, 142775 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.850064554135
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.85116834838 recall  0.85116834838 f1  0.85116834838
loaded (32154) terms
extended to (39872) terms
done loading vocabulary
vectorizing done, 39872 terms vocabulary tokenized
vectorizing done, 39872 terms vocabulary tokenized
training F1:  0.99752519003
training accuracy:  0.99752519003
testing accuracy:  0.8022230435
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.803505045141 recall  0.803505045141 f1  0.803505045141
loaded (172385) terms
vectorizing done, 172385 terms vocabulary tokenized
vectorizing done, 172385 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.852189937932
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.853292618163 recall  0.853292618163 f1  0.853292618163
loaded (61764) terms
extended to (76734) terms
done loading vocabulary
vectorizing done, 76734 terms vocabulary tokenized
vectorizing done, 76734 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.830362855067
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.831386086033 recall  0.831386086033 f1  0.831386086033
loaded (129726) terms
vectorizing done, 129726 terms vocabulary tokenized
vectorizing done, 129726 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.848392453081
ng20_raw_unigrams_stopwords  -->  precision  0.849575146044 recall  0.849575146044 f1  0.849575146044
loaded (1181742) terms
vectorizing done, 1181742 terms vocabulary tokenized
vectorizing done, 1181742 terms vocabulary tokenized
training F1:  0.999292911437
training accuracy:  0.999292911437
testing accuracy:  0.855296469923
ng20_raw_bigrams_stopwords  -->  precision  0.856213489113 recall  0.856213489113 f1  0.856213489113
loaded (123577) terms
vectorizing done, 123577 terms vocabulary tokenized
vectorizing done, 123577 terms vocabulary tokenized
training F1:  0.998939367156
training accuracy:  0.998939367156
testing accuracy:  0.848339101599
ng20_raw_lemmas_unigrams_stopwords_df1_tf1  -->  precision  0.849442379182 recall  0.849442379182 f1  0.849442379182
loaded (1142875) terms
vectorizing done, 1142875 terms vocabulary tokenized
vectorizing done, 1142875 terms vocabulary tokenized
training F1:  0.999292911437
training accuracy:  0.999292911437
testing accuracy:  0.85419503682
ng20_raw_lemmas_bigrams_stopwords_df1_tf1  -->  precision  0.855151354222 recall  0.855151354222 f1  0.855151354222
loaded (161982) terms
done loading vocabulary
vectorizing done, 161982 terms vocabulary tokenized
vectorizing done, 161982 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.850654044835
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.851699415826 recall  0.851699415826 f1  0.851699415826
loaded (38405) terms
extended to (52994) terms
done loading vocabulary
vectorizing done, 52994 terms vocabulary tokenized
vectorizing done, 52994 terms vocabulary tokenized
training F1:  0.998409050734
training accuracy:  0.998409050734
testing accuracy:  0.824956445688
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.826075411577 recall  0.826075411577 f1  0.826075411577
loaded (129986) terms
done loading vocabulary
vectorizing done, 129986 terms vocabulary tokenized
vectorizing done, 129986 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.848503198142
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.849707912905 recall  0.849707912905 f1  0.849707912905
loaded (6409) terms
extended to (10757) terms
done loading vocabulary
vectorizing done, 10757 terms vocabulary tokenized
vectorizing done, 10757 terms vocabulary tokenized
training F1:  0.98762595015
training accuracy:  0.98762595015
testing accuracy:  0.738956974137
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.740175252257 recall  0.740175252257 f1  0.740175252257
loaded (153957) terms
vectorizing done, 153957 terms vocabulary tokenized
vectorizing done, 153957 terms vocabulary tokenized
training F1:  0.998939367156
training accuracy:  0.998939367156
testing accuracy:  0.850958142
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.851964949549 recall  0.851964949549 f1  0.851964949549
loaded (30380) terms
extended to (37524) terms
done loading vocabulary
vectorizing done, 37524 terms vocabulary tokenized
vectorizing done, 37524 terms vocabulary tokenized
training F1:  0.996376171115
training accuracy:  0.996376171115
testing accuracy:  0.790542400819
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.791556027616 recall  0.791556027616 f1  0.791556027616
loaded (162783) terms
vectorizing done, 162783 terms vocabulary tokenized
vectorizing done, 162783 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.850784869537
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.851832182687 recall  0.851832182687 f1  0.851832182687
loaded (39206) terms
extended to (53957) terms
done loading vocabulary
vectorizing done, 53957 terms vocabulary tokenized
vectorizing done, 53957 terms vocabulary tokenized
training F1:  0.998409050734
training accuracy:  0.998409050734
testing accuracy:  0.825133507083
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.826208178439 recall  0.826208178439 f1  0.826208178439
loaded (179633) terms
vectorizing done, 179633 terms vocabulary tokenized
vectorizing done, 179633 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.851556983161
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.852628783856 recall  0.852628783856 f1  0.852628783856
loaded (56056) terms
extended to (71519) terms
done loading vocabulary
vectorizing done, 71519 terms vocabulary tokenized
vectorizing done, 71519 terms vocabulary tokenized
training F1:  0.998497436804
training accuracy:  0.998497436804
testing accuracy:  0.828665549303
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.829792883696 recall  0.829792883696 f1  0.829792883696
loaded (156843) terms
vectorizing done, 156843 terms vocabulary tokenized
vectorizing done, 156843 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.850569375811
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.851699415826 recall  0.851699415826 f1  0.851699415826
loaded (33266) terms
extended to (41510) terms
done loading vocabulary
vectorizing done, 41510 terms vocabulary tokenized
vectorizing done, 41510 terms vocabulary tokenized
training F1:  0.996994873608
training accuracy:  0.996994873608
testing accuracy:  0.795070447479
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.796070100903 recall  0.796070100903 f1  0.796070100903
loaded (180279) terms
vectorizing done, 180279 terms vocabulary tokenized
vectorizing done, 180279 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.85156558974
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.852628783856 recall  0.852628783856 f1  0.852628783856
loaded (56702) terms
extended to (72310) terms
done loading vocabulary
vectorizing done, 72310 terms vocabulary tokenized
vectorizing done, 72310 terms vocabulary tokenized
training F1:  0.998497436804
training accuracy:  0.998497436804
testing accuracy:  0.827983089429
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.829129049389 recall  0.829129049389 f1  0.829129049389
loaded (110389) terms
vectorizing done, 110389 terms vocabulary tokenized
vectorizing done, 110389 terms vocabulary tokenized
training F1:  0.998939367156
training accuracy:  0.998939367156
testing accuracy:  0.845833570019
ng20_raw_stems_unigrams_stopwords_df1_tf1  -->  precision  0.847052575677 recall  0.847052575677 f1  0.847052575677
loaded (796715) terms
vectorizing done, 796715 terms vocabulary tokenized
vectorizing done, 796715 terms vocabulary tokenized
training F1:  0.999381297508
training accuracy:  0.999381297508
testing accuracy:  0.85227256388
ng20_raw_stems_bigrams_stopwords_df1_tf1  -->  precision  0.853425385024 recall  0.853425385024 f1  0.853425385024
loaded (148561) terms
vectorizing done, 148561 terms vocabulary tokenized
vectorizing done, 148561 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.850357835262
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.851433882103 recall  0.851433882103 f1  0.851433882103
loaded (38172) terms
extended to (50232) terms
done loading vocabulary
vectorizing done, 50232 terms vocabulary tokenized
vectorizing done, 50232 terms vocabulary tokenized
training F1:  0.998585822874
training accuracy:  0.998585822874
testing accuracy:  0.824684841935
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.825809877854 recall  0.825809877854 f1  0.825809877854
loaded (116801) terms
vectorizing done, 116801 terms vocabulary tokenized
vectorizing done, 116801 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.845443503103
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.846654275093 recall  0.846654275093 f1  0.846654275093
loaded (6412) terms
extended to (10261) terms
done loading vocabulary
vectorizing done, 10261 terms vocabulary tokenized
vectorizing done, 10261 terms vocabulary tokenized
training F1:  0.98753756408
training accuracy:  0.98753756408
testing accuracy:  0.741383719439
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.742166755178 recall  0.742166755178 f1  0.742166755178
loaded (143790) terms
vectorizing done, 143790 terms vocabulary tokenized
vectorizing done, 143790 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.849225335666
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.850371747212 recall  0.850371747212 f1  0.850371747212
loaded (33401) terms
extended to (39832) terms
done loading vocabulary
vectorizing done, 39832 terms vocabulary tokenized
vectorizing done, 39832 terms vocabulary tokenized
training F1:  0.996818101467
training accuracy:  0.996818101467
testing accuracy:  0.792359362525
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.793414763675 recall  0.793414763675 f1  0.793414763675
loaded (149347) terms
vectorizing done, 149347 terms vocabulary tokenized
vectorizing done, 149347 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.850617620759
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.851699415826 recall  0.851699415826 f1  0.851699415826
loaded (38958) terms
extended to (51123) terms
done loading vocabulary
vectorizing done, 51123 terms vocabulary tokenized
vectorizing done, 51123 terms vocabulary tokenized
training F1:  0.998585822874
training accuracy:  0.998585822874
testing accuracy:  0.824371976109
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.825544344132 recall  0.825544344132 f1  0.825544344132
loaded (168379) terms
vectorizing done, 168379 terms vocabulary tokenized
vectorizing done, 168379 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.849910101284
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.851035581519 recall  0.851035581519 f1  0.851035581519
loaded (57990) terms
extended to (70731) terms
done loading vocabulary
vectorizing done, 70731 terms vocabulary tokenized
vectorizing done, 70731 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.825906496767
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.827137546468 recall  0.827137546468 f1  0.827137546468
loaded (146650) terms
vectorizing done, 146650 terms vocabulary tokenized
vectorizing done, 146650 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.848469155801
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.849575146044 recall  0.849575146044 f1  0.849575146044
loaded (36261) terms
extended to (43452) terms
done loading vocabulary
vectorizing done, 43452 terms vocabulary tokenized
vectorizing done, 43452 terms vocabulary tokenized
training F1:  0.997260031819
training accuracy:  0.997260031819
testing accuracy:  0.795296783775
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.796202867764 recall  0.796202867764 f1  0.796202867764
loaded (169002) terms
vectorizing done, 169002 terms vocabulary tokenized
vectorizing done, 169002 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.849930435602
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.851035581519 recall  0.851035581519 f1  0.851035581519
loaded (58613) terms
extended to (71443) terms
done loading vocabulary
vectorizing done, 71443 terms vocabulary tokenized
vectorizing done, 71443 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.826675513598
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.827934147637 recall  0.827934147637 f1  0.827934147637
done!

