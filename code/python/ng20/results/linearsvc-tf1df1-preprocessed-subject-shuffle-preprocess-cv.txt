IPython Notebookng20_classifier-cv Last Checkpoint: Dec 31 19:24 (autosaved)
File
Edit
View
Insert
Cell
Kernel
Help
 Cell Toolbar:
Classify 20ng docs
Classifiy 20ng docs using unigrams and bigrams features with different classifiers and report classification results
In [61]:

def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = CountVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    # generate tfidf vectors
    transformer = TfidfTransformer()
    corpus_tfidf_vectors = transformer.fit_transform(corpus_vectors)
 
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-61-743655218ee8>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
In [62]:

def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import TfidfVectorizer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = TfidfVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_tfidf_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-62-f88374f887f0>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
In [63]:

# given classifier predictions probabilities, return predictions with top n probabilities > 0.5 for each instance or greatest one if all are <=0.5
def get_max_n_pred(pred_proba, n_pred, threshold):
    import heapq
    import numpy
    max_n_pred = numpy.ndarray(shape=pred_proba.shape)
    for i in range(len(pred_proba)):
        largest_n_proba = heapq.nlargest(n_pred,pred_proba[i])
        max_n_pred[i] = numpy.array(((pred_proba[i]>threshold) & (pred_proba[i]>=largest_n_proba[len(largest_n_proba)-1]) & 1))
        if max_n_pred[i].sum(axis=0)==0: # at least one label should be returned
            max_n_pred[i] = numpy.array(((pred_proba[i]>=max(pred_proba[i])) & 1))
    return max_n_pred
In [64]:

# reference: http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification
def classify(x_train,y_train,x_test,y_test,max_labels):
    from sklearn.preprocessing import MultiLabelBinarizer
    from sklearn.multiclass import OneVsRestClassifier
    from sklearn.svm import SVC
    from sklearn.svm import LinearSVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.preprocessing import binarize
    from sklearn.cross_validation import train_test_split
    from sklearn import metrics
    import numpy
    from numpy import mean
    import scipy
    from sklearn.cross_validation import cross_val_score
    from sklearn.metrics import make_scorer
    from sklearn.metrics import precision_score
    from sklearn.metrics import recall_score
    from sklearn.metrics import f1_score
    
    # combine train and test vectors
    #print 'merging training and testing samples x({0}),x({1})'.format(x_train.shape,x_test.shape)
    #print 'merging training and testing samples y({0}),y({1})'.format(len(y_train),len(y_test))
    if x_test.shape[0]>0:
        x = scipy.sparse.vstack((x_train,x_test))
        y = y_train + y_test
    else:
        x = x_train
        y = y_train
    #print 'merged into x({0})'.format(x.shape)
    #print 'merged into y({0})'.format(len(y))
    # binarize the labels
    #mlb = MultiLabelBinarizer()
    #y_train_binarized = mlb.fit_transform(y_train)
    
    # train/test split
    #corpus_tfidf_vectors, labels_binarized = shuffle(corpus_tfidf_vectors, labels_binarized)
    #x_train, x_test, y_train, y_test = train_test_split(corpus_tfidf_vectors, labels_binarized, test_size=test_size, random_state=1)
    
    # classify
    #cls = OneVsRestClassifier(LogisticRegression(class_weight='auto'))
    #cls = OneVsRestClassifier(LogisticRegression())
    #cls = MultinomialNB(alpha=0.01)
    #cls = OneVsRestClassifier(BernoulliNB()need binarize(x_train and x_test))
    #cls = OneVsRestClassifier(SVC(kernel='linear',probability=True,max_iter=1000))
    cls = LinearSVC()
    acc_scores = cross_val_score(cls,x,y,scoring='accuracy',cv=10,n_jobs=-1)
    print 'accuracy scores = {0},{1}'.format(acc_scores,mean(acc_scores))
    macro_p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro precision scores = {0},{1}'.format(macro_p_scores,mean(macro_p_scores))
    macro_r_scores = cross_val_score(cls,x,y,scoring=make_scorer(recall_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro recall scores = {0},{1}'.format(macro_r_scores,mean(macro_r_scores))
    macro_f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro f1 scores = {0},{1}'.format(macro_f1_scores,mean(macro_f1_scores))
    p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average precision scores = {0},{1}'.format(p_scores,mean(p_scores))
    r_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average recall scores = {0},{1}'.format(r_scores,mean(r_scores))
    f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted f1 scores = {0},{1}'.format(f1_scores,mean(f1_scores))
   
    return {'precision':mean(macro_p_scores),
            'recall':mean(macro_r_scores),
            'f1':mean(macro_f1_scores)}
In [65]:

import sklearn
from sklearn.svm import LinearSVC
c = LinearSVC()
print sklearn.__version__
0.15.2
In [66]:

def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_unigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-66-5bcc0f6a848c>:1: SyntaxWarning: import * only allowed at module level
  def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [67]:

def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-67-094e349cf724>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [68]:

def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_bigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-68-c28207c92f80>:1: SyntaxWarning: import * only allowed at module level
  def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [69]:

def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-69-781cd4f52dc5>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [70]:

def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    from sklearn.decomposition import TruncatedSVD
    from scipy import sparse
    import numpy
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # apply LSA
    #print numpy.max(corpus_train_tfidf_vectors)
    #print numpy.min(corpus_train_tfidf_vectors)
    lsa = TruncatedSVD(n_components=num_components)
    lsa.fit(corpus_train_tfidf_vectors)
    #corpus_train_tfidf_vectors = numpy.dot(corpus_train_tfidf_vectors,pca.components_.transpose())
    corpus_train_tfidf_vectors = lsa.transform(corpus_train_tfidf_vectors)
    corpus_test_tfidf_vectors = lsa.transform(corpus_test_tfidf_vectors)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print 'LSA ^' , vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-70-0ae0e12f66cc>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
In [71]:

def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)    
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-71-d27651528d70>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [72]:

def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-72-8129eac551f8>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [73]:

def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-73-180bdc332cbe>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [74]:

def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-74-cd1ea993b277>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [75]:

def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-75-98c5bdcd6b4f>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [76]:

def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-76-1c5602c28486>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [77]:

def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-77-c5ecc72d6e7c>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [78]:

def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-78-60ce875247ce>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [79]:

def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-79-2010f39a430e>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [80]:

def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-80-a08ffa055f62>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [81]:

def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-81-781d3020ecf2>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [82]:

def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-82-69e08236a4c4>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [83]:

def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-83-bdd713c1f2ac>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [84]:

def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-84-6b79430f2923>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [85]:

def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'stem')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-85-a650503cc609>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [86]:

def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-86-3444b80fb7e1>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [87]:

def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-87-dd4a635e1842>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [88]:

def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-88-ce43e0732809>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [89]:

def test():
    from ng20_corpus_loader import load_corpus_and_labels
    from ng20_corpus_loader import load_corpus_with_labels_mappings
    
    # load 20ng docs with class lables from DB
    corpus_train_data = load_corpus_and_labels('train')
    print 'done loading {0} train records and {1} labels.'.format(len(corpus_train_data['corpus']),len(corpus_train_data['labels_dic']))
 
    corpus_test_data = load_corpus_with_labels_mappings('test',corpus_train_data['labels_dic'])
    print 'done loading {0} test records.'.format(len(corpus_test_data['corpus']))
    
    stopwords_removal_mask = 1
    chi_features_mask = 2
    raw_tokens_mask = 4
    for i in range(4,6): # test w/o stopword removal and w/o chi square features and w/o raw tokens
        stopwords_removal = i&stopwords_removal_mask==stopwords_removal_mask
        use_chi_features = i&chi_features_mask==chi_features_mask
        use_raw_tokens = i&raw_tokens_mask==raw_tokens_mask
        
        test_all_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        #test_lemmatized_bigrams_with_LSA({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
        #                         {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
        #                         stopwords_removal,use_chi_features,use_raw_tokens,113240)
        
        test_lemmatized_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
In [90]:

# test using all vocabulary
test()
 
print 'done!'
loaded 18828 records.
done loading 18828 train records and 20 labels.
loaded 0 records.
done loading 0 test records.
loaded (118848) terms
vectorizing done, 118848 terms vocabulary tokenized
vectorizing done, 118848 terms vocabulary tokenized
accuracy scores = [ 0.87202538  0.89936441  0.9321315   0.93050398  0.91715348  0.91759702
  0.92450824  0.92336349  0.91267306  0.89232409],0.912164464731
macro precision scores = [ 0.87146385  0.90216434  0.93450048  0.93085855  0.9176804   0.91809209
  0.92501087  0.92312306  0.9127178   0.89048427],0.91260957001
macro recall scores = [ 0.86466023  0.89589799  0.92913668  0.92889743  0.91549618  0.91522042
  0.9201615   0.92140932  0.90899759  0.88775688],0.908763422148
macro f1 scores = [ 0.86459009  0.89751999  0.93082953  0.92963419  0.91620764  0.91568824
  0.92155741  0.92198938  0.91018698  0.88810519],0.909630863805
weighted average precision scores = [ 0.87270359  0.90161677  0.93341571  0.93107405  0.91718275  0.91863623
  0.92551533  0.92360931  0.9139393   0.89366581],0.913135884763
weighted average recall scores = [ 0.87270359  0.90161677  0.93341571  0.93107405  0.91718275  0.91863623
  0.92551533  0.92360931  0.9139393   0.89366581],0.913135884763
weighted f1 scores = [ 0.86977538  0.8992758   0.93195696  0.93056079  0.91682765  0.91722542
  0.92410054  0.92324483  0.91268805  0.89202462],0.911768004377
ng20_raw_unigrams  -->  precision  0.91260957001 recall  0.908763422148 f1  0.909630863805
loaded (1420511) terms
vectorizing done, 1420511 terms vocabulary tokenized
vectorizing done, 1420511 terms vocabulary tokenized
accuracy scores = [ 0.88736118  0.91207627  0.93637328  0.93474801  0.92671269  0.92982456
  0.93886231  0.93028206  0.92492013  0.89765458],0.921881508128
macro precision scores = [ 0.88653141  0.91606588  0.93951909  0.93549803  0.92776282  0.93114556
  0.93996659  0.93177106  0.92517156  0.89926237],0.923269437722
macro recall scores = [ 0.8780585   0.90919077  0.9326299   0.93241526  0.92549125  0.92754739
  0.93488498  0.9284177   0.92195763  0.8940352 ],0.918462858732
macro f1 scores = [ 0.87749787  0.91103812  0.93464154  0.93361749  0.92619218  0.92841489
  0.93639467  0.92945699  0.92304712  0.89455454],0.91948554122
weighted average precision scores = [ 0.88770409  0.91481975  0.93806742  0.93516606  0.92725019  0.93144767
  0.94014641  0.93127113  0.92562913  0.90165294],0.923315478794
weighted average recall scores = [ 0.88770409  0.91481975  0.93806742  0.93516606  0.92725019  0.93144767
  0.94014641  0.93127113  0.92562913  0.90165294],0.923315478794
weighted f1 scores = [ 0.88395009  0.91217985  0.93601978  0.9346677   0.92656951  0.92974868
  0.93859494  0.93021641  0.92481917  0.89772622],0.921449235158
ng20_raw_bigrams  -->  precision  0.923269437722 recall  0.918462858732 f1  0.91948554122
loaded (111602) terms
vectorizing done, 111602 terms vocabulary tokenized
vectorizing done, 111602 terms vocabulary tokenized
accuracy scores = [ 0.87149656  0.89830508  0.93160127  0.92413793  0.91556028  0.92185008
  0.9271664   0.9212347   0.90894569  0.88752665],0.910782464639
macro precision scores = [ 0.87069853  0.90169614  0.9346168   0.92454079  0.91556895  0.92117354
  0.92764625  0.92210058  0.90868883  0.88651273],0.911324312696
macro recall scores = [ 0.86376288  0.89530676  0.92904217  0.92237104  0.91396011  0.91894106
  0.92297009  0.91927584  0.90444795  0.8835884 ],0.907366629719
macro f1 scores = [ 0.8636848   0.89693404  0.93087201  0.9232195   0.91441454  0.9192318
  0.9243785   0.92014075  0.90560321  0.8839251 ],0.908240425508
weighted average precision scores = [ 0.8716068   0.9014318   0.93291244  0.92454587  0.91525285  0.92280925
  0.92786231  0.92200287  0.90993152  0.88999716],0.911835287207
weighted average recall scores = [ 0.8716068   0.9014318   0.93291244  0.92454587  0.91525285  0.92280925
  0.92786231  0.92200287  0.90993152  0.88999716],0.911835287207
weighted f1 scores = [ 0.86895976  0.89857036  0.93145437  0.92412391  0.91508458  0.92163173
  0.9267161   0.92113588  0.90860244  0.88768397],0.910396310619
ng20_raw_lemmas_unigrams_df1_tf1  -->  precision  0.911324312696 recall  0.907366629719 f1  0.908240425508
loaded (1349814) terms
vectorizing done, 1349814 terms vocabulary tokenized
vectorizing done, 1349814 terms vocabulary tokenized
accuracy scores = [ 0.88365944  0.90942797  0.9369035   0.933687    0.92936803  0.93035619
  0.93833068  0.92708888  0.9201278   0.89605544],0.920500491579
macro precision scores = [ 0.88481159  0.91401707  0.93957731  0.93489604  0.9297626   0.93027405
  0.9385892   0.92856906  0.92070717  0.89701288],0.921821696525
macro recall scores = [ 0.87394601  0.9059744   0.93366017  0.9311274   0.92760652  0.92771054
  0.9340407   0.92518763  0.91692436  0.89284662],0.916902435752
macro f1 scores = [ 0.87276655  0.90798265  0.93542628  0.93250784  0.92822768  0.92808375
  0.9353293   0.92625753  0.91813563  0.8930306 ],0.917774780131
weighted average precision scores = [ 0.88495184  0.91305286  0.93846741  0.93442405  0.9294466   0.93183484
  0.9392854   0.92803969  0.92116197  0.89920868],0.921987335655
weighted average recall scores = [ 0.88495184  0.91305286  0.93846741  0.93442405  0.9294466   0.93183484
  0.9392854   0.92803969  0.92116197  0.89920868],0.921987335655
weighted f1 scores = [ 0.87956916  0.90964553  0.93663967  0.933615    0.92900601  0.93025293
  0.93792416  0.92702232  0.92004697  0.89584869],0.919957044412
ng20_raw_lemmas_bigrams_df1_tf1  -->  precision  0.921821696525 recall  0.916902435752 f1  0.917774780131
loaded (163767) terms
done loading vocabulary
vectorizing done, 163767 terms vocabulary tokenized
vectorizing done, 163767 terms vocabulary tokenized
accuracy scores = [ 0.87572713  0.90466102  0.93584305  0.92732095  0.91874668  0.92450824
  0.92982456  0.92389569  0.9142705   0.88539446],0.914019228299
macro precision scores = [ 0.87605474  0.90757036  0.93800166  0.92796319  0.91787798  0.92451056
  0.92994583  0.92513692  0.91388613  0.88553467],0.91464820332
macro recall scores = [ 0.86773114  0.90140184  0.93312938  0.92582077  0.9171436   0.92187748
  0.92529291  0.92230922  0.91004248  0.88167641],0.910642521669
macro f1 scores = [ 0.86756579  0.90287391  0.93473085  0.926674    0.91723071  0.92219724
  0.92656289  0.92326737  0.91121049  0.88202798],0.911434123947
weighted average precision scores = [ 0.87643322  0.90718415  0.93679218  0.92777475  0.91834328  0.92605944
  0.93080984  0.92462811  0.91516733  0.88868585],0.915187814022
weighted average recall scores = [ 0.87643322  0.90718415  0.93679218  0.92777475  0.91834328  0.92605944
  0.93080984  0.92462811  0.91516733  0.88868585],0.915187814022
weighted f1 scores = [ 0.87288585  0.90461303  0.935612    0.92734467  0.91827138  0.92439362
  0.92938581  0.92387193  0.91407048  0.88550523],0.913595399697
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.91464820332 recall  0.910642521669 f1  0.911434123947
loaded (52165) terms
extended to (70324) terms
done loading vocabulary
vectorizing done, 70324 terms vocabulary tokenized
vectorizing done, 70324 terms vocabulary tokenized
accuracy scores = [ 0.84981491  0.88188559  0.91781548  0.90397878  0.90387679  0.90749601
  0.91547049  0.90526876  0.89456869  0.86727079],0.894744630683
macro precision scores = [ 0.84921674  0.88461296  0.9200708   0.90422745  0.90336689  0.90744991
  0.91556777  0.90641816  0.89276594  0.8662985 ],0.89499951126
macro recall scores = [ 0.84173712  0.87836619  0.91469525  0.90156887  0.90191504  0.90386186
  0.91049934  0.90358763  0.88980748  0.86335661],0.890939538437
macro f1 scores = [ 0.84118819  0.87971216  0.91638802  0.9025824   0.90230551  0.90457825
  0.91181599  0.90439303  0.89069835  0.86333137],0.891699327259
weighted average precision scores = [ 0.85042061  0.88423959  0.91883161  0.90497119  0.90332054  0.90888541
  0.91636522  0.90601285  0.89511849  0.87017477],0.895834027713
weighted average recall scores = [ 0.85042061  0.88423959  0.91883161  0.90497119  0.90332054  0.90888541
  0.91636522  0.90601285  0.89511849  0.87017477],0.895834027713
weighted f1 scores = [ 0.84688648  0.88161865  0.91748857  0.90417715  0.90330547  0.90716352
  0.91486473  0.90506529  0.8943052   0.86732209],0.894219715763
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.89499951126 recall  0.890939538437 f1  0.891699327259
loaded (122655) terms
done loading vocabulary
vectorizing done, 122655 terms vocabulary tokenized
vectorizing done, 122655 terms vocabulary tokenized
accuracy scores = [ 0.87043892  0.89618644  0.93372216  0.92732095  0.91449814  0.92450824
  0.92769803  0.9217669   0.91107561  0.8901919 ],0.911740730192
macro precision scores = [ 0.86911632  0.89899585  0.93630274  0.92796443  0.91430995  0.92425807
  0.92782969  0.92197677  0.91114358  0.88925489],0.912115230385
macro recall scores = [ 0.86233315  0.8928145   0.93078944  0.92582876  0.91264396  0.92249898
  0.92336767  0.92016258  0.90699672  0.88649453],0.908393027721
macro f1 scores = [ 0.86222497  0.89416374  0.93260096  0.92663394  0.91305626  0.92254789
  0.92466162  0.92067483  0.90827717  0.88658387],0.909142525269
weighted average precision scores = [ 0.87056745  0.89867331  0.93485008  0.92807131  0.91408772  0.92578134
  0.92857883  0.92239179  0.91216164  0.89278565],0.91279491167
weighted average recall scores = [ 0.87056745  0.89867331  0.93485008  0.92807131  0.91408772  0.92578134
  0.92857883  0.92239179  0.91216164  0.89278565],0.91279491167
weighted f1 scores = [ 0.8679199   0.89600447  0.93350271  0.92743956  0.91389837  0.92438885
  0.92730958  0.92172092  0.91092744  0.8902481 ],0.911335988943
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.912115230385 recall  0.908393027721 f1  0.909142525269
loaded (11053) terms
extended to (16950) terms
done loading vocabulary
vectorizing done, 16950 terms vocabulary tokenized
vectorizing done, 16950 terms vocabulary tokenized
accuracy scores = [ 0.77154944  0.81673729  0.86108165  0.83713528  0.84811471  0.85167464
  0.85326954  0.85151676  0.828541    0.79850746],0.831812778287
macro precision scores = [ 0.7682301   0.82075792  0.86081578  0.83675812  0.84618961  0.85096647
  0.85110438  0.85142957  0.82670761  0.79769529],0.831065484832
macro recall scores = [ 0.76271344  0.81092808  0.85647541  0.83411687  0.84647577  0.84764751
  0.8469581   0.85012968  0.82292281  0.79282719],0.827119486211
macro f1 scores = [ 0.76113484  0.81270767  0.85749336  0.83492875  0.84590859  0.84754334
  0.84734778  0.8497815   0.82294613  0.79366762],0.827345958163
weighted average precision scores = [ 0.77279875  0.82055852  0.86214603  0.83986706  0.84753106  0.850475
  0.85377268  0.85261315  0.82908255  0.80384543],0.833269023834
weighted average recall scores = [ 0.77279875  0.82055852  0.86214603  0.83986706  0.84753106  0.850475
  0.85377268  0.85261315  0.82908255  0.80384543],0.833269023834
weighted f1 scores = [ 0.76870742  0.81632068  0.86056512  0.83797307  0.84738721  0.84962924
  0.85201683  0.85108015  0.82712727  0.79964084],0.831044783476
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.831065484832 recall  0.827119486211 f1  0.827345958163
loaded (142223) terms
vectorizing done, 142223 terms vocabulary tokenized
vectorizing done, 142223 terms vocabulary tokenized
accuracy scores = [ 0.8699101   0.90095339  0.93425239  0.92572944  0.91609134  0.92450824
  0.9271664   0.92389569  0.91160809  0.8901919 ],0.91243069846
macro precision scores = [ 0.86785911  0.9036814   0.9372641   0.9261427   0.91649913  0.92406324
  0.92916853  0.92433271  0.91176529  0.88949601],0.913027221021
macro recall scores = [ 0.86192998  0.89753253  0.93156752  0.92402174  0.9141714   0.92193582
  0.92254782  0.92195393  0.9072213   0.88661865],0.908950070536
macro f1 scores = [ 0.8616459   0.89906061  0.93343736  0.92484734  0.91477632  0.92210725
  0.9244521   0.92270176  0.90855169  0.88681273],0.909839306951
weighted average precision scores = [ 0.87000335  0.90367409  0.93559352  0.92619621  0.91587574  0.92538584
  0.92886574  0.9245673   0.91269188  0.89253368],0.913538733362
weighted average recall scores = [ 0.87000335  0.90367409  0.93559352  0.92619621  0.91587574  0.92538584
  0.92886574  0.9245673   0.91269188  0.89253368],0.913538733362
weighted f1 scores = [ 0.86752928  0.90105412  0.9340955   0.9257453   0.91549484  0.92418108
  0.92680207  0.92383528  0.91134868  0.89016834],0.912025450289
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.913027221021 recall  0.908950070536 f1  0.909839306951
loaded (30621) terms
extended to (38614) terms
done loading vocabulary
vectorizing done, 38614 terms vocabulary tokenized
vectorizing done, 38614 terms vocabulary tokenized
accuracy scores = [ 0.82231623  0.85222458  0.89236479  0.87851459  0.87519915  0.88357257
  0.89314195  0.88451304  0.85623003  0.83688699],0.867496392139
macro precision scores = [ 0.82012496  0.8522211   0.89348951  0.8772293   0.87337364  0.88331037
  0.8923649   0.88543629  0.85647056  0.83495728],0.866897791649
macro recall scores = [ 0.81450873  0.84777668  0.88913178  0.87588593  0.87245575  0.87996616
  0.8875894   0.88156232  0.85264064  0.83138085],0.863289823968
macro f1 scores = [ 0.81407838  0.84866257  0.8906069   0.87614865  0.87221954  0.88047559
  0.88856681  0.8823909   0.85369053  0.83184374],0.863868360217
weighted average precision scores = [ 0.82289068  0.85326871  0.89371415  0.87843814  0.87463691  0.88448576
  0.89413044  0.88568908  0.85820944  0.84067579],0.868613910136
weighted average recall scores = [ 0.82289068  0.85326871  0.89371415  0.87843814  0.87463691  0.88448576
  0.89413044  0.88568908  0.85820944  0.84067579],0.868613910136
weighted f1 scores = [ 0.82003953  0.85161032  0.89241185  0.87806571  0.87422723  0.88296316
  0.89236686  0.88405414  0.85637589  0.83749882],0.866961351021
ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.866897791649 recall  0.863289823968 f1  0.863868360217
loaded (166783) terms
vectorizing done, 166783 terms vocabulary tokenized
vectorizing done, 166783 terms vocabulary tokenized
accuracy scores = [ 0.87678477  0.90413136  0.93743372  0.92891247  0.91874668  0.92663477
  0.93035619  0.92549228  0.91214058  0.88646055],0.914709337056
macro precision scores = [ 0.8781449   0.90680409  0.93954758  0.92929557  0.91859418  0.92703361
  0.93105063  0.92681121  0.91214858  0.88685968],0.915629002296
macro recall scores = [ 0.86874113  0.90101522  0.93466525  0.92761168  0.91714633  0.92424625
  0.92567996  0.92395     0.90801197  0.88316378],0.911423156786
macro f1 scores = [ 0.86871004  0.90244315  0.93629216  0.92826927  0.91750417  0.92461906
  0.92709433  0.92489949  0.909331    0.88348998],0.912265265476
weighted average precision scores = [ 0.87827563  0.90652728  0.93834707  0.92938731  0.91827033  0.9282341
  0.93156859  0.92622163  0.91326153  0.88963723],0.915973067682
weighted average recall scores = [ 0.87827563  0.90652728  0.93834707  0.92938731  0.91827033  0.9282341
  0.93156859  0.92622163  0.91326153  0.88963723],0.915973067682
weighted f1 scores = [ 0.87406451  0.90411557  0.93720514  0.92897204  0.9181839   0.9265231
  0.92984571  0.92543899  0.91205654  0.8865927 ],0.914299820481
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.915629002296 recall  0.911423156786 f1  0.912265265476
loaded (55181) terms
extended to (73778) terms
done loading vocabulary
vectorizing done, 73778 terms vocabulary tokenized
vectorizing done, 73778 terms vocabulary tokenized
accuracy scores = [ 0.84981491  0.88400424  0.91993637  0.9061008   0.90387679  0.90855928
  0.91866029  0.90473656  0.89350373  0.86673774],0.895593070472
macro precision scores = [ 0.84952118  0.88620922  0.92163329  0.90656818  0.90313514  0.90901818
  0.91817304  0.90701849  0.89133467  0.86513549],0.89577468843
macro recall scores = [ 0.8407824   0.88016161  0.91670348  0.90345179  0.90196491  0.9055588
  0.91343052  0.90291909  0.88876582  0.86244258],0.891618100023
macro f1 scores = [ 0.83949998  0.88153647  0.91826113  0.90460396  0.90221477  0.90614494
  0.91463251  0.90406218  0.88950014  0.86239232],0.892284839891
weighted average precision scores = [ 0.8506745   0.8860106   0.92067332  0.90729259  0.90324887  0.91002356
  0.91916804  0.906093    0.89379811  0.86918756],0.896617014583
weighted average recall scores = [ 0.8506745   0.8860106   0.92067332  0.90729259  0.90324887  0.91002356
  0.91916804  0.906093    0.89379811  0.86918756],0.896617014583
weighted f1 scores = [ 0.84600924  0.88365291  0.91953928  0.90631535  0.90325676  0.90818068
  0.91789916  0.90459602  0.89313776  0.86666864],0.8949255797
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.89577468843 recall  0.891618100023 f1  0.892284839891
loaded (179717) terms
vectorizing done, 179717 terms vocabulary tokenized
vectorizing done, 179717 terms vocabulary tokenized
accuracy scores = [ 0.87678477  0.90519068  0.93584305  0.92785146  0.91980882  0.92397661
  0.92929293  0.92336349  0.91373802  0.8891258 ],0.914497562406
macro precision scores = [ 0.87706937  0.90803439  0.93801438  0.92846476  0.91941386  0.92394177
  0.9292474   0.92472409  0.91360463  0.8891484 ],0.915166305776
macro recall scores = [ 0.86875154  0.90190184  0.93313464  0.92634138  0.91798416  0.92137222
  0.92446002  0.92179902  0.90984409  0.88554452],0.911113342045
macro f1 scores = [ 0.86858088  0.90339943  0.93475868  0.92719637  0.91832106  0.92168031
  0.9257818   0.92277764  0.91100276  0.88590704],0.911940595314
weighted average precision scores = [ 0.87760743  0.90758395  0.93677844  0.92826326  0.91941273  0.9255391
  0.93027522  0.92421166  0.91473112  0.89209127],0.915649419021
weighted average recall scores = [ 0.87760743  0.90758395  0.93677844  0.92826326  0.91941273  0.9255391
  0.93027522  0.92421166  0.91473112  0.89209127],0.915649419021
weighted f1 scores = [ 0.87400037  0.90511538  0.93562391  0.92786633  0.91925779  0.92389496
  0.92883557  0.92336838  0.91359824  0.88924746],0.914080838495
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.915166305776 recall  0.911113342045 f1  0.911940595314
loaded (68115) terms
extended to (87019) terms
done loading vocabulary
vectorizing done, 87019 terms vocabulary tokenized
vectorizing done, 87019 terms vocabulary tokenized
accuracy scores = [ 0.85351666  0.88559322  0.91834571  0.9071618   0.90281466  0.91068581
  0.91919192  0.90633316  0.89669862  0.86833689],0.896867842765
macro precision scores = [ 0.85236217  0.88733657  0.92011578  0.90759874  0.90210672  0.91125787
  0.91869837  0.90750426  0.89499054  0.8670129 ],0.896898391557
macro recall scores = [ 0.84487128  0.88180736  0.91552594  0.9047768   0.90090515  0.90732691
  0.91435443  0.90432986  0.89216033  0.86410171],0.893015975198
macro f1 scores = [ 0.84407397  0.88298611  0.91705352  0.90587785  0.90118227  0.90811531
  0.91544933  0.90524456  0.89306126  0.86413882],0.893718298587
weighted average precision scores = [ 0.85386504  0.88742729  0.91900342  0.90813559  0.90219349  0.91251411
  0.91986165  0.90728954  0.89723531  0.87100287],0.897852831098
weighted average recall scores = [ 0.85386504  0.88742729  0.91900342  0.90813559  0.90219349  0.91251411
  0.91986165  0.90728954  0.89723531  0.87100287],0.897852831098
weighted f1 scores = [ 0.85027476  0.88522058  0.91804221  0.90736688  0.90220885  0.9104719
  0.91858365  0.90618718  0.89649925  0.86833803],0.896319328952
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.896898391557 recall  0.893015975198 f1  0.893718298587
loaded (149119) terms
vectorizing done, 149119 terms vocabulary tokenized
vectorizing done, 149119 terms vocabulary tokenized
accuracy scores = [ 0.8725542   0.90201271  0.93478261  0.92732095  0.91502921  0.92238171
  0.92929293  0.9222991   0.91160809  0.8891258 ],0.9126407318
macro precision scores = [ 0.87102139  0.90459813  0.93706374  0.92750846  0.91555528  0.92171245
  0.93056395  0.92296478  0.91180792  0.88801735],0.913081345454
macro recall scores = [ 0.86435861  0.89840666  0.93237674  0.92583349  0.91316238  0.9203277
  0.92493237  0.92043899  0.90810994  0.88550108],0.909344795746
macro f1 scores = [ 0.86420343  0.89982328  0.93397011  0.92650292  0.91379086  0.92030216
  0.92655676  0.92127897  0.90927549  0.88547287],0.910117687007
weighted average precision scores = [ 0.87257828  0.90452987  0.93574981  0.9276928   0.91466027  0.92314853
  0.93061704  0.92288529  0.91269522  0.8914951 ],0.913605220403
weighted average recall scores = [ 0.87257828  0.90452987  0.93574981  0.9276928   0.91466027  0.92314853
  0.93061704  0.92288529  0.91269522  0.8914951 ],0.913605220403
weighted f1 scores = [ 0.86999763  0.90191093  0.93462366  0.92734612  0.91433358  0.92211865
  0.92891694  0.92223473  0.91153693  0.8890759 ],0.912209506401
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.913081345454 recall  0.909344795746 f1  0.910117687007
loaded (37517) terms
extended to (47497) terms
done loading vocabulary
vectorizing done, 47497 terms vocabulary tokenized
vectorizing done, 47497 terms vocabulary tokenized
accuracy scores = [ 0.82178741  0.86652542  0.90509014  0.88435013  0.88688263  0.89580011
  0.89367358  0.88930282  0.86687966  0.84061834],0.875091024333
macro precision scores = [ 0.81997301  0.8683457   0.90699515  0.88542751  0.88727047  0.89639366
  0.89308981  0.88969786  0.86632644  0.83965631],0.875317590731
macro recall scores = [ 0.81328286  0.86261303  0.90178954  0.88306824  0.88477933  0.89260113
  0.88917285  0.8870958   0.86369247  0.83510933],0.871320456884
macro f1 scores = [ 0.81206134  0.86376589  0.90345513  0.88387214  0.8850733   0.89305685
  0.89003969  0.88769808  0.86402721  0.83556554],0.871861518388
weighted average precision scores = [ 0.82245715  0.86834689  0.90619293  0.88559659  0.88716736  0.89697002
  0.89459595  0.89042356  0.86854842  0.84472377],0.876502265532
weighted average recall scores = [ 0.82245715  0.86834689  0.90619293  0.88559659  0.88716736  0.89697002
  0.89459595  0.89042356  0.86854842  0.84472377],0.876502265532
weighted f1 scores = [ 0.818656    0.8659922   0.90484044  0.8845912   0.88609442  0.89508213
  0.89314153  0.88925305  0.86673819  0.84095158],0.874534073362
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.875317590731 recall  0.871320456884 f1  0.871861518388
loaded (182581) terms
vectorizing done, 182581 terms vocabulary tokenized
vectorizing done, 182581 terms vocabulary tokenized
accuracy scores = [ 0.87731359  0.90572034  0.9369035   0.92944297  0.91821561  0.9255715
  0.92929293  0.92442789  0.91480298  0.8880597 ],0.914975101772
macro precision scores = [ 0.87866839  0.90809141  0.93905628  0.92986659  0.91807     0.92539587
  0.92933437  0.92571502  0.91469504  0.88830366],0.915719663315
macro recall scores = [ 0.86922468  0.90269507  0.93414442  0.92817133  0.91659688  0.92347499
  0.92409266  0.92293474  0.9108645   0.88469482],0.911689408642
macro f1 scores = [ 0.8691912   0.90406624  0.93577443  0.9288441   0.91693889  0.92358861
  0.925419    0.92385805  0.91206309  0.88501708],0.912476068562
weighted average precision scores = [ 0.87880765  0.90780784  0.93783743  0.92986092  0.91771898  0.92694335
  0.93027294  0.92520745  0.91577055  0.89088404],0.916111114322
weighted average recall scores = [ 0.87880765  0.90780784  0.93783743  0.92986092  0.91771898  0.92694335
  0.93027294  0.92520745  0.91577055  0.89088404],0.916111114322
weighted f1 scores = [ 0.87457043  0.90567343  0.93667317  0.92948493  0.91761218  0.92548523
  0.92865604  0.92441393  0.91465534  0.8880772 ],0.914530187891
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.915719663315 recall  0.911689408642 f1  0.912476068562
loaded (70979) terms
extended to (90294) terms
done loading vocabulary
vectorizing done, 90294 terms vocabulary tokenized
vectorizing done, 90294 terms vocabulary tokenized
accuracy scores = [ 0.85774722  0.8845339   0.92205726  0.9071618   0.90600106  0.90855928
  0.92078682  0.90526876  0.89616613  0.86940299],0.897768522364
macro precision scores = [ 0.85752015  0.88656084  0.92354763  0.90720705  0.90519899  0.9091719
  0.92020151  0.90729482  0.89436037  0.86763135],0.897869461105
macro recall scores = [ 0.84909685  0.88069299  0.91905964  0.90449819  0.90400595  0.90527546
  0.91575446  0.9033965   0.89164003  0.86513811],0.893855817319
macro f1 scores = [ 0.84836776  0.88205502  0.92054903  0.90550058  0.90431615  0.90588463
  0.9168995   0.90446643  0.89241079  0.86507179],0.894552166982
weighted average precision scores = [ 0.85863443  0.88646245  0.9226131   0.90800704  0.90542058  0.91035473
  0.9213395   0.90675275  0.89646801  0.87162168],0.898767427654
weighted average recall scores = [ 0.85863443  0.88646245  0.9226131   0.90800704  0.90542058  0.91035473
  0.9213395   0.90675275  0.89646801  0.87162168],0.898767427654
weighted f1 scores = [ 0.85450155  0.88420142  0.92170192  0.90725879  0.90545572  0.90815505
  0.92012095  0.90522529  0.89577433  0.86929118],0.897168621338
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.897869461105 recall  0.893855817319 f1  0.894552166982
loaded (94763) terms
vectorizing done, 94763 terms vocabulary tokenized
vectorizing done, 94763 terms vocabulary tokenized
accuracy scores = [ 0.86567953  0.8940678   0.92895016  0.9204244   0.91768455  0.92025518
  0.9271664   0.91325173  0.90362087  0.88113006],0.907223069058
macro precision scores = [ 0.86459179  0.89687598  0.93076472  0.91939423  0.91846513  0.92022326
  0.92732421  0.91426749  0.90224914  0.87939293],0.907354887031
macro recall scores = [ 0.8581002   0.89074834  0.92648821  0.91824767  0.91587656  0.91816555
  0.92194752  0.91093628  0.898668    0.87642675],0.903560509035
macro f1 scores = [ 0.85832071  0.89206659  0.92797529  0.91857905  0.91673593  0.91846725
  0.92342567  0.91189869  0.89969266  0.876845  ],0.904400685773
weighted average precision scores = [ 0.86579344  0.89718962  0.92981758  0.92056856  0.91760358  0.92130451
  0.92799592  0.91434864  0.90454377  0.88324661],0.908241223218
weighted average recall scores = [ 0.86579344  0.89718962  0.92981758  0.92056856  0.91760358  0.92130451
  0.92799592  0.91434864  0.90454377  0.88324661],0.908241223218
weighted f1 scores = [ 0.86346752  0.89415058  0.92881472  0.9202592   0.91728558  0.9201159
  0.92654362  0.91315288  0.90342875  0.88113693],0.906835567974
ng20_raw_stems_unigrams_df1_tf1  -->  precision  0.907354887031 recall  0.903560509035 f1  0.904400685773
loaded (1247865) terms
vectorizing done, 1247865 terms vocabulary tokenized
vectorizing done, 1247865 terms vocabulary tokenized
accuracy scores = [ 0.87731359  0.91260593  0.9416755   0.93952255  0.92565056  0.93141946
  0.93673578  0.92602448  0.92172524  0.89765458],0.921032767217
macro precision scores = [ 0.87502381  0.91624449  0.9435223   0.94055196  0.92599635  0.93283993
  0.93759239  0.92861434  0.92251678  0.89827767],0.922118001903
macro recall scores = [ 0.86724468  0.90956404  0.93836759  0.93696977  0.92344695  0.92915312
  0.93168847  0.92381931  0.91843973  0.89480211],0.917349575859
macro f1 scores = [ 0.86581515  0.91140136  0.94003391  0.93825833  0.92425676  0.92997216
  0.93334757  0.92528354  0.91967652  0.89481109],0.918285638223
weighted average precision scores = [ 0.87650005  0.91561823  0.94266685  0.94045674  0.92574211  0.9334137
  0.93790756  0.92786444  0.92272137  0.90075537],0.922364642769
weighted average recall scores = [ 0.87650005  0.91561823  0.94266685  0.94045674  0.92574211  0.9334137
  0.93790756  0.92786444  0.92272137  0.90075537],0.922364642769
weighted f1 scores = [ 0.87303382  0.91290086  0.94139671  0.93954292  0.92532997  0.93140909
  0.93620483  0.92610102  0.92152341  0.89759705],0.920503966282
ng20_raw_stems_bigrams_df1_tf1  -->  precision  0.922118001903 recall  0.917349575859 f1  0.918285638223
loaded (150830) terms
vectorizing done, 150830 terms vocabulary tokenized
vectorizing done, 150830 terms vocabulary tokenized
accuracy scores = [ 0.87308302  0.90254237  0.93425239  0.9198939   0.91927775  0.93088783
  0.93195109  0.91644492  0.90894569  0.88006397],0.911734291698
macro precision scores = [ 0.8750503   0.90504791  0.93615289  0.91959548  0.9196062   0.93204061
  0.93226913  0.91810849  0.907586    0.88058993],0.912604693887
macro recall scores = [ 0.86483229  0.89923089  0.93158529  0.91723636  0.91710433  0.92910411
  0.92702977  0.91455639  0.90400531  0.87669355],0.908137830118
macro f1 scores = [ 0.86437299  0.90064375  0.93309291  0.91805958  0.91789619  0.92975477
  0.92849979  0.91575126  0.90492706  0.87700574],0.909000402967
weighted average precision scores = [ 0.87466099  0.90504585  0.93517303  0.92016612  0.91925207  0.9324936
  0.93288205  0.91754628  0.90961291  0.88395301],0.91307858986
weighted average recall scores = [ 0.87466099  0.90504585  0.93517303  0.92016612  0.91925207  0.9324936
  0.93288205  0.91754628  0.90961291  0.88395301],0.91307858986
weighted f1 scores = [ 0.86993892  0.90253073  0.93404666  0.91972899  0.91888345  0.93094048
  0.93142193  0.91649479  0.90854741  0.88042209],0.91129554511
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.912604693887 recall  0.908137830118 f1  0.909000402967
loaded (56067) terms
extended to (72412) terms
done loading vocabulary
vectorizing done, 72412 terms vocabulary tokenized
vectorizing done, 72412 terms vocabulary tokenized
accuracy scores = [ 0.85034373  0.88400424  0.91728526  0.90291777  0.90546999  0.91068581
  0.92025518  0.90047898  0.89084132  0.86780384],0.895008612267
macro precision scores = [ 0.85126849  0.88555213  0.91963112  0.90225422  0.90474553  0.91250823
  0.92064728  0.90157396  0.88906332  0.86711443],0.895435869917
macro recall scores = [ 0.84279264  0.88010408  0.91438     0.90021963  0.90346121  0.90803349
  0.91497787  0.89845019  0.8851632   0.86300174],0.891058404229
macro f1 scores = [ 0.84202354  0.88139579  0.91609395  0.90093502  0.90367973  0.90902655
  0.91645045  0.89929915  0.88629399  0.863316  ],0.891851416429
weighted average precision scores = [ 0.85149223  0.88579623  0.91855528  0.90348791  0.90486435  0.91234965
  0.9215136   0.901469    0.89135354  0.87103659],0.896191838028
weighted average recall scores = [ 0.85149223  0.88579623  0.91855528  0.90348791  0.90486435  0.91234965
  0.9215136   0.901469    0.89135354  0.87103659],0.896191838028
weighted f1 scores = [ 0.8472339   0.88372233  0.91712312  0.90290783  0.90479755  0.91041462
  0.91974503  0.90032849  0.8903864   0.86774071],0.894439996941
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.895435869917 recall  0.891058404229 f1  0.891851416429
loaded (105798) terms
vectorizing done, 105798 terms vocabulary tokenized
vectorizing done, 105798 terms vocabulary tokenized
accuracy scores = [ 0.87043892  0.90148305  0.93054083  0.9193634   0.91927775  0.92078682
  0.92982456  0.91750931  0.90628328  0.88059701],0.90961049281
macro precision scores = [ 0.86912035  0.90317792  0.93203716  0.91877664  0.92029029  0.92158667
  0.93127153  0.91778823  0.90497488  0.88045434],0.90994780144
macro recall scores = [ 0.8624182   0.89833922  0.9282765   0.91706959  0.91707361  0.91884626
  0.92537109  0.91525036  0.90224117  0.87649548],0.906138149334
macro f1 scores = [ 0.86275827  0.89952564  0.92958865  0.91760063  0.91808275  0.91946336
  0.92704078  0.91607252  0.90299198  0.87718558],0.907031017143
weighted average precision scores = [ 0.87048797  0.90327998  0.93133921  0.91963901  0.91931972  0.92213358
  0.9311096   0.9180785   0.90702736  0.88357221],0.910598713001
weighted average recall scores = [ 0.87048797  0.90327998  0.93133921  0.91963901  0.91931972  0.92213358
  0.9311096   0.9180785   0.90702736  0.88357221],0.910598713001
weighted f1 scores = [ 0.86820894  0.90136062  0.9304304   0.91920431  0.91882202  0.9207909
  0.92937753  0.91739066  0.90610769  0.88081656],0.909250961963
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.90994780144 recall  0.906138149334 f1  0.907031017143
loaded (11035) terms
extended to (16252) terms
done loading vocabulary
vectorizing done, 16252 terms vocabulary tokenized
vectorizing done, 16252 terms vocabulary tokenized
accuracy scores = [ 0.77578001  0.81832627  0.85949099  0.84721485  0.84864578  0.85699096
  0.85964912  0.85896754  0.82694356  0.79584222],0.834785129555
macro precision scores = [ 0.77176578  0.82113424  0.86019403  0.84854869  0.84787233  0.85815384
  0.8573477   0.85930695  0.82510638  0.79449933],0.834392926463
macro recall scores = [ 0.76779498  0.8126744   0.85419126  0.84330841  0.84706067  0.85253092
  0.85300862  0.85754102  0.82156403  0.78976984],0.829944416131
macro f1 scores = [ 0.76605789  0.81431823  0.85540747  0.84503953  0.84676511  0.85290386
  0.85359894  0.85770698  0.82210749  0.79061364],0.830451913287
weighted average precision scores = [ 0.77568949  0.82156959  0.86033382  0.85004578  0.84843967  0.85697886
  0.86056746  0.85964392  0.82746893  0.79975688],0.836049439322
weighted average recall scores = [ 0.77568949  0.82156959  0.86033382  0.85004578  0.84843967  0.85697886
  0.86056746  0.85964392  0.82746893  0.79975688],0.836049439322
weighted f1 scores = [ 0.77268047  0.81793353  0.85842242  0.84777157  0.8478734   0.85508921
  0.85863251  0.85859544  0.82611991  0.7963236 ],0.833944205806
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.834392926463 recall  0.829944416131 f1  0.830451913287
loaded (129858) terms
vectorizing done, 129858 terms vocabulary tokenized
vectorizing done, 129858 terms vocabulary tokenized
accuracy scores = [ 0.86673718  0.89936441  0.93107105  0.9204244   0.92246415  0.92238171
  0.93088783  0.91325173  0.9057508   0.88219616],0.909452941674
macro precision scores = [ 0.8652009   0.90176159  0.93270729  0.91950109  0.92355355  0.92249864
  0.93242225  0.91395049  0.9047585   0.88118077],0.909753505876
macro recall scores = [ 0.85878934  0.89588757  0.9283822   0.91822695  0.92057857  0.92031711
  0.92612178  0.91120833  0.90170196  0.87790654],0.905912032889
macro f1 scores = [ 0.85823977  0.89718646  0.9298321   0.91859808  0.92154903  0.92073151
  0.92782417  0.91201464  0.90262881  0.87822075],0.906682531872
weighted average precision scores = [ 0.86681402  0.90231434  0.93203789  0.92042863  0.92264934  0.92382672
  0.93260764  0.91447364  0.90665484  0.88463399],0.910644105709
weighted average recall scores = [ 0.86681402  0.90231434  0.93203789  0.92042863  0.92264934  0.92382672
  0.93260764  0.91447364  0.90665484  0.88463399],0.910644105709
weighted f1 scores = [ 0.8640181   0.89943626  0.93092453  0.92017774  0.92213871  0.92245895
  0.93047938  0.91332897  0.90567871  0.88214046],0.909078179213
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.909753505876 recall  0.905912032889 f1  0.906682531872
loaded (35095) terms
extended to (42581) terms
done loading vocabulary
vectorizing done, 42581 terms vocabulary tokenized
vectorizing done, 42581 terms vocabulary tokenized
accuracy scores = [ 0.81649921  0.84798729  0.89978791  0.88222812  0.87838555  0.88835726
  0.89686337  0.88877062  0.86155485  0.83795309],0.869838726477
macro precision scores = [ 0.81428866  0.8476857   0.90120218  0.88169532  0.87581837  0.88995592
  0.89702135  0.88906904  0.85996685  0.83817361],0.869487700117
macro recall scores = [ 0.80956873  0.84212998  0.89627315  0.88011458  0.87566528  0.88543288
  0.89114295  0.88572651  0.85712785  0.83332003],0.865650193002
macro f1 scores = [ 0.809052    0.84301009  0.89790813  0.88054829  0.87496714  0.88639928
  0.89235535  0.8866429   0.85779017  0.83366657],0.866233993086
weighted average precision scores = [ 0.81795591  0.84952898  0.90108673  0.88252787  0.87743227  0.89007088
  0.89846744  0.88957607  0.86246398  0.84273283],0.871184296693
weighted average recall scores = [ 0.81795591  0.84952898  0.90108673  0.88252787  0.87743227  0.89007088
  0.89846744  0.88957607  0.86246398  0.84273283],0.871184296693
weighted f1 scores = [ 0.81485639  0.84717826  0.8997377   0.88202655  0.87714187  0.888047
  0.89612559  0.88848911  0.86129625  0.83832568],0.86932244159
ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.869487700117 recall  0.865650193002 f1  0.866233993086
loaded (153485) terms
vectorizing done, 153485 terms vocabulary tokenized
vectorizing done, 153485 terms vocabulary tokenized
accuracy scores = [ 0.87414067  0.90254237  0.93319194  0.92095491  0.92193309  0.92822967
  0.93141946  0.91804151  0.91107561  0.88166311],0.912319233208
macro precision scores = [ 0.87500538  0.90487423  0.9354394   0.92059791  0.9224681   0.92872952
  0.93214717  0.91918498  0.90997096  0.88201308],0.913043074558
macro recall scores = [ 0.86554743  0.89899099  0.93045216  0.9182572   0.91988024  0.92616978
  0.92667965  0.91610826  0.90664388  0.87795356],0.908668315434
macro f1 scores = [ 0.86509566  0.90049681  0.93212229  0.91911197  0.92067467  0.92661139
  0.92824624  0.91715638  0.9075935   0.87842106],0.909552996006
weighted average precision scores = [ 0.87520785  0.90490411  0.93408028  0.92112432  0.9219398   0.92980889
  0.93259872  0.91898557  0.91177498  0.88512782],0.913555233426
weighted average recall scores = [ 0.87520785  0.90490411  0.93408028  0.92112432  0.9219398   0.92980889
  0.93259872  0.91898557  0.91177498  0.88512782],0.913555233426
weighted f1 scores = [ 0.87095437  0.90250735  0.93294937  0.92076549  0.92153639  0.92824922
  0.93099954  0.91808402  0.9108073   0.88185423],0.911870728967
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.913043074558 recall  0.908668315434 f1  0.909552996006
loaded (58722) terms
extended to (75314) terms
done loading vocabulary
vectorizing done, 75314 terms vocabulary tokenized
vectorizing done, 75314 terms vocabulary tokenized
accuracy scores = [ 0.84928609  0.88188559  0.91781548  0.90291777  0.9070632   0.91015417
  0.91866029  0.89941458  0.88817891  0.86940299],0.894477907808
macro precision scores = [ 0.84915014  0.88370598  0.91926721  0.90248859  0.90625725  0.91082823
  0.91862526  0.90011396  0.88674826  0.86876096],0.894594583525
macro recall scores = [ 0.84085279  0.87764878  0.9149062   0.90024825  0.90498951  0.90736212
  0.91273048  0.89729327  0.88278148  0.8642145 ],0.890302738093
macro f1 scores = [ 0.83989063  0.87913239  0.91636767  0.90103459  0.905164    0.9079566
  0.91408399  0.89806812  0.88378572  0.8647326 ],0.891021630549
weighted average precision scores = [ 0.84994093  0.88371715  0.91864915  0.90350543  0.90647429  0.9118699
  0.91966866  0.90027706  0.88893366  0.8724874 ],0.895552362758
weighted average recall scores = [ 0.84994093  0.88371715  0.91864915  0.90350543  0.90647429  0.9118699
  0.91966866  0.90027706  0.88893366  0.8724874 ],0.895552362758
weighted f1 scores = [ 0.84584335  0.88154811  0.91760363  0.90289224  0.90636267  0.90991385
  0.91783766  0.89926214  0.8876787   0.86927577],0.893821811607
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.894594583525 recall  0.890302738093 f1  0.891021630549
loaded (169597) terms
vectorizing done, 169597 terms vocabulary tokenized
vectorizing done, 169597 terms vocabulary tokenized
accuracy scores = [ 0.8725542   0.90254237  0.93425239  0.92148541  0.92033988  0.92982456
  0.93301435  0.91750931  0.90841321  0.88219616],0.912213185383
macro precision scores = [ 0.87435419  0.90525655  0.93617274  0.92110805  0.92062716  0.93102344
  0.9331119   0.91901241  0.90709091  0.88321153],0.913096887061
macro recall scores = [ 0.86460585  0.89930819  0.93160087  0.91875141  0.91838231  0.9280939
  0.9280709   0.9155928   0.90377568  0.87915869],0.908734060024
macro f1 scores = [ 0.86421895  0.90077181  0.93311107  0.91957858  0.91912835  0.92865041
  0.92943266  0.91678634  0.90468576  0.87942539],0.909578932105
weighted average precision scores = [ 0.87372006  0.90517042  0.93521162  0.92171234  0.92028242  0.93154076
  0.93386541  0.91849001  0.90892935  0.88641174],0.913533415072
weighted average recall scores = [ 0.87372006  0.90517042  0.93521162  0.92171234  0.92028242  0.93154076
  0.93386541  0.91849001  0.90892935  0.88641174],0.913533415072
weighted f1 scores = [ 0.86940222  0.90257847  0.93406666  0.92130329  0.91999571  0.92984047
  0.93243401  0.91756592  0.90803974  0.8825824 ],0.911780888891
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.913096887061 recall  0.908734060024 f1  0.909578932105
loaded (74834) terms
extended to (91762) terms
done loading vocabulary
vectorizing done, 91762 terms vocabulary tokenized
vectorizing done, 91762 terms vocabulary tokenized
accuracy scores = [ 0.85140137  0.88559322  0.92258749  0.90397878  0.90653213  0.91334397
  0.92025518  0.90047898  0.89403621  0.86993603],0.896814336185
macro precision scores = [ 0.85342554  0.88759697  0.92503249  0.90314448  0.90590254  0.91529871
  0.92053774  0.90181009  0.89208677  0.86833077],0.897316609639
macro recall scores = [ 0.84366039  0.88152317  0.91989639  0.9011646   0.9044611   0.9106004
  0.91508513  0.89844436  0.88879051  0.86493905],0.892856509039
macro f1 scores = [ 0.84275274  0.88298344  0.92162389  0.90184483  0.90475227  0.91164048
  0.91645634  0.89942959  0.8897149   0.8651742 ],0.89363726921
weighted average precision scores = [ 0.85322167  0.88730628  0.92386151  0.90441893  0.90598223  0.915224
  0.92137951  0.90162377  0.89439698  0.8724429 ],0.897985779113
weighted average recall scores = [ 0.85322167  0.88730628  0.92386151  0.90441893  0.90598223  0.915224
  0.92137951  0.90162377  0.89439698  0.8724429 ],0.897985779113
weighted f1 scores = [ 0.84809244  0.88518351  0.92250146  0.90389618  0.90588158  0.91311687
  0.91966841  0.9004233   0.89357671  0.86975416],0.89620946013
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.897316609639 recall  0.892856509039 f1  0.89363726921
loaded (136452) terms
vectorizing done, 136452 terms vocabulary tokenized
vectorizing done, 136452 terms vocabulary tokenized
accuracy scores = [ 0.87096774  0.89989407  0.93107105  0.92095491  0.92087095  0.92185008
  0.93141946  0.91538052  0.90894569  0.88539446],0.910674891957
macro precision scores = [ 0.86783609  0.90211185  0.93296702  0.92004033  0.92186882  0.92217846
  0.93266461  0.91609774  0.90819431  0.88589678],0.910985601352
macro recall scores = [ 0.86256841  0.89666225  0.92864492  0.91861588  0.91861496  0.91979112
  0.92693143  0.91328685  0.90488925  0.88165909],0.907166414965
macro f1 scores = [ 0.8617582   0.89804061  0.9301554   0.91908704  0.91964923  0.92033419
  0.92859331  0.9141746   0.90579462  0.88224192],0.907982910969
weighted average precision scores = [ 0.86972821  0.90221442  0.93193068  0.92105281  0.92084821  0.92294644
  0.9328776   0.91636396  0.90972915  0.88893973],0.911663119559
weighted average recall scores = [ 0.86972821  0.90221442  0.93193068  0.92105281  0.92084821  0.92294644
  0.9328776   0.91636396  0.90972915  0.88893973],0.911663119559
weighted f1 scores = [ 0.867787    0.89990745  0.93093631  0.92079143  0.92039013  0.9218128
  0.93109983  0.91541691  0.90869197  0.88566351],0.910249734363
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.910985601352 recall  0.907166414965 f1  0.907982910969
loaded (41689) terms
extended to (50546) terms
done loading vocabulary
vectorizing done, 50546 terms vocabulary tokenized
vectorizing done, 50546 terms vocabulary tokenized
accuracy scores = [ 0.81861449  0.86016949  0.90562036  0.89124668  0.88475836  0.89473684
  0.89792663  0.88930282  0.86528222  0.84061834],0.874827623996
macro precision scores = [ 0.8153105   0.86073251  0.90879353  0.89127689  0.88384027  0.895077
  0.89716432  0.88993303  0.86403796  0.84026686],0.87464328818
macro recall scores = [ 0.81033977  0.85531039  0.90266179  0.88940807  0.88292767  0.89244962
  0.892497    0.88698286  0.86125402  0.83575681],0.87095880023
macro f1 scores = [ 0.80910666  0.85625852  0.90471296  0.88997473  0.88253441  0.89284836
  0.89363633  0.88778993  0.86160503  0.83605455],0.871452147341
weighted average precision scores = [ 0.81929373  0.86214634  0.90710487  0.89209651  0.88403631  0.89532734
  0.89875201  0.89051139  0.86658654  0.84561249],0.876146752424
weighted average recall scores = [ 0.81929373  0.86214634  0.90710487  0.89209651  0.88403631  0.89532734
  0.89875201  0.89051139  0.86658654  0.84561249],0.876146752424
weighted f1 scores = [ 0.81590456  0.85963926  0.90554412  0.89129638  0.88355776  0.89419745
  0.8972758   0.88927753  0.86494075  0.84120776],0.874284137357
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.87464328818 recall  0.87095880023 f1  0.871452147341
loaded (172073) terms
vectorizing done, 172073 terms vocabulary tokenized
vectorizing done, 172073 terms vocabulary tokenized
accuracy scores = [ 0.87466949  0.90148305  0.93425239  0.92254642  0.92246415  0.92929293
  0.93301435  0.91857371  0.91054313  0.88219616],0.912903578176
macro precision scores = [ 0.87546928  0.90401413  0.93592935  0.92203309  0.92284712  0.92993675
  0.93374161  0.92019824  0.90937312  0.88257756],0.913612025464
macro recall scores = [ 0.8665867   0.89793748  0.93150491  0.91949921  0.92067411  0.92746848
  0.92807111  0.91661321  0.90612316  0.8786269 ],0.909310526719
macro f1 scores = [ 0.86623588  0.89951377  0.93296918  0.92040363  0.92132274  0.92788435
  0.92957507  0.91787301  0.90703766  0.87895271],0.910176798229
weighted average precision scores = [ 0.87547204  0.90393624  0.93494684  0.92275751  0.92233744  0.93092677
  0.93425687  0.91970787  0.91112958  0.88556709],0.914103824324
weighted average recall scores = [ 0.87547204  0.90393624  0.93494684  0.92275751  0.92233744  0.93092677
  0.93425687  0.91970787  0.91112958  0.88556709],0.914103824324
weighted f1 scores = [ 0.8716502   0.9014761   0.93396649  0.9223439   0.9220423   0.92934004
  0.93247087  0.91868964  0.91022067  0.88227533],0.912447554782
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.913612025464 recall  0.909310526719 f1  0.910176798229
loaded (77310) terms
extended to (94464) terms
done loading vocabulary
vectorizing done, 94464 terms vocabulary tokenized
vectorizing done, 94464 terms vocabulary tokenized
accuracy scores = [ 0.85298784  0.88347458  0.92417815  0.9061008   0.90653213  0.9122807
  0.91972355  0.90101118  0.8913738   0.87046908],0.896813180784
macro precision scores = [ 0.85524739  0.88482489  0.9263296   0.90581778  0.90597137  0.91365577
  0.9200764   0.90224006  0.8892739   0.86899968],0.897243684084
macro recall scores = [ 0.84508473  0.87902863  0.9213624   0.90334893  0.90450003  0.90939273
  0.91400792  0.89895994  0.88627511  0.86483666],0.892679708327
macro f1 scores = [ 0.84437287  0.88039678  0.92307122  0.90418645  0.90484179  0.91035846
  0.91539655  0.8998873   0.88706668  0.86524065],0.89348187708
weighted average precision scores = [ 0.85485526  0.88492463  0.92517369  0.90669827  0.90603386  0.9140551
  0.92099073  0.90218188  0.89188431  0.87311631],0.897991401796
weighted average recall scores = [ 0.85485526  0.88492463  0.92517369  0.90669827  0.90603386  0.9140551
  0.92099073  0.90218188  0.89188431  0.87311631],0.897991401796
weighted f1 scores = [ 0.84969103  0.88295487  0.92402387  0.90602619  0.90594454  0.91208826
  0.91897232  0.90095417  0.89098376  0.87017522],0.896181422169
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.897243684084 recall  0.892679708327 f1  0.89348187708
loaded (118489) terms
vectorizing done, 118489 terms vocabulary tokenized
vectorizing done, 118489 terms vocabulary tokenized
accuracy scores = [ 0.87043892  0.90042373  0.9321315   0.92997347  0.91927775  0.92025518
  0.92769803  0.91910591  0.91320554  0.89498934],0.912749936892
macro precision scores = [ 0.87191297  0.9029131   0.93285359  0.93000807  0.92059169  0.92159144
  0.92796139  0.91834543  0.91359529  0.89295335],0.913272632465
macro recall scores = [ 0.86367792  0.89704824  0.92963571  0.92810445  0.91732501  0.91762777
  0.92359072  0.91676071  0.91056246  0.89079164],0.909512462427
macro f1 scores = [ 0.86438969  0.89850154  0.93070114  0.92879163  0.91823892  0.9184767
  0.92494957  0.91714185  0.91161173  0.89097668],0.910377943309
weighted average precision scores = [ 0.87205694  0.90259942  0.9328082   0.93019464  0.91965585  0.92194265
  0.92837193  0.9198453   0.91475485  0.89597114],0.913820090869
weighted average recall scores = [ 0.87205694  0.90259942  0.9328082   0.93019464  0.91965585  0.92194265
  0.92837193  0.9198453   0.91475485  0.89597114],0.913820090869
weighted f1 scores = [ 0.8686715   0.90030802  0.93198981  0.92983915  0.91883755  0.92005755
  0.92731313  0.91907742  0.91352868  0.89459166],0.912421447653
ng20_raw_unigrams_stopwords  -->  precision  0.913272632465 recall  0.909512462427 f1  0.910377943309
loaded (1491273) terms
vectorizing done, 1491273 terms vocabulary tokenized
vectorizing done, 1491273 terms vocabulary tokenized
accuracy scores = [ 0.8826018   0.91260593  0.93955461  0.933687    0.92618163  0.92344498
  0.93673578  0.92708888  0.92172524  0.89818763],0.920181347571
macro precision scores = [ 0.88503875  0.91646788  0.94134563  0.93392149  0.92826896  0.92527744
  0.93658127  0.92725229  0.92230701  0.89757283],0.921403357129
macro recall scores = [ 0.87566424  0.90931888  0.93673729  0.93148881  0.92512611  0.91992736
  0.93251318  0.92498939  0.91962794  0.89422266],0.916961586165
macro f1 scores = [ 0.87621187  0.91109765  0.93822905  0.93241053  0.92588921  0.92107367
  0.93374322  0.92562795  0.92058954  0.89448966],0.917936237295
weighted average precision scores = [ 0.88472667  0.91543373  0.94056415  0.93417027  0.92690559  0.92542769
  0.93749624  0.92802702  0.92290494  0.90040958],0.921606586903
weighted average recall scores = [ 0.88472667  0.91543373  0.94056415  0.93417027  0.92690559  0.92542769
  0.93749624  0.92802702  0.92290494  0.90040958],0.921606586903
weighted f1 scores = [ 0.88052809  0.91260288  0.93937327  0.93365557  0.925777    0.92311861
  0.93638828  0.92708232  0.9219598   0.8979495 ],0.919843533249
ng20_raw_bigrams_stopwords  -->  precision  0.921403357129 recall  0.916961586165 f1  0.917936237295
loaded (111251) terms
vectorizing done, 111251 terms vocabulary tokenized
vectorizing done, 111251 terms vocabulary tokenized
accuracy scores = [ 0.86779482  0.89777542  0.93160127  0.92466844  0.91609134  0.91919192
  0.92663477  0.91750931  0.91320554  0.89179104],0.910626387641
macro precision scores = [ 0.86735283  0.90088718  0.93372682  0.92489107  0.91648378  0.91877962
  0.92753546  0.91707976  0.91369713  0.88923475],0.910966841397
macro recall scores = [ 0.86045629  0.89412176  0.92888329  0.92255912  0.91409859  0.91645517
  0.92253874  0.9152348   0.90966064  0.88725612],0.907126452044
macro f1 scores = [ 0.86102501  0.89580983  0.93049571  0.92340358  0.91482635  0.91661698
  0.9241311   0.91565382  0.91104767  0.8871133 ],0.908012335042
weighted average precision scores = [ 0.86837755  0.90074491  0.93248389  0.92558976  0.91620892  0.92063719
  0.92749949  0.91836645  0.91461232  0.89321578],0.911773625716
weighted average recall scores = [ 0.86837755  0.90074491  0.93248389  0.92558976  0.91620892  0.92063719
  0.92749949  0.91836645  0.91461232  0.89321578],0.911773625716
weighted f1 scores = [ 0.86592729  0.89784411  0.93135888  0.92481648  0.91573662  0.91901796
  0.92628795  0.91745808  0.91335811  0.8914032 ],0.910320866608
ng20_raw_lemmas_unigrams_stopwords_df1_tf1  -->  precision  0.910966841397 recall  0.907126452044 f1  0.908012335042
loaded (1423418) terms
vectorizing done, 1423418 terms vocabulary tokenized
vectorizing done, 1423418 terms vocabulary tokenized
accuracy scores = [ 0.88418826  0.91313559  0.93849417  0.933687    0.92936803  0.92929293
  0.93833068  0.92389569  0.91533546  0.89658849],0.92023162964
macro precision scores = [ 0.88529086  0.91783351  0.94046761  0.93447437  0.9302833   0.92958822
  0.93838703  0.9243678   0.91501337  0.89570237],0.921140844509
macro recall scores = [ 0.87703934  0.90961142  0.93574353  0.93155208  0.92779522  0.92634396
  0.93406242  0.92222795  0.91241127  0.89290663],0.916969381967
macro f1 scores = [ 0.87757866  0.91170023  0.93722935  0.93265754  0.92854284  0.92689665
  0.93529407  0.92281381  0.91332405  0.89276311],0.917880030471
weighted average precision scores = [ 0.88544364  0.91649291  0.93950533  0.93430384  0.92939289  0.93079772
  0.93931636  0.92486222  0.91630641  0.898778  ],0.921519931358
weighted average recall scores = [ 0.88544364  0.91649291  0.93950533  0.93430384  0.92939289  0.93079772
  0.93931636  0.92486222  0.91630641  0.898778  ],0.921519931358
weighted f1 scores = [ 0.8821731   0.9132353   0.93824253  0.93367162  0.92895848  0.92909982
  0.9379731   0.92391446  0.91545041  0.89623558],0.919895437645
ng20_raw_lemmas_bigrams_stopwords_df1_tf1  -->  precision  0.921140844509 recall  0.916969381967 f1  0.917880030471
loaded (159408) terms
done loading vocabulary
vectorizing done, 159408 terms vocabulary tokenized
vectorizing done, 159408 terms vocabulary tokenized
accuracy scores = [ 0.8725542   0.90254237  0.93319194  0.92838196  0.91874668  0.92238171
  0.92982456  0.9217669   0.91373802  0.891258  ],0.913438634676
macro precision scores = [ 0.87436651  0.90518849  0.9349173   0.92859712  0.91915138  0.92170356
  0.93114912  0.92232888  0.91447023  0.88912444],0.914099702083
macro recall scores = [ 0.86538957  0.89826776  0.93028859  0.92622494  0.91695169  0.91987922
  0.92554073  0.92000271  0.91053331  0.88743305],0.910051156652
macro f1 scores = [ 0.86595708  0.89994308  0.93180347  0.92708826  0.91766216  0.91994912
  0.92720117  0.92071156  0.91182987  0.88727364],0.910941941656
weighted average precision scores = [ 0.87425789  0.90538901  0.93405583  0.92902504  0.91867878  0.92346289
  0.93120585  0.922508    0.91539304  0.89253085],0.914650718242
weighted average recall scores = [ 0.87425789  0.90538901  0.93405583  0.92902504  0.91867878  0.92346289
  0.93120585  0.922508    0.91539304  0.89253085],0.914650718242
weighted f1 scores = [ 0.87049422  0.90251656  0.93293069  0.9284      0.91837997  0.92216304
  0.92949917  0.92173445  0.91393963  0.89092305],0.913098077404
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.914099702083 recall  0.910051156652 f1  0.910941941656
loaded (48157) terms
extended to (65065) terms
done loading vocabulary
vectorizing done, 65065 terms vocabulary tokenized
vectorizing done, 65065 terms vocabulary tokenized
accuracy scores = [ 0.85034373  0.88029661  0.91145281  0.90397878  0.90228359  0.90005316
  0.91547049  0.90420436  0.89190628  0.86886994],0.892885976465
macro precision scores = [ 0.85135601  0.88122335  0.9123736   0.90414061  0.90173299  0.89900228
  0.91649888  0.90511029  0.8924152   0.86692446],0.893077767471
macro recall scores = [ 0.84485961  0.87570466  0.90869739  0.90175533  0.90033617  0.8969868
  0.91131463  0.90195779  0.88765888  0.86442035],0.889369161042
macro f1 scores = [ 0.84580332  0.8769654   0.90997473  0.90254478  0.90065697  0.89716599
  0.91290346  0.90274186  0.88924615  0.8642346 ],0.890223724823
weighted average precision scores = [ 0.85157826  0.88202901  0.91197089  0.90511877  0.90206775  0.90108099
  0.91675775  0.90517842  0.89378174  0.87142121],0.894098481258
weighted average recall scores = [ 0.85157826  0.88202901  0.91197089  0.90511877  0.90206775  0.90108099
  0.91675775  0.90517842  0.89378174  0.87142121],0.894098481258
weighted f1 scores = [ 0.84894788  0.87990951  0.91123528  0.90414504  0.90181408  0.89981966
  0.9152505   0.90394238  0.89213481  0.86874925],0.892594838449
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.893077767471 recall  0.889369161042 f1  0.890223724823
loaded (119345) terms
done loading vocabulary
vectorizing done, 119345 terms vocabulary tokenized
vectorizing done, 119345 terms vocabulary tokenized
accuracy scores = [ 0.87043892  0.90042373  0.93319194  0.92679045  0.91768455  0.91812865
  0.92822967  0.91963811  0.91373802  0.891258  ],0.911952202782
macro precision scores = [ 0.87152355  0.90312571  0.93551861  0.92757538  0.91797967  0.91711669
  0.9295448   0.91946921  0.9142397   0.88907487],0.912516818584
macro recall scores = [ 0.86367946  0.89639975  0.93041401  0.92476493  0.91557417  0.9155226
  0.92420893  0.91774261  0.90991657  0.88705335],0.908527639628
macro f1 scores = [ 0.8646363   0.89797444  0.93212443  0.92583629  0.91633064  0.9155671
  0.92585042  0.91815891  0.91131304  0.88679716],0.909458873251
weighted average precision scores = [ 0.87197041  0.9032236   0.93421534  0.92767084  0.91777355  0.91908626
  0.92924722  0.92025303  0.91508062  0.89305036],0.913157123063
weighted average recall scores = [ 0.87197041  0.9032236   0.93421534  0.92767084  0.91777355  0.91908626
  0.92924722  0.92025303  0.91508062  0.89305036],0.913157123063
weighted f1 scores = [ 0.86901305  0.90035483  0.93299325  0.9269188   0.91733554  0.91791847
  0.92784766  0.9195214   0.91375959  0.89093845],0.911660103292
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.912516818584 recall  0.908527639628 f1  0.909458873251
loaded (8094) terms
extended to (13239) terms
done loading vocabulary
vectorizing done, 13239 terms vocabulary tokenized
vectorizing done, 13239 terms vocabulary tokenized
accuracy scores = [ 0.76837652  0.80985169  0.84199364  0.82917772  0.8385555   0.83997873
  0.84635832  0.83288984  0.81043663  0.7793177 ],0.819693628971
macro precision scores = [ 0.76352493  0.81193359  0.84152846  0.82911558  0.83584091  0.83817654
  0.84434636  0.83172289  0.81115665  0.77701608],0.818436199804
macro recall scores = [ 0.75894113  0.80413018  0.83665554  0.82448696  0.83519255  0.83638041
  0.83874415  0.82962178  0.80495542  0.77231599],0.814142410099
macro f1 scores = [ 0.75759944  0.80595709  0.83791122  0.82601564  0.83490941  0.8355974
  0.83958993  0.82955736  0.80541082  0.77270505],0.814525336172
weighted average precision scores = [ 0.76822221  0.81331952  0.84413894  0.83206029  0.83895367  0.83937099
  0.84686213  0.83347835  0.81297553  0.78352677],0.821290839699
weighted average recall scores = [ 0.76822221  0.81331952  0.84413894  0.83206029  0.83895367  0.83937099
  0.84686213  0.83347835  0.81297553  0.78352677],0.821290839699
weighted f1 scores = [ 0.76542288  0.80987853  0.84193495  0.82982648  0.83812755  0.83821191
  0.84493071  0.83215549  0.809318    0.77942379],0.818923028547
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.818436199804 recall  0.814142410099 f1  0.814525336172
loaded (151674) terms
vectorizing done, 151674 terms vocabulary tokenized
vectorizing done, 151674 terms vocabulary tokenized
accuracy scores = [ 0.87308302  0.90042373  0.9321315   0.92785146  0.91449814  0.92185008
  0.92769803  0.91750931  0.91586794  0.8891258 ],0.912003901941
macro precision scores = [ 0.87370084  0.90259897  0.93434936  0.92801299  0.91519368  0.92114329
  0.92940553  0.91693858  0.91637126  0.88671727],0.912443176727
macro recall scores = [ 0.86619998  0.89647267  0.92938297  0.92555533  0.91255188  0.91931399
  0.9233362   0.91555191  0.9129374   0.8849055 ],0.908620783277
macro f1 scores = [ 0.86694416  0.89793695  0.93103091  0.9264294   0.91334867  0.91945727
  0.92510276  0.9159351   0.91412768  0.88459004],0.909490293393
weighted average precision scores = [ 0.87441011  0.90310604  0.93310757  0.92879699  0.91456204  0.92305168
  0.92898615  0.91807601  0.91733302  0.89088352],0.913231312944
weighted average recall scores = [ 0.87441011  0.90310604  0.93310757  0.92879699  0.91456204  0.92305168
  0.92898615  0.91807601  0.91733302  0.89088352],0.913231312944
weighted f1 scores = [ 0.87151189  0.90042011  0.93190824  0.92797768  0.91407677  0.92176462
  0.92725023  0.91750067  0.91612245  0.88883051],0.911736315893
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.912443176727 recall  0.908620783277 f1  0.909490293393
loaded (40423) terms
extended to (48687) terms
done loading vocabulary
vectorizing done, 48687 terms vocabulary tokenized
vectorizing done, 48687 terms vocabulary tokenized
accuracy scores = [ 0.81649921  0.85434322  0.89395546  0.87745358  0.87785449  0.88463583
  0.88995215  0.88078765  0.85889244  0.82729211],0.866166614458
macro precision scores = [ 0.81586401  0.85498251  0.89415491  0.87561424  0.87505567  0.88439204
  0.89108544  0.88091611  0.86035937  0.82484556],0.865726986369
macro recall scores = [ 0.80899116  0.85092516  0.89090529  0.87374607  0.87525942  0.88194185
  0.88457557  0.87827216  0.85529987  0.82195171],0.862186826559
macro f1 scores = [ 0.8087888   0.85171241  0.89192602  0.87410541  0.87435628  0.88232057
  0.88612719  0.87873695  0.85676874  0.82210932],0.862695168175
weighted average precision scores = [ 0.81754882  0.85558559  0.89489953  0.87732553  0.87701605  0.88560988
  0.89106777  0.88131368  0.86177667  0.83044584],0.867258935294
weighted average recall scores = [ 0.81754882  0.85558559  0.89489953  0.87732553  0.87701605  0.88560988
  0.89106777  0.88131368  0.86177667  0.83044584],0.867258935294
weighted f1 scores = [ 0.81414982  0.85385368  0.89386756  0.87682924  0.87661386  0.88433771
  0.88905107  0.88021269  0.85931095  0.82759228],0.865581887244
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.865726986369 recall  0.862186826559 f1  0.862695168175
loaded (160458) terms
vectorizing done, 160458 terms vocabulary tokenized
vectorizing done, 160458 terms vocabulary tokenized
accuracy scores = [ 0.8725542   0.90307203  0.93372216  0.92944297  0.91874668  0.92185008
  0.92982456  0.9217669   0.91373802  0.89072495],0.913544255728
macro precision scores = [ 0.87436651  0.90561817  0.93537443  0.92984949  0.91914319  0.9208006
  0.93114912  0.92232888  0.91447023  0.88862569],0.914172631027
macro recall scores = [ 0.86538957  0.89878859  0.93080942  0.92724535  0.91696189  0.91925422
  0.92554073  0.92000271  0.91053331  0.8867837 ],0.910130949479
macro f1 scores = [ 0.86595708  0.90044528  0.93230656  0.92820168  0.91767183  0.91926697
  0.92720117  0.92071156  0.91182987  0.88664221],0.911023422523
weighted average precision scores = [ 0.87425789  0.90583444  0.93452987  0.9301782   0.91878295  0.92283861
  0.93120585  0.922508    0.91539304  0.89205681],0.914758567856
weighted average recall scores = [ 0.87425789  0.90583444  0.93452987  0.9301782   0.91878295  0.92283861
  0.93120585  0.922508    0.91539304  0.89205681],0.914758567856
weighted f1 scores = [ 0.87049422  0.90303183  0.93344752  0.92948361  0.91844274  0.92164587
  0.92949917  0.92173445  0.91393963  0.8903698 ],0.913208883213
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.914172631027 recall  0.910130949479 f1  0.911023422523
loaded (49207) terms
extended to (66331) terms
done loading vocabulary
vectorizing done, 66331 terms vocabulary tokenized
vectorizing done, 66331 terms vocabulary tokenized
accuracy scores = [ 0.84717081  0.88400424  0.91198303  0.90344828  0.90228359  0.89952153
  0.91493886  0.90420436  0.8913738   0.86780384],0.892673234244
macro precision scores = [ 0.84831532  0.88485133  0.913244    0.90338135  0.90242942  0.89843101
  0.91654794  0.90508384  0.89208845  0.86598318],0.893035583179
macro recall scores = [ 0.8409532   0.87980461  0.9092521   0.90069401  0.90035458  0.8964766
  0.91089796  0.90195779  0.88719834  0.86341047],0.889099965244
macro f1 scores = [ 0.84186879  0.88096834  0.91062286  0.90160746  0.90097671  0.89662611
  0.91258977  0.90271793  0.88881268  0.86307494],0.889986558267
weighted average precision scores = [ 0.84874167  0.8856711   0.91247282  0.90450663  0.90238728  0.9004763
  0.91647164  0.90515851  0.89333783  0.87045317],0.893967696255
weighted average recall scores = [ 0.84874167  0.8856711   0.91247282  0.90450663  0.90238728  0.9004763
  0.91647164  0.90515851  0.89333783  0.87045317],0.893967696255
weighted f1 scores = [ 0.84560379  0.88371424  0.9117053   0.90355623  0.90195018  0.89925227
  0.91473179  0.90392162  0.89160647  0.86754045],0.892358232796
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.893035583179 recall  0.889099965244 f1  0.889986558267
loaded (183612) terms
vectorizing done, 183612 terms vocabulary tokenized
vectorizing done, 183612 terms vocabulary tokenized
accuracy scores = [ 0.87466949  0.90307203  0.93319194  0.92997347  0.91874668  0.92185008
  0.9287613   0.9222991   0.91533546  0.8901919 ],0.913809145029
macro precision scores = [ 0.8763313   0.90555297  0.93486777  0.9303163   0.91895444  0.92071061
  0.93022173  0.92282392  0.91594891  0.88815918],0.914388712411
macro recall scores = [ 0.86725153  0.89878344  0.93030437  0.9277504   0.91688624  0.91924896
  0.92439159  0.92051807  0.91218903  0.88630584],0.910362947005
macro f1 scores = [ 0.86763242  0.90039417  0.93178377  0.92867175  0.9174801   0.91925911
  0.92608148  0.92122892  0.91342894  0.88611309],0.911207374198
weighted average precision scores = [ 0.8763492   0.90576111  0.93401746  0.93065409  0.91845969  0.9227412
  0.93022963  0.92314439  0.91692629  0.89160733],0.914989038608
weighted average recall scores = [ 0.8763492   0.90576111  0.93401746  0.93065409  0.91845969  0.9227412
  0.93022963  0.92314439  0.91692629  0.89160733],0.914989038608
weighted f1 scores = [ 0.87244254  0.90297861  0.93290853  0.92997036  0.91821758  0.92163799
  0.92840707  0.92233059  0.91553901  0.88982023],0.913425250536
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.914388712411 recall  0.910362947005 f1  0.911207374198
loaded (72361) terms
extended to (90274) terms
done loading vocabulary
vectorizing done, 90274 terms vocabulary tokenized
vectorizing done, 90274 terms vocabulary tokenized
accuracy scores = [ 0.84769963  0.88559322  0.91569459  0.90503979  0.90440786  0.90164806
  0.91706539  0.90739755  0.89563365  0.87260128],0.895278102381
macro precision scores = [ 0.84907536  0.88683931  0.91656342  0.90442345  0.90405397  0.90078871
  0.91824601  0.9092367   0.89666411  0.87052478],0.895641582895
macro recall scores = [ 0.84059126  0.88145649  0.91319589  0.90223535  0.90262403  0.89863835
  0.91263579  0.90542108  0.89211656  0.86833089],0.891724568467
macro f1 scores = [ 0.841137    0.8827118   0.9143182   0.90298969  0.90297218  0.89872418
  0.91420787  0.90634534  0.89371537  0.86805582],0.892517743139
weighted average precision scores = [ 0.84954065  0.88746968  0.91604177  0.90582286  0.90430816  0.90292231
  0.91833233  0.90891239  0.89745383  0.87489952],0.896570350142
weighted average recall scores = [ 0.84954065  0.88746968  0.91604177  0.90582286  0.90430816  0.90292231
  0.91833233  0.90891239  0.89745383  0.87489952],0.896570350142
weighted f1 scores = [ 0.84561134  0.88535016  0.91537244  0.9051      0.90400135  0.9013688
  0.91664709  0.9072609   0.8959283   0.8724399 ],0.894908028273
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.895641582895 recall  0.891724568467 f1  0.892517743139
loaded (155428) terms
vectorizing done, 155428 terms vocabulary tokenized
vectorizing done, 155428 terms vocabulary tokenized
accuracy scores = [ 0.87202538  0.90201271  0.93319194  0.92891247  0.91768455  0.92078682
  0.92769803  0.91804151  0.91586794  0.88965885],0.912588020182
macro precision scores = [ 0.87238714  0.90496576  0.93552103  0.92920072  0.91819988  0.91978912
  0.92951418  0.91780854  0.91640148  0.88725943],0.91310472745
macro recall scores = [ 0.86432923  0.89801381  0.93040854  0.92670642  0.91559785  0.91821266
  0.9231919   0.91620126  0.91283301  0.88541066],0.909090535195
macro f1 scores = [ 0.86470033  0.89969722  0.93208848  0.92762363  0.91629719  0.91829031
  0.9249945   0.91666449  0.91404383  0.8850986 ],0.909949858935
weighted average precision scores = [ 0.87321176  0.9049183   0.934341    0.92976028  0.91769159  0.92181609
  0.9290752   0.91854415  0.91737669  0.89146589],0.913820094431
weighted average recall scores = [ 0.87321176  0.9049183   0.934341    0.92976028  0.91769159  0.92181609
  0.9290752   0.91854415  0.91737669  0.89146589],0.913820094431
weighted f1 scores = [ 0.86994639  0.90199038  0.93301219  0.92901903  0.91715371  0.92065456
  0.92721173  0.91797991  0.91609459  0.88937406],0.91224365596
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.91310472745 recall  0.909090535195 f1  0.909949858935
loaded (44177) terms
extended to (53775) terms
done loading vocabulary
vectorizing done, 53775 terms vocabulary tokenized
vectorizing done, 53775 terms vocabulary tokenized
accuracy scores = [ 0.82072977  0.85752119  0.89925769  0.87904509  0.88210303  0.88729399
  0.89367358  0.88451304  0.86741214  0.83102345],0.870257297122
macro precision scores = [ 0.81982545  0.85786608  0.89978833  0.87801202  0.87940733  0.88681872
  0.89408924  0.88455082  0.86880599  0.82840862],0.869757259314
macro recall scores = [ 0.81363619  0.85313024  0.89663386  0.87622188  0.88015911  0.88518515
  0.88796376  0.88165685  0.86423832  0.82457229],0.866339764897
macro f1 scores = [ 0.81346065  0.85394122  0.89766785  0.87661641  0.87901722  0.88513237
  0.88934356  0.88212315  0.86550282  0.82496356],0.866776881225
weighted average precision scores = [ 0.82170713  0.85938697  0.90038318  0.87998761  0.88154713  0.88793584
  0.89506145  0.88511674  0.86969134  0.83458271],0.871540010178
weighted average recall scores = [ 0.82170713  0.85938697  0.90038318  0.87998761  0.88154713  0.88793584
  0.89506145  0.88511674  0.86969134  0.83458271],0.871540010178
weighted f1 scores = [ 0.81860793  0.85711821  0.89931007  0.87901203  0.88102937  0.88679988
  0.89288376  0.88389321  0.86756225  0.83129585],0.86975125667
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.869757259314 recall  0.866339764897 f1  0.866776881225
loaded (184467) terms
vectorizing done, 184467 terms vocabulary tokenized
vectorizing done, 184467 terms vocabulary tokenized
accuracy scores = [ 0.87466949  0.90307203  0.93372216  0.93050398  0.91874668  0.92238171
  0.92982456  0.9222991   0.91533546  0.89072495],0.914128012234
macro precision scores = [ 0.87631777  0.90555297  0.93554084  0.93082766  0.91895444  0.92124831
  0.93119327  0.92282392  0.91594891  0.88872969],0.914713779437
macro recall scores = [ 0.86725153  0.89878344  0.93096861  0.92826061  0.91688624  0.91975916
  0.92555115  0.92051807  0.91218903  0.88681604],0.910698388349
macro f1 scores = [ 0.86764705  0.90039417  0.9324523   0.92917259  0.9174801   0.91978543
  0.92719895  0.92122892  0.91342894  0.88664529],0.911543372956
weighted average precision scores = [ 0.87633898  0.90576111  0.93456432  0.93118096  0.91845969  0.92330674
  0.93124458  0.92314439  0.91692629  0.89220856],0.915313561416
weighted average recall scores = [ 0.87633898  0.90576111  0.93456432  0.93118096  0.91845969  0.92330674
  0.93124458  0.92314439  0.91692629  0.89220856],0.915313561416
weighted f1 scores = [ 0.87246009  0.90297861  0.93345309  0.93048872  0.91821758  0.92218902
  0.92948827  0.92233059  0.91553901  0.89037886],0.913752383631
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.914713779437 recall  0.910698388349 f1  0.911543372956
loaded (73216) terms
extended to (91317) terms
done loading vocabulary
vectorizing done, 91317 terms vocabulary tokenized
vectorizing done, 91317 terms vocabulary tokenized
accuracy scores = [ 0.84822845  0.88559322  0.91569459  0.90557029  0.90440786  0.90217969
  0.91706539  0.90792975  0.89403621  0.87153518],0.895224063644
macro precision scores = [ 0.84873824  0.88687458  0.91662774  0.90493422  0.90409274  0.90111316
  0.91818017  0.9100081   0.895033    0.86931155],0.895491349511
macro recall scores = [ 0.84096549  0.88104167  0.91334701  0.9027404   0.90266843  0.8991878
  0.91263042  0.90594784  0.8901635   0.86698726],0.891567981967
macro f1 scores = [ 0.84145009  0.88229982  0.91442829  0.90350396  0.90303152  0.89918692
  0.91416189  0.90699638  0.89181638  0.86685991],0.892373514291
weighted average precision scores = [ 0.84993442  0.88746803  0.91608398  0.90636038  0.90432687  0.90338993
  0.91825925  0.90935932  0.8959851   0.87382162],0.896498890083
weighted average recall scores = [ 0.84993442  0.88746803  0.91608398  0.90636038  0.90432687  0.90338993
  0.91825925  0.90935932  0.8959851   0.87382162],0.896498890083
weighted f1 scores = [ 0.8462856   0.88521223  0.91538637  0.90564044  0.9040293   0.90189556
  0.91660032  0.90774646  0.89430571  0.87144068],0.894854267323
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.895491349511 recall  0.891567981967 f1  0.892373514291
loaded (94526) terms
vectorizing done, 94526 terms vocabulary tokenized
vectorizing done, 94526 terms vocabulary tokenized
accuracy scores = [ 0.86885246  0.89618644  0.93107105  0.92307692  0.92140202  0.92078682
  0.92663477  0.91165514  0.90202343  0.88219616],0.908388520187
macro precision scores = [ 0.86989171  0.89875889  0.93287833  0.92396292  0.9229909   0.92101046
  0.92776751  0.91163839  0.90061767  0.88118659],0.909070336629
macro recall scores = [ 0.86166778  0.89250451  0.92852507  0.92066964  0.91955761  0.91871027
  0.9217065   0.90955668  0.89753537  0.87806774],0.904850115225
macro f1 scores = [ 0.86250467  0.89413453  0.92996491  0.92177195  0.92063588  0.91910806
  0.92338073  0.91024633  0.89833324  0.87833586],0.905841616798
weighted average precision scores = [ 0.87014439  0.89899296  0.93196999  0.92401106  0.92173229  0.92202941
  0.92769867  0.91205333  0.90286047  0.8845029 ],0.909599547121
weighted average recall scores = [ 0.87014439  0.89899296  0.93196999  0.92401106  0.92173229  0.92202941
  0.92769867  0.91205333  0.90286047  0.8845029 ],0.909599547121
weighted f1 scores = [ 0.86702458  0.89632312  0.93087521  0.92305027  0.92104966  0.92071877
  0.926033    0.91151948  0.90177488  0.88208703],0.908045599228
ng20_raw_stems_unigrams_stopwords_df1_tf1  -->  precision  0.909070336629 recall  0.904850115225 f1  0.905841616798
loaded (1350558) terms
vectorizing done, 1350558 terms vocabulary tokenized
vectorizing done, 1350558 terms vocabulary tokenized
accuracy scores = [ 0.87784241  0.91154661  0.93955461  0.93580902  0.93096123  0.9287613
  0.93779904  0.9201703   0.91640043  0.89445629],0.919330124473
macro precision scores = [ 0.87889688  0.91506225  0.94106362  0.93670242  0.93209575  0.93016568
  0.93864557  0.92172892  0.91602506  0.89496854],0.920535468474
macro recall scores = [ 0.87023861  0.9080524   0.93742541  0.93341363  0.92932626  0.92565822
  0.93281987  0.91838055  0.91237638  0.89102787],0.915871918546
macro f1 scores = [ 0.87053006  0.90993528  0.93862907  0.93461773  0.93023581  0.92679321
  0.93454143  0.9194294   0.91352854  0.89136659],0.916960711165
weighted average precision scores = [ 0.8789483   0.91440206  0.94070812  0.93650247  0.93115062  0.93069012
  0.93874307  0.92165723  0.91731136  0.8972787 ],0.920739205231
weighted average recall scores = [ 0.8789483   0.91440206  0.94070812  0.93650247  0.93115062  0.93069012
  0.93874307  0.92165723  0.91731136  0.8972787 ],0.920739205231
weighted f1 scores = [ 0.87541604  0.91166045  0.93955939  0.93577325  0.93068303  0.92873182
  0.93725208  0.92030963  0.91627904  0.89433776],0.919000249834
ng20_raw_stems_bigrams_stopwords_df1_tf1  -->  precision  0.920535468474 recall  0.915871918546 f1  0.916960711165
loaded (149240) terms
vectorizing done, 149240 terms vocabulary tokenized
vectorizing done, 149240 terms vocabulary tokenized
accuracy scores = [ 0.87202538  0.90307203  0.9321315   0.92679045  0.92405736  0.92503987
  0.92982456  0.91271953  0.9057508   0.88326226],0.911467374306
macro precision scores = [ 0.87508738  0.90533732  0.93348906  0.92777334  0.92470676  0.9256729
  0.93128373  0.91327732  0.90491183  0.88275931],0.912429895252
macro recall scores = [ 0.8648516   0.89936171  0.92968672  0.92438391  0.9220933   0.92294353
  0.92492856  0.91075997  0.90145896  0.8796613 ],0.908012956179
macro f1 scores = [ 0.8655222   0.90079156  0.93099283  0.9254651   0.92292807  0.92349704
  0.92675653  0.91153459  0.90245425  0.88000901],0.908995119208
weighted average precision scores = [ 0.87434225  0.90567043  0.93291064  0.92787693  0.92415299  0.92662134
  0.93123896  0.91373177  0.90661648  0.88554751],0.912870932473
weighted average recall scores = [ 0.87434225  0.90567043  0.93291064  0.92787693  0.92415299  0.92662134
  0.93123896  0.91373177  0.90661648  0.88554751],0.912870932473
weighted f1 scores = [ 0.86996146  0.90305958  0.93199754  0.92676931  0.92370888  0.92510426
  0.92939511  0.91277096  0.90553979  0.88320965],0.91115165343
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.912429895252 recall  0.908012956179 f1  0.908995119208
loaded (54714) terms
extended to (70018) terms
done loading vocabulary
vectorizing done, 70018 terms vocabulary tokenized
vectorizing done, 70018 terms vocabulary tokenized
accuracy scores = [ 0.84822845  0.88400424  0.91781548  0.90981432  0.90759426  0.90271132
  0.91547049  0.90101118  0.88658147  0.86620469],0.893943591324
macro precision scores = [ 0.84627908  0.88653491  0.91946848  0.91031281  0.90825172  0.90329635
  0.9156875   0.90251808  0.88553093  0.8660518 ],0.894393167132
macro recall scores = [ 0.84169961  0.87973991  0.91519273  0.90736324  0.90557109  0.90000898
  0.91007479  0.8990173   0.88181776  0.86188146],0.89023668704
macro f1 scores = [ 0.84202173  0.88133671  0.91667169  0.90843051  0.90622821  0.9008572
  0.91167857  0.90012743  0.88295449  0.862285  ],0.891259152452
weighted average precision scores = [ 0.84846703  0.88700976  0.91838684  0.91078513  0.90763625  0.90403819
  0.91632392  0.90178955  0.88802864  0.86964485],0.895211015932
weighted average recall scores = [ 0.84846703  0.88700976  0.91838684  0.91078513  0.90763625  0.90403819
  0.91632392  0.90178955  0.88802864  0.86964485],0.895211015932
weighted f1 scores = [ 0.84671223  0.88399074  0.91756205  0.90990998  0.90701951  0.90261351
  0.9149032   0.90085794  0.8866391   0.86626411],0.893647237755
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.894393167132 recall  0.89023668704 f1  0.891259152452
loaded (103258) terms
vectorizing done, 103258 terms vocabulary tokenized
vectorizing done, 103258 terms vocabulary tokenized
accuracy scores = [ 0.87202538  0.89777542  0.9300106   0.92360743  0.92246415  0.92238171
  0.9287613   0.91325173  0.90362087  0.88006397],0.909396256942
macro precision scores = [ 0.87215621  0.90022504  0.93132243  0.92489614  0.9237022   0.92265256
  0.93009814  0.91348687  0.90269531  0.87945422],0.910068911795
macro recall scores = [ 0.86499851  0.89413908  0.9275197   0.92145845  0.92055686  0.92040612
  0.92415214  0.91115604  0.89919645  0.87616597],0.905974931808
macro f1 scores = [ 0.86563439  0.89572069  0.92877904  0.92256466  0.92151877  0.92079094
  0.92590658  0.91190998  0.90014059  0.87639828],0.906936392595
weighted average precision scores = [ 0.87276418  0.90057745  0.93074845  0.92478809  0.92266655  0.92384154
  0.92994359  0.91403607  0.90477002  0.88274544],0.910688138279
weighted average recall scores = [ 0.87276418  0.90057745  0.93074845  0.92478809  0.92266655  0.92384154
  0.92994359  0.91403607  0.90477002  0.88274544],0.910688138279
weighted f1 scores = [ 0.87016824  0.89792868  0.92980096  0.92363536  0.9220776   0.92242022
  0.92831842  0.91324977  0.90348582  0.88002331],0.90911083738
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.910068911795 recall  0.905974931808 f1  0.906936392595
loaded (8732) terms
extended to (13483) terms
done loading vocabulary
vectorizing done, 13483 terms vocabulary tokenized
vectorizing done, 13483 terms vocabulary tokenized
accuracy scores = [ 0.76679006  0.81567797  0.84782609  0.84137931  0.84121083  0.83997873
  0.85539607  0.8419372   0.80777423  0.78944563],0.824741611353
macro precision scores = [ 0.76398709  0.81750432  0.84798136  0.8429802   0.83955198  0.84145399
  0.85347696  0.84043584  0.80715234  0.78837876],0.824290284542
macro recall scores = [ 0.75923393  0.8080959   0.84235326  0.83786983  0.83881811  0.83631365
  0.84886692  0.83928176  0.80185605  0.7837674 ],0.819645682376
macro f1 scores = [ 0.75842649  0.80971841  0.84359991  0.83967347  0.83854629  0.83681773
  0.84982179  0.83923252  0.8026631   0.78408304],0.820258275889
weighted average precision scores = [ 0.76741971  0.81936917  0.84962565  0.84447806  0.84137269  0.84017867
  0.85671318  0.84176738  0.81069768  0.79424216],0.826586435285
weighted average recall scores = [ 0.76741971  0.81936917  0.84962565  0.84447806  0.84137269  0.84017867
  0.85671318  0.84176738  0.81069768  0.79424216],0.826586435285
weighted f1 scores = [ 0.76460925  0.81516462  0.84728276  0.84217392  0.84067228  0.83838032
  0.85480489  0.84123319  0.80750535  0.78985162],0.824167821176
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.824290284542 recall  0.819645682376 f1  0.820258275889
loaded (142027) terms
vectorizing done, 142027 terms vocabulary tokenized
vectorizing done, 142027 terms vocabulary tokenized
accuracy scores = [ 0.87202538  0.89989407  0.92948038  0.92519894  0.92352629  0.92397661
  0.92769803  0.91484832  0.90628328  0.88166311],0.91045944176
macro precision scores = [ 0.87303877  0.902167    0.93127719  0.92591118  0.92452163  0.92409245
  0.92877944  0.91521569  0.9054395   0.88129302],0.9111735875
macro recall scores = [ 0.86510892  0.89616958  0.92699196  0.92255912  0.9216378   0.92166403
  0.92260497  0.91273972  0.90190056  0.87773644],0.906911310189
macro f1 scores = [ 0.86557882  0.89762429  0.92846406  0.92360529  0.92249867  0.92217168
  0.92440963  0.91356605  0.90293182  0.87777279],0.907862309814
weighted average precision scores = [ 0.87326851  0.90268766  0.93035744  0.92627902  0.92381833  0.92533132
  0.92897541  0.91575984  0.90729314  0.88450125],0.91182719335
weighted average recall scores = [ 0.87326851  0.90268766  0.93035744  0.92627902  0.92381833  0.92533132
  0.92897541  0.91575984  0.90729314  0.88450125],0.91182719335
weighted f1 scores = [ 0.87005901  0.89996332  0.92934389  0.9251578   0.92318659  0.92401282
  0.92724809  0.91492055  0.90615009  0.88138738],0.910142952783
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.9111735875 recall  0.906911310189 f1  0.907862309814
loaded (47501) terms
extended to (55244) terms
done loading vocabulary
vectorizing done, 55244 terms vocabulary tokenized
vectorizing done, 55244 terms vocabulary tokenized
accuracy scores = [ 0.81438392  0.8559322   0.90137858  0.88753316  0.87573022  0.8856991
  0.90005316  0.88451304  0.86208733  0.8326226 ],0.869993330699
macro precision scores = [ 0.81619369  0.85714226  0.90395118  0.88620615  0.87227314  0.88552327
  0.90027863  0.88443361  0.86144855  0.8314665 ],0.869891698647
macro recall scores = [ 0.80770167  0.85054655  0.8977423   0.88514324  0.87298745  0.88238801
  0.8947964   0.88163484  0.8586924   0.82747207],0.865910492856
macro f1 scores = [ 0.80865497  0.85210332  0.89968406  0.8852816   0.87144097  0.88288483
  0.89631802  0.88219895  0.85939567  0.82753148],0.866549388027
weighted average precision scores = [ 0.81793505  0.85895169  0.90307624  0.88776369  0.87447442  0.88701893
  0.90111129  0.88550829  0.86337819  0.83622852],0.87154463054
weighted average recall scores = [ 0.81793505  0.85895169  0.90307624  0.88776369  0.87447442  0.88701893
  0.90111129  0.88550829  0.86337819  0.83622852],0.87154463054
weighted f1 scores = [ 0.8134586   0.85587961  0.90125181  0.8872444   0.87394366  0.88538281
  0.89952974  0.8842016   0.86208141  0.83252488],0.869549851588
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.869891698647 recall  0.865910492856 f1  0.866549388027
loaded (150355) terms
vectorizing done, 150355 terms vocabulary tokenized
vectorizing done, 150355 terms vocabulary tokenized
accuracy scores = [ 0.87202538  0.90360169  0.93266172  0.92679045  0.92405736  0.9255715
  0.92982456  0.91325173  0.90628328  0.88379531],0.911786298726
macro precision scores = [ 0.87510361  0.90585244  0.93403537  0.92764724  0.92470676  0.92616477
  0.93128373  0.91415443  0.90558663  0.8834108 ],0.912794579321
macro recall scores = [ 0.8648516   0.89986676  0.93020734  0.92437876  0.9220933   0.92345373
  0.92492856  0.91138497  0.90226541  0.8801715 ],0.908360193599
macro f1 scores = [ 0.86551002  0.9013018   0.93149273  0.92543018  0.92292807  0.92399879
  0.92675653  0.91226796  0.90324176  0.88052528],0.90934531148
weighted average precision scores = [ 0.87435445  0.9062155   0.93344873  0.92774178  0.92415299  0.92713388
  0.93123896  0.9143296   0.90716558  0.88623221],0.913201368631
weighted average recall scores = [ 0.87435445  0.9062155   0.93344873  0.92774178  0.92415299  0.92713388
  0.93123896  0.9143296   0.90716558  0.88623221],0.913201368631
weighted f1 scores = [ 0.86994632  0.90359715  0.93249634  0.92673371  0.92370888  0.92562708
  0.92939511  0.91333222  0.90611185  0.88375115],0.911469980931
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.912794579321 recall  0.908360193599 f1  0.90934531148
loaded (55829) terms
extended to (71280) terms
done loading vocabulary
vectorizing done, 71280 terms vocabulary tokenized
vectorizing done, 71280 terms vocabulary tokenized
accuracy scores = [ 0.84769963  0.88665254  0.91834571  0.91193634  0.90971853  0.90271132
  0.91706539  0.90313997  0.88604899  0.86567164],0.894899006383
macro precision scores = [ 0.84510945  0.88911149  0.92000792  0.91249862  0.91060707  0.90256916
  0.91837308  0.90451651  0.88564551  0.86514796],0.895358677722
macro recall scores = [ 0.84104194  0.88230188  0.91571872  0.90945897  0.90766771  0.89988366
  0.91185429  0.90134244  0.88132871  0.86129327],0.891189159741
macro f1 scores = [ 0.84110671  0.88396068  0.9171908   0.91055119  0.90848149  0.90039743
  0.91368166  0.90226428  0.88267148  0.86153881],0.892184452002
weighted average precision scores = [ 0.84779766  0.88964519  0.91895508  0.91292368  0.90985003  0.90369602
  0.91846489  0.90396795  0.8876535   0.86888079],0.896183480793
weighted average recall scores = [ 0.84779766  0.88964519  0.91895508  0.91292368  0.90985003  0.90369602
  0.91846489  0.90396795  0.8876535   0.86888079],0.896183480793
weighted f1 scores = [ 0.84609718  0.88668889  0.91809681  0.91202085  0.90921745  0.90242258
  0.9165685   0.90296068  0.88610561  0.86560774],0.894578629461
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.895358677722 recall  0.891189159741 f1  0.892184452002
loaded (178173) terms
vectorizing done, 178173 terms vocabulary tokenized
vectorizing done, 178173 terms vocabulary tokenized
accuracy scores = [ 0.8699101   0.90360169  0.93372216  0.92679045  0.92458842  0.92663477
  0.93141946  0.91325173  0.90628328  0.88646055],0.912266262293
macro precision scores = [ 0.87290499  0.90586921  0.93543186  0.92756546  0.92521372  0.92711569
  0.9327942   0.91393046  0.90504331  0.88551503],0.913138392198
macro recall scores = [ 0.86281099  0.89985108  0.93134265  0.92437854  0.9226035   0.92446931
  0.92632529  0.91125976  0.90208727  0.88289607],0.908802445131
macro f1 scores = [ 0.86328427  0.90133615  0.93272506  0.92543927  0.92345622  0.92500229
  0.92814699  0.91212953  0.90294418  0.88310293],0.909756690162
weighted average precision scores = [ 0.87206302  0.90614542  0.93461344  0.92766151  0.9246945   0.92811015
  0.93282761  0.91430722  0.90703728  0.88835395],0.913581408523
weighted average recall scores = [ 0.87206302  0.90614542  0.93461344  0.92766151  0.9246945   0.92811015
  0.93282761  0.91430722  0.90703728  0.88835395],0.913581408523
weighted f1 scores = [ 0.8676325   0.90359055  0.9335917   0.92674553  0.9242657   0.92666776
  0.93093383  0.91334616  0.90610452  0.88632783],0.91192060886
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.913138392198 recall  0.908802445131 f1  0.909756690162
loaded (83647) terms
extended to (99758) terms
done loading vocabulary
vectorizing done, 99758 terms vocabulary tokenized
vectorizing done, 99758 terms vocabulary tokenized
accuracy scores = [ 0.84717081  0.88400424  0.92258749  0.91193634  0.9086564   0.90802764
  0.92238171  0.90526876  0.89084132  0.86780384],0.896867854722
macro precision scores = [ 0.84515369  0.88607223  0.92443304  0.91204186  0.90942325  0.90811833
  0.92256028  0.90723535  0.89005842  0.86673124],0.897182768418
macro recall scores = [ 0.83963465  0.87954014  0.91977447  0.90942664  0.90657056  0.90561015
  0.91674109  0.90354278  0.88634706  0.86311765],0.893030519088
macro f1 scores = [ 0.83967055  0.88109996  0.92134139  0.91025293  0.90733866  0.90618241
  0.91836688  0.90464238  0.88752517  0.86325591],0.89396762719
weighted average precision scores = [ 0.84732575  0.88714913  0.92325122  0.91272246  0.90872582  0.9092522
  0.92330468  0.90653262  0.89198903  0.87096606],0.898121897603
weighted average recall scores = [ 0.84732575  0.88714913  0.92325122  0.91272246  0.90872582  0.9092522
  0.92330468  0.90653262  0.89198903  0.87096606],0.898121897603
weighted f1 scores = [ 0.84500961  0.88411016  0.92228268  0.91187272  0.90812031  0.9079815
  0.92178041  0.90522756  0.89079664  0.8677509 ],0.896493247917
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.897182768418 recall  0.893030519088 f1  0.89396762719
loaded (146052) terms
vectorizing done, 146052 terms vocabulary tokenized
vectorizing done, 146052 terms vocabulary tokenized
accuracy scores = [ 0.87202538  0.90095339  0.92841994  0.92413793  0.92246415  0.92450824
  0.9287613   0.91378393  0.90521832  0.88166311],0.910193568905
macro precision scores = [ 0.87197805  0.90306479  0.92996254  0.92539667  0.92349422  0.92463142
  0.93047309  0.91430601  0.90439342  0.88095954],0.910865976126
macro recall scores = [ 0.86510892  0.89732081  0.92599228  0.92154386  0.92048131  0.92219012
  0.92365399  0.91174892  0.90117629  0.87791375],0.906713026872
macro f1 scores = [ 0.86537592  0.89879167  0.9273655   0.92279577  0.92142589  0.92269269
  0.92557993  0.91256623  0.90208396  0.87795735],0.907663490894
weighted average precision scores = [ 0.87251391  0.90353501  0.92915993  0.92543424  0.92279391  0.92590255
  0.93036252  0.91480967  0.90604407  0.88399173],0.911454752588
weighted average recall scores = [ 0.87251391  0.90353501  0.92915993  0.92543424  0.92279391  0.92590255
  0.93036252  0.91480967  0.90604407  0.88399173],0.911454752588
weighted f1 scores = [ 0.86991245  0.9010416   0.92825766  0.92417945  0.9221633   0.92455218
  0.92830083  0.91386541  0.90501067  0.88136643],0.90986499758
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.910865976126 recall  0.906713026872 f1  0.907663490894
loaded (51526) terms
extended to (60263) terms
done loading vocabulary
vectorizing done, 60263 terms vocabulary tokenized
vectorizing done, 60263 terms vocabulary tokenized
accuracy scores = [ 0.81755685  0.86228814  0.90402969  0.88859416  0.88210303  0.88623073
  0.9005848   0.88344864  0.8658147   0.84115139],0.87318021168
macro precision scores = [ 0.81863833  0.86374403  0.90620996  0.88779988  0.8799246   0.88607823
  0.90058389  0.88353495  0.8662562   0.84068722],0.87334572856
macro recall scores = [ 0.81062932  0.85680756  0.90075989  0.88621991  0.87965505  0.88286037
  0.89446997  0.88109566  0.86310334  0.83617262],0.869177370051
macro f1 scores = [ 0.81150889  0.85830157  0.90254751  0.88661922  0.87865571  0.88324406
  0.89602472  0.8816091   0.86384031  0.83636843],0.869871951515
weighted average precision scores = [ 0.82066794  0.86594667  0.9055622   0.88904443  0.88152799  0.88716336
  0.90184083  0.88472667  0.86787863  0.84560136],0.874996008534
weighted average recall scores = [ 0.82066794  0.86594667  0.9055622   0.88904443  0.88152799  0.88716336
  0.90184083  0.88472667  0.86787863  0.84560136],0.874996008534
weighted f1 scores = [ 0.81656341  0.86235266  0.90398632  0.88842791  0.8807113   0.88558586
  0.8999148   0.88339967  0.86601798  0.84136011],0.872832002277
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.87334572856 recall  0.869177370051 f1  0.869871951515
loaded (179061) terms
vectorizing done, 179061 terms vocabulary tokenized
vectorizing done, 179061 terms vocabulary tokenized
accuracy scores = [ 0.8699101   0.90360169  0.93478261  0.92679045  0.92458842  0.92663477
  0.93141946  0.91431613  0.90681576  0.88646055],0.912531994564
macro precision scores = [ 0.87294004  0.90586921  0.93641377  0.92756546  0.92527238  0.92711569
  0.9327942   0.91573913  0.90608129  0.88552171],0.913531287479
macro recall scores = [ 0.86281099  0.89985108  0.93237368  0.92437854  0.92261392  0.92446931
  0.92632529  0.91250976  0.90289372  0.88301877],0.909124506106
macro f1 scores = [ 0.86329453  0.90133615  0.93373072  0.92543927  0.92351146  0.92500229
  0.92814699  0.91358406  0.90384386  0.88325042],0.910113975899
weighted average precision scores = [ 0.87209486  0.90614542  0.93562304  0.92766151  0.92476307  0.92811015
  0.93282761  0.91554143  0.90766881  0.8882685 ],0.913870439634
weighted average recall scores = [ 0.87209486  0.90614542  0.93562304  0.92766151  0.92476307  0.92811015
  0.93282761  0.91554143  0.90766881  0.8882685 ],0.913870439634
weighted f1 scores = [ 0.86764084  0.90359055  0.93462589  0.92674553  0.92432174  0.92666776
  0.93093383  0.91444926  0.90666367  0.88635299],0.912199206811
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.913531287479 recall  0.909124506106 f1  0.910113975899
loaded (84535) terms
extended to (100767) terms
done loading vocabulary
vectorizing done, 100767 terms vocabulary tokenized
vectorizing done, 100767 terms vocabulary tokenized
accuracy scores = [ 0.84611317  0.88400424  0.92205726  0.91193634  0.90918747  0.90536948
  0.92238171  0.90420436  0.89084132  0.86780384],0.896389919401
macro precision scores = [ 0.84400704  0.88650116  0.9239647   0.91201183  0.90984866  0.90484728
  0.92306819  0.90608553  0.89014458  0.86677115],0.896725011582
macro recall scores = [ 0.83861919  0.87956108  0.91929026  0.90958968  0.90712001  0.90290935
  0.91686104  0.90236744  0.88641271  0.86331698],0.892604773901
macro f1 scores = [ 0.83851765  0.88126525  0.92087161  0.91039161  0.90783082  0.90318909
  0.91857455  0.90342644  0.88753541  0.86340046],0.893500289059
weighted average precision scores = [ 0.84629805  0.88737199  0.92278029  0.91273889  0.90927718  0.90614715
  0.92347079  0.90552379  0.89206977  0.87100297],0.89766808624
weighted average recall scores = [ 0.84629805  0.88737199  0.92278029  0.91273889  0.90927718  0.90614715
  0.92347079  0.90552379  0.89206977  0.87100297],0.89766808624
weighted f1 scores = [ 0.84389072  0.88418136  0.92178857  0.91194136  0.90866658  0.90510095
  0.92178527  0.90413149  0.89077045  0.86777602],0.896003275724
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.896725011582 recall  0.892604773901 f1  0.893500289059
done!

