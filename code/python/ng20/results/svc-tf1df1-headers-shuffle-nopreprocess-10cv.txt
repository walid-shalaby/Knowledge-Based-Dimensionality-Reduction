IPython Notebookng20_classifier-cv Last Checkpoint: Dec 24 16:50 (autosaved)
File
Edit
View
Insert
Cell
Kernel
Help
 Cell Toolbar:
Classify 20ng docs
Classifiy 20ng docs using unigrams and bigrams features with different classifiers and report classification results
In [454]:

def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = CountVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    # generate tfidf vectors
    transformer = TfidfTransformer()
    corpus_tfidf_vectors = transformer.fit_transform(corpus_vectors)
 
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-454-743655218ee8>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
In [455]:

def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import TfidfVectorizer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = TfidfVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_tfidf_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-455-f88374f887f0>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
In [456]:

# given classifier predictions probabilities, return predictions with top n probabilities > 0.5 for each instance or greatest one if all are <=0.5
def get_max_n_pred(pred_proba, n_pred, threshold):
    import heapq
    import numpy
    max_n_pred = numpy.ndarray(shape=pred_proba.shape)
    for i in range(len(pred_proba)):
        largest_n_proba = heapq.nlargest(n_pred,pred_proba[i])
        max_n_pred[i] = numpy.array(((pred_proba[i]>threshold) & (pred_proba[i]>=largest_n_proba[len(largest_n_proba)-1]) & 1))
        if max_n_pred[i].sum(axis=0)==0: # at least one label should be returned
            max_n_pred[i] = numpy.array(((pred_proba[i]>=max(pred_proba[i])) & 1))
    return max_n_pred
In [457]:

# reference: http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification
def classify(x_train,y_train,x_test,y_test,max_labels):
    from sklearn.preprocessing import MultiLabelBinarizer
    from sklearn.multiclass import OneVsRestClassifier
    from sklearn.svm import SVC
    from sklearn.svm import LinearSVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.preprocessing import binarize
    from sklearn.cross_validation import train_test_split
    from sklearn import metrics
    import numpy
    from numpy import mean
    import scipy
    from sklearn.cross_validation import cross_val_score
    from sklearn.metrics import make_scorer
    from sklearn.metrics import precision_score
    from sklearn.metrics import recall_score
    from sklearn.metrics import f1_score
    
    # combine train and test vectors
    #print 'merging training and testing samples x({0}),x({1})'.format(x_train.shape,x_test.shape)
    #print 'merging training and testing samples y({0}),y({1})'.format(len(y_train),len(y_test))
    x = scipy.sparse.vstack((x_train,x_test))
    y = y_train + y_test
    #print 'merged into x({0})'.format(x.shape)
    #print 'merged into y({0})'.format(len(y))
    # binarize the labels
    #mlb = MultiLabelBinarizer()
    #y_train_binarized = mlb.fit_transform(y_train)
    
    # train/test split
    #corpus_tfidf_vectors, labels_binarized = shuffle(corpus_tfidf_vectors, labels_binarized)
    #x_train, x_test, y_train, y_test = train_test_split(corpus_tfidf_vectors, labels_binarized, test_size=test_size, random_state=1)
    
    # classify
    #cls = OneVsRestClassifier(LogisticRegression(class_weight='auto'))
    #cls = OneVsRestClassifier(LogisticRegression())
    #cls = MultinomialNB(alpha=0.01)
    #cls = OneVsRestClassifier(BernoulliNB()need binarize(x_train and x_test))
    #cls = OneVsRestClassifier(SVC(kernel='linear',probability=True,max_iter=1000))
    cls = LinearSVC()
    acc_scores = cross_val_score(cls,x,y,scoring='accuracy',cv=10,n_jobs=-1)
    print 'accuracy scores = {0},{1}'.format(acc_scores,mean(acc_scores))
    macro_p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro precision scores = {0},{1}'.format(macro_p_scores,mean(macro_p_scores))
    macro_r_scores = cross_val_score(cls,x,y,scoring=make_scorer(recall_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro recall scores = {0},{1}'.format(macro_r_scores,mean(macro_r_scores))
    macro_f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro f1 scores = {0},{1}'.format(macro_f1_scores,mean(macro_f1_scores))
    p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average precision scores = {0},{1}'.format(p_scores,mean(p_scores))
    r_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average recall scores = {0},{1}'.format(r_scores,mean(r_scores))
    f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted f1 scores = {0},{1}'.format(f1_scores,mean(f1_scores))
   
    return {'precision':mean(macro_p_scores),
            'recall':mean(macro_r_scores),
            'f1':mean(macro_f1_scores)}
In [458]:

import sklearn
from sklearn.svm import LinearSVC
c = LinearSVC()
print sklearn.__version__
0.15.2
In [459]:

def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_unigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-459-5bcc0f6a848c>:1: SyntaxWarning: import * only allowed at module level
  def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [460]:

def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-460-094e349cf724>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [461]:

def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_bigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-461-c28207c92f80>:1: SyntaxWarning: import * only allowed at module level
  def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [462]:

def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-462-781cd4f52dc5>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [463]:

def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    from sklearn.decomposition import TruncatedSVD
    from scipy import sparse
    import numpy
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # apply LSA
    #print numpy.max(corpus_train_tfidf_vectors)
    #print numpy.min(corpus_train_tfidf_vectors)
    lsa = TruncatedSVD(n_components=num_components)
    lsa.fit(corpus_train_tfidf_vectors)
    #corpus_train_tfidf_vectors = numpy.dot(corpus_train_tfidf_vectors,pca.components_.transpose())
    corpus_train_tfidf_vectors = lsa.transform(corpus_train_tfidf_vectors)
    corpus_test_tfidf_vectors = lsa.transform(corpus_test_tfidf_vectors)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print 'LSA ^' , vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-463-0ae0e12f66cc>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
In [464]:

def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)    
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-464-d27651528d70>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [465]:

def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-465-8129eac551f8>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [466]:

def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-466-180bdc332cbe>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [467]:

def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-467-cd1ea993b277>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [468]:

def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-468-98c5bdcd6b4f>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [469]:

def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-469-1c5602c28486>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [470]:

def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-470-c5ecc72d6e7c>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [471]:

def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-471-60ce875247ce>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [472]:

def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-472-2010f39a430e>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [473]:

def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-473-a08ffa055f62>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [474]:

def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-474-781d3020ecf2>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [475]:

def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-475-69e08236a4c4>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [476]:

def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-476-bdd713c1f2ac>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [477]:

def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-477-6b79430f2923>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [478]:

def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'stem')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-478-a650503cc609>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [479]:

def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-479-3444b80fb7e1>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [480]:

def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-480-dd4a635e1842>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [481]:

def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-481-ce43e0732809>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [482]:

def test():
    from ng20_corpus_loader import load_corpus_and_labels
    from ng20_corpus_loader import load_corpus_with_labels_mappings
    
    # load 20ng docs with class lables from DB
    corpus_train_data = load_corpus_and_labels('train')
    print 'done loading {0} train records and {1} labels.'.format(len(corpus_train_data['corpus']),len(corpus_train_data['labels_dic']))
 
    corpus_test_data = load_corpus_with_labels_mappings('test',corpus_train_data['labels_dic'])
    print 'done loading {0} test records.'.format(len(corpus_test_data['corpus']))
    
    stopwords_removal_mask = 1
    chi_features_mask = 2
    raw_tokens_mask = 4
    for i in range(4,6): # test w/o stopword removal and w/o chi square features and w/o raw tokens
        stopwords_removal = i&stopwords_removal_mask==stopwords_removal_mask
        use_chi_features = i&chi_features_mask==chi_features_mask
        use_raw_tokens = i&raw_tokens_mask==raw_tokens_mask
        
        test_all_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        #test_lemmatized_bigrams_with_LSA({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
        #                         {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
        #                         stopwords_removal,use_chi_features,use_raw_tokens,113240)
        
        test_lemmatized_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
In [483]:

# test using all vocabulary
test()
 
print 'done!'
loaded 11314 records.
done loading 11314 train records and 20 labels.
loaded 7532 records.
done loading 7532 test records.
loaded (173735) terms
vectorizing done, 173735 terms vocabulary tokenized
vectorizing done, 173735 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90428345  0.93597884  0.93697034  0.92470838  0.92033988
  0.93676939  0.90691489  0.91640043  0.89339019],0.915736255465
macro precision scores = [ 0.88120422  0.9082126   0.93762643  0.93812367  0.92589333  0.91991242
  0.93735399  0.90652965  0.91709641  0.8945477 ],0.916650043963
macro recall scores = [ 0.87541778  0.90091433  0.93379226  0.93636402  0.92240231  0.91807533
  0.93484465  0.90249787  0.91397699  0.89025894],0.912854448149
macro f1 scores = [ 0.87614293  0.90266157  0.93507349  0.93692999  0.92314049  0.91809241
  0.9357286   0.90343463  0.91494773  0.89129555],0.913744738498
weighted average precision scores = [ 0.88170479  0.90726351  0.93658467  0.9380334   0.92516571  0.92182118
  0.93721354  0.9075348   0.91779206  0.89653624],0.916964989311
weighted average recall scores = [ 0.88170479  0.90726351  0.93658467  0.9380334   0.92516571  0.92182118
  0.93721354  0.9075348   0.91779206  0.89653624],0.916964989311
weighted f1 scores = [ 0.87993718  0.90422703  0.93574256  0.93719028  0.92410451  0.92020798
  0.93666659  0.90634016  0.91653474  0.89386326],0.915481429437
ng20_raw_unigrams  -->  precision  0.916650043963 recall  0.912854448149 f1  0.913744738498
loaded (1664448) terms
vectorizing done, 1664448 terms vocabulary tokenized
vectorizing done, 1664448 terms vocabulary tokenized
accuracy scores = [ 0.88900634  0.91168694  0.93756614  0.94120763  0.93107105  0.92936803
  0.94102019  0.91861702  0.92225772  0.89872068],0.922052174073
macro precision scores = [ 0.88955285  0.91484361  0.94009316  0.9423951   0.93328137  0.92956811
  0.94162327  0.91885306  0.9237649   0.89925732],0.92332327352
macro recall scores = [ 0.88116377  0.90860552  0.93535405  0.94033171  0.9295716   0.9273379
  0.93868599  0.91485604  0.9203246   0.89579929],0.919203047751
macro f1 scores = [ 0.88195262  0.91018889  0.93694906  0.9410468   0.93064711  0.92770868
  0.93972026  0.91598521  0.92143789  0.89647694],0.920211347579
weighted average precision scores = [ 0.89007693  0.91398004  0.93845566  0.94228305  0.93278978  0.9310029
  0.94157496  0.91944554  0.92349263  0.90116152],0.923426301322
weighted average recall scores = [ 0.89007693  0.91398004  0.93845566  0.94228305  0.93278978  0.9310029
  0.94157496  0.91944554  0.92349263  0.90116152],0.923426301322
weighted f1 scores = [ 0.88693207  0.9116193   0.93736203  0.94143151  0.93121649  0.92944064
  0.94091308  0.91827182  0.92231108  0.89896108],0.921845910067
ng20_raw_bigrams  -->  precision  0.92332327352 recall  0.919203047751 f1  0.920211347579
loaded (166463) terms
vectorizing done, 166463 terms vocabulary tokenized
vectorizing done, 166463 terms vocabulary tokenized
accuracy scores = [ 0.88002114  0.90322581  0.93597884  0.93432203  0.92895016  0.92087095
  0.934644    0.90585106  0.91267306  0.89445629],0.915099333366
macro precision scores = [ 0.87733772  0.90679342  0.93741793  0.93509185  0.93045224  0.91927532
  0.93511962  0.9047555   0.91387525  0.89488832],0.915500715649
macro recall scores = [ 0.87273103  0.90043163  0.93420642  0.93345081  0.92705687  0.91868298
  0.93222771  0.90091927  0.90982896  0.89189157],0.912142726155
macro f1 scores = [ 0.87321743  0.90191601  0.93529441  0.93401229  0.92788093  0.91845059
  0.93318458  0.90187263  0.91102772  0.89258343],0.912944001694
weighted average precision scores = [ 0.87997684  0.90567652  0.9366051   0.93499982  0.92967381  0.92179482
  0.93514127  0.90610909  0.91457246  0.89695653],0.916150627724
weighted average recall scores = [ 0.87997684  0.90567652  0.9366051   0.93499982  0.92967381  0.92179482
  0.93514127  0.90610909  0.91457246  0.89695653],0.916150627724
weighted f1 scores = [ 0.87848854  0.9030624   0.93582723  0.93440211  0.92855357  0.92084399
  0.93446776  0.90517364  0.91283716  0.89488515],0.91485415458
ng20_raw_lemmas_unigrams_df1_tf1  -->  precision  0.915500715649 recall  0.912142726155 f1  0.912944001694
loaded (1593710) terms
vectorizing done, 1593710 terms vocabulary tokenized
vectorizing done, 1593710 terms vocabulary tokenized
accuracy scores = [ 0.88530655  0.91274458  0.93968254  0.93802966  0.93372216  0.92671269
  0.94367694  0.9143617   0.91853035  0.89925373],0.921202091435
macro precision scores = [ 0.88258007  0.91527387  0.94217825  0.93940216  0.93554172  0.92697374
  0.94430803  0.9146636   0.92016102  0.9003086 ],0.922139103084
macro recall scores = [ 0.87636052  0.90931295  0.93756492  0.93714495  0.93211845  0.92418524
  0.94094326  0.9101367   0.91649592  0.89674964],0.918101257303
macro f1 scores = [ 0.87619388  0.91065577  0.93909021  0.93796897  0.9331051   0.92474102
  0.94211954  0.91133829  0.91760343  0.89736711],0.919018332209
weighted average precision scores = [ 0.88498399  0.91490575  0.94053436  0.93893752  0.93509018  0.92849235
  0.94418263  0.91537601  0.91995302  0.90237132],0.922482713695
weighted average recall scores = [ 0.88498399  0.91490575  0.94053436  0.93893752  0.93509018  0.92849235
  0.94418263  0.91537601  0.91995302  0.90237132],0.922482713695
weighted f1 scores = [ 0.88257266  0.91250872  0.93942908  0.93818929  0.9337493   0.92677253
  0.94350936  0.9139666   0.91857667  0.89971205],0.920898624632
ng20_raw_lemmas_bigrams_df1_tf1  -->  precision  0.922139103084 recall  0.918101257303 f1  0.919018332209
loaded (221958) terms
done loading vocabulary
vectorizing done, 221958 terms vocabulary tokenized
vectorizing done, 221958 terms vocabulary tokenized
accuracy scores = [ 0.88689218  0.90904283  0.93650794  0.93591102  0.9300106   0.92140202
  0.93836344  0.91170213  0.91799787  0.89658849],0.918441851506
macro precision scores = [ 0.88600178  0.9119889   0.93754966  0.93710856  0.93089115  0.92015265
  0.9383045   0.91180724  0.91878806  0.89689388],0.918948639332
macro recall scores = [ 0.88008516  0.9054002   0.93472027  0.93487792  0.92838618  0.91911447
  0.93567116  0.9069927   0.91571237  0.89355301],0.915451344292
macro f1 scores = [ 0.88084278  0.90695133  0.93562477  0.93571322  0.92896066  0.91899248
  0.93657198  0.90822428  0.91650355  0.89430696],0.916269201116
weighted average precision scores = [ 0.88724734  0.91154453  0.93706399  0.93674135  0.93045408  0.92282928
  0.93866869  0.91257429  0.91915523  0.89931057],0.919558934155
weighted average recall scores = [ 0.88724734  0.91154453  0.93706399  0.93674135  0.93045408  0.92282928
  0.93866869  0.91257429  0.91915523  0.89931057],0.919558934155
weighted f1 scores = [ 0.88531137  0.90889325  0.93631047  0.93605665  0.92962455  0.92150992
  0.93816122  0.91119577  0.91788057  0.89701806],0.918196182089
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.918948639332 recall  0.915451344292 f1  0.916269201116
loaded (55495) terms
extended to (74491) terms
done loading vocabulary
vectorizing done, 74491 terms vocabulary tokenized
vectorizing done, 74491 terms vocabulary tokenized
accuracy scores = [ 0.85835095  0.89370703  0.91798942  0.9184322   0.90986214  0.91237387
  0.92454835  0.89148936  0.89563365  0.86886994],0.899125692303
macro precision scores = [ 0.85540207  0.89646078  0.91962496  0.9187904   0.90952225  0.91079245
  0.92536253  0.89206098  0.893667    0.86844726],0.89901306818
macro recall scores = [ 0.85083119  0.89091254  0.91492777  0.91677172  0.90712344  0.90992285
  0.92150302  0.8863677   0.892556    0.86436752],0.895528375255
macro f1 scores = [ 0.850889    0.89229694  0.91637587  0.91734623  0.90749977  0.90952074
  0.92258974  0.88770824  0.89262158  0.86502879],0.89618768893
weighted average precision scores = [ 0.85794162  0.89591557  0.91946854  0.91906809  0.91003283  0.91365921
  0.92506173  0.89284439  0.89636092  0.8715509 ],0.900190380088
weighted average recall scores = [ 0.85794162  0.89591557  0.91946854  0.91906809  0.91003283  0.91365921
  0.92506173  0.89284439  0.89636092  0.8715509 ],0.900190380088
weighted f1 scores = [ 0.85630233  0.893666    0.91789319  0.91833076  0.90923199  0.91218653
  0.92415433  0.89096352  0.89553248  0.86885637],0.898711749386
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.89901306818 recall  0.895528375255 f1  0.89618768893
loaded (177564) terms
done loading vocabulary
vectorizing done, 177564 terms vocabulary tokenized
vectorizing done, 177564 terms vocabulary tokenized
accuracy scores = [ 0.88266385  0.90586991  0.93544974  0.93538136  0.92682927  0.91927775
  0.93517535  0.90691489  0.91640043  0.89605544],0.916001796791
macro precision scores = [ 0.88155294  0.90941784  0.93707005  0.93591084  0.9284166   0.91817023
  0.93536673  0.90652018  0.91657081  0.89661626],0.916561248388
macro recall scores = [ 0.87604017  0.90236464  0.93325883  0.9343983   0.92502078  0.9169049
  0.93287696  0.90238321  0.91370944  0.89341516],0.913037239827
macro f1 scores = [ 0.87681916  0.90399818  0.93445199  0.93491889  0.92578353  0.91682329
  0.9336658   0.90348407  0.91442726  0.89417426],0.913854642668
weighted average precision scores = [ 0.88325034  0.90850802  0.93624982  0.93606697  0.92758967  0.92070055
  0.93564281  0.90748627  0.91769522  0.89875224],0.91719419027
weighted average recall scores = [ 0.88325034  0.90850802  0.93624982  0.93606697  0.92758967  0.92070055
  0.93564281  0.90748627  0.91769522  0.89875224],0.91719419027
weighted f1 scores = [ 0.88134754  0.90567711  0.93520121  0.93548802  0.92638792  0.91932012
  0.93499666  0.90639566  0.91639298  0.89654512],0.915775233391
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.916561248388 recall  0.913037239827 f1  0.913854642668
loaded (11101) terms
extended to (17030) terms
done loading vocabulary
vectorizing done, 17030 terms vocabulary tokenized
vectorizing done, 17030 terms vocabulary tokenized
accuracy scores = [ 0.78382664  0.82707562  0.86190476  0.85540254  0.84835631  0.86245353
  0.86928799  0.83882979  0.82800852  0.79850746],0.837365316649
macro precision scores = [ 0.78137173  0.83179313  0.86227414  0.8543081   0.84797997  0.86127056
  0.86880844  0.83715273  0.82756573  0.79760221],0.837012672343
macro recall scores = [ 0.77556603  0.82202121  0.8578947   0.85293867  0.84713119  0.86021405
  0.86716967  0.83225315  0.82524468  0.79223415],0.833266749552
macro f1 scores = [ 0.77458733  0.82401178  0.85904217  0.85313172  0.84650848  0.85969361
  0.86730838  0.83263641  0.8251164   0.79312959],0.833516586666
weighted average precision scores = [ 0.78402216  0.83033736  0.86317984  0.85684911  0.84795867  0.86178222
  0.86948511  0.83867229  0.82900044  0.80238878],0.838367599266
weighted average recall scores = [ 0.78402216  0.83033736  0.86317984  0.85684911  0.84795867  0.86178222
  0.86948511  0.83867229  0.82900044  0.80238878],0.838367599266
weighted f1 scores = [ 0.78092444  0.82648799  0.86159567  0.85561598  0.8471007   0.86112239
  0.86877767  0.83705513  0.82722772  0.79870461],0.836461230133
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.837012672343 recall  0.833266749552 f1  0.833516586666
loaded (197617) terms
vectorizing done, 197617 terms vocabulary tokenized
vectorizing done, 197617 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.90745637  0.93703704  0.93273305  0.92735949  0.92352629
  0.934644    0.90904255  0.91586794  0.89552239],0.916532442718
macro precision scores = [ 0.87877037  0.91031705  0.93787659  0.9335651   0.9289217   0.92156991
  0.93533012  0.90851775  0.91667648  0.89625328],0.916779833971
macro recall scores = [ 0.87444681  0.90435755  0.9350843   0.93185191  0.925505    0.92098017
  0.93235119  0.90412522  0.91308205  0.89289115],0.913467534951
macro f1 scores = [ 0.87479909  0.90585935  0.93603965  0.93240333  0.92635032  0.92072929
  0.93337735  0.90524748  0.9142344   0.8937405 ],0.914278075372
weighted average precision scores = [ 0.88160047  0.90959372  0.93742929  0.93350793  0.92807758  0.9246048
  0.93534638  0.90962727  0.91742457  0.89840286],0.917561486908
weighted average recall scores = [ 0.88160047  0.90959372  0.93742929  0.93350793  0.92807758  0.9246048
  0.93534638  0.90962727  0.91742457  0.89840286],0.917561486908
weighted f1 scores = [ 0.88041065  0.90731336  0.93683568  0.93281665  0.92697087  0.92356087
  0.93459452  0.90845328  0.91604176  0.89611508],0.916311272154
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.916779833971 recall  0.913467534951 f1  0.914278075372
loaded (31154) terms
extended to (39297) terms
done loading vocabulary
vectorizing done, 39297 terms vocabulary tokenized
vectorizing done, 39297 terms vocabulary tokenized
accuracy scores = [ 0.82346723  0.86197779  0.9031746   0.88612288  0.88176034  0.88157196
  0.90063762  0.87287234  0.86634718  0.84115139],0.871908332724
macro precision scores = [ 0.82355067  0.86400528  0.90374825  0.88679155  0.88110557  0.87902115
  0.90141278  0.87118884  0.86459204  0.84137083],0.871678695632
macro recall scores = [ 0.81626137  0.85873596  0.90040186  0.8842557   0.87983849  0.87788729
  0.89716342  0.86692346  0.86208833  0.8349692 ],0.867852509166
macro f1 scores = [ 0.81656163  0.86014255  0.9015356   0.88509543  0.87962614  0.87778874
  0.89812829  0.86785924  0.86271613  0.83605056],0.868550429624
weighted average precision scores = [ 0.82529628  0.8643636   0.90375077  0.88708425  0.8817393   0.88189127
  0.90156784  0.87330994  0.8671828   0.84551237],0.873169841669
weighted average recall scores = [ 0.82529628  0.8643636   0.90375077  0.88708425  0.8817393   0.88189127
  0.90156784  0.87330994  0.8671828   0.84551237],0.873169841669
weighted f1 scores = [ 0.82170125  0.86208524  0.90297477  0.88618228  0.88091187  0.88108145
  0.90017338  0.8720707   0.8661863   0.84124344],0.871461068238
ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.871678695632 recall  0.867852509166 f1  0.868550429624
loaded (224956) terms
vectorizing done, 224956 terms vocabulary tokenized
vectorizing done, 224956 terms vocabulary tokenized
accuracy scores = [ 0.8858351   0.9106293   0.93597884  0.93432203  0.93054083  0.92352629
  0.93942614  0.91117021  0.91586794  0.89605544],0.918335211356
macro precision scores = [ 0.88519052  0.91390776  0.93740562  0.93544584  0.93133499  0.92245567
  0.93931396  0.91127643  0.91644942  0.89674455],0.918952475717
macro recall scores = [ 0.87908506  0.90691019  0.93449351  0.93329698  0.92890701  0.92143884
  0.93655242  0.90658599  0.91366093  0.89334936],0.915428030397
macro f1 scores = [ 0.88004273  0.90856935  0.93543918  0.93408199  0.929481    0.92131604
  0.9375253   0.90772914  0.91439963  0.89405967],0.916264402765
weighted average precision scores = [ 0.88626048  0.9131859   0.93658877  0.93528813  0.9309239   0.92503072
  0.93975515  0.91204838  0.91669811  0.89897277],0.919475230277
weighted average recall scores = [ 0.88626048  0.9131859   0.93658877  0.93528813  0.9309239   0.92503072
  0.93975515  0.91204838  0.91669811  0.89897277],0.919475230277
weighted f1 scores = [ 0.88440451  0.91045023  0.93580903  0.93452204  0.93016435  0.92367229
  0.93924708  0.91063988  0.91568187  0.89651115],0.918110242936
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.918952475717 recall  0.915428030397 f1  0.916264402765
loaded (58493) terms
extended to (77918) terms
done loading vocabulary
vectorizing done, 77918 terms vocabulary tokenized
vectorizing done, 77918 terms vocabulary tokenized
accuracy scores = [ 0.85676533  0.89370703  0.92063492  0.91790254  0.90933192  0.9102496
  0.92348565  0.89202128  0.89403621  0.87313433],0.899126881237
macro precision scores = [ 0.85542297  0.89672717  0.92262219  0.91873782  0.90885585  0.90894105
  0.92398944  0.89195743  0.89233066  0.87264544],0.899223001788
macro recall scores = [ 0.84982253  0.89093315  0.91803174  0.91652337  0.90690142  0.90790759
  0.92077627  0.88640422  0.89110841  0.86859322],0.895700192017
macro f1 scores = [ 0.85023032  0.89235412  0.91942869  0.91727111  0.90723883  0.90742691
  0.92171639  0.88770183  0.89120604  0.86937494],0.896394918532
weighted average precision scores = [ 0.85724489  0.89590769  0.9220795   0.9188334   0.90925143  0.9118957
  0.92371227  0.8929862   0.89471949  0.87530095],0.900193151369
weighted average recall scores = [ 0.85724489  0.89590769  0.9220795   0.9188334   0.90925143  0.9118957
  0.92371227  0.8929862   0.89471949  0.87530095],0.900193151369
weighted f1 scores = [ 0.85501513  0.89360055  0.92052098  0.91801699  0.90874236  0.91008578
  0.92306841  0.89132013  0.89387781  0.87300734],0.89872554924
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.899223001788 recall  0.895700192017 f1  0.896394918532
loaded (238169) terms
vectorizing done, 238169 terms vocabulary tokenized
vectorizing done, 238169 terms vocabulary tokenized
accuracy scores = [ 0.88636364  0.90851401  0.93703704  0.93697034  0.92948038  0.92193309
  0.93942614  0.91117021  0.91799787  0.89765458],0.918654730286
macro precision scores = [ 0.88539645  0.91177167  0.93802863  0.93803162  0.93063044  0.92062897
  0.93934859  0.9111237   0.91885246  0.89779141],0.919160393635
macro recall scores = [ 0.87927605  0.90488999  0.93523573  0.93588802  0.92786019  0.91934649
  0.93681494  0.90648249  0.91571753  0.89473943],0.915625085987
macro f1 scores = [ 0.88001607  0.90650639  0.93612356  0.93670283  0.92849242  0.91928691
  0.93770103  0.9076457   0.91653732  0.89547977],0.91644920088
weighted average precision scores = [ 0.88669371  0.91131764  0.93756477  0.93768074  0.93018151  0.92335394
  0.9397024   0.91186166  0.91922217  0.90021201],0.919779055805
weighted average recall scores = [ 0.88669371  0.91131764  0.93756477  0.93768074  0.93018151  0.92335394
  0.9397024   0.91186166  0.91922217  0.90021201],0.919779055805
weighted f1 scores = [ 0.88469917  0.90843048  0.9368272   0.93707971  0.92914485  0.92198763
  0.93924395  0.91059257  0.91791303  0.89813144],0.91840500394
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.919160393635 recall  0.915625085987 f1  0.91644920088
loaded (71706) terms
extended to (91464) terms
done loading vocabulary
vectorizing done, 91464 terms vocabulary tokenized
vectorizing done, 91464 terms vocabulary tokenized
accuracy scores = [ 0.85835095  0.89423585  0.92063492  0.91631356  0.9135737   0.91290494
  0.92454835  0.89202128  0.89510117  0.87420043],0.900188515257
macro precision scores = [ 0.85489179  0.89674899  0.92177579  0.91715132  0.91389256  0.91111686
  0.92474286  0.8923801   0.89430182  0.87389598],0.900089807533
macro recall scores = [ 0.85065182  0.89154841  0.91746879  0.91475142  0.91067041  0.91041947
  0.92135872  0.88710159  0.89266933  0.86997062],0.896661056572
macro f1 scores = [ 0.85042793  0.8928656   0.91882306  0.91553273  0.91121306  0.90995955
  0.92225863  0.88833084  0.89266469  0.87065374],0.897272980452
weighted average precision scores = [ 0.85746596  0.89618246  0.92187708  0.91729301  0.91415173  0.91435359
  0.92476361  0.89319113  0.89683516  0.87675738],0.901287110241
weighted average recall scores = [ 0.85746596  0.89618246  0.92187708  0.91729301  0.91415173  0.91435359
  0.92476361  0.89319113  0.89683516  0.87675738],0.901287110241
weighted f1 scores = [ 0.8560277   0.89415701  0.9205126   0.91640352  0.91292123  0.91282319
  0.92404972  0.89144643  0.89521164  0.87422796],0.899778100697
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.900089807533 recall  0.896661056572 f1  0.897272980452
loaded (204528) terms
vectorizing done, 204528 terms vocabulary tokenized
vectorizing done, 204528 terms vocabulary tokenized
accuracy scores = [ 0.88372093  0.90851401  0.93809524  0.93485169  0.92895016  0.92140202
  0.93836344  0.90851064  0.91746539  0.89498934],0.917486286329
macro precision scores = [ 0.88186098  0.91215051  0.93958222  0.93524424  0.93043276  0.91971974
  0.93842352  0.9085941   0.9174828   0.89565012],0.917914099031
macro recall scores = [ 0.8765713   0.9049002   0.93595198  0.93388252  0.92717663  0.91877116
  0.93594366  0.90406348  0.91506601  0.89214014],0.91444670932
macro f1 scores = [ 0.87717253  0.90657841  0.93714419  0.93435297  0.92795059  0.91863913
  0.93681727  0.90525203  0.91562658  0.8929939 ],0.915252760165
weighted average precision scores = [ 0.8838227   0.91135328  0.938845    0.93547432  0.92951494  0.92268811
  0.93877564  0.90912102  0.91881623  0.89784058],0.91862518236
weighted average recall scores = [ 0.8838227   0.91135328  0.938845    0.93547432  0.92951494  0.92268811
  0.93877564  0.90912102  0.91881623  0.89784058],0.91862518236
weighted f1 scores = [ 0.88214557  0.9083655   0.93791152  0.93495428  0.92849525  0.92147232
  0.93824929  0.90793827  0.91754776  0.89550705],0.917258681473
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.917914099031 recall  0.91444670932 f1  0.915252760165
loaded (38065) terms
extended to (48205) terms
done loading vocabulary
vectorizing done, 48205 terms vocabulary tokenized
vectorizing done, 48205 terms vocabulary tokenized
accuracy scores = [ 0.8255814   0.86779482  0.91164021  0.89194915  0.88971368  0.89962825
  0.90541977  0.88031915  0.87167199  0.84914712],0.879286553778
macro precision scores = [ 0.82410957  0.87008114  0.91409793  0.89321761  0.8903571   0.89936225
  0.90584725  0.8791561   0.87035457  0.85015229],0.879673581698
macro recall scores = [ 0.81741509  0.86360879  0.90909251  0.89069414  0.88831567  0.89643568
  0.90243695  0.87458348  0.86855999  0.84365754],0.87547998409
macro f1 scores = [ 0.8168036   0.86509387  0.91065812  0.8915298   0.88857684  0.89664816
  0.9033092   0.87554742  0.86863411  0.84447821],0.87612793275
weighted average precision scores = [ 0.82664552  0.87002372  0.91307971  0.89306531  0.89030375  0.90063007
  0.90604104  0.88106406  0.87215246  0.85383889],0.880684453442
weighted average recall scores = [ 0.82664552  0.87002372  0.91307971  0.89306531  0.89030375  0.90063007
  0.90604104  0.88106406  0.87215246  0.85383889],0.880684453442
weighted f1 scores = [ 0.82287954  0.86751625  0.91156651  0.8920821   0.88927664  0.89893963
  0.9050529   0.87957597  0.871143    0.84909924],0.878713177009
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.879673581698 recall  0.87547998409 f1  0.87612793275
loaded (241012) terms
vectorizing done, 241012 terms vocabulary tokenized
vectorizing done, 241012 terms vocabulary tokenized
accuracy scores = [ 0.88636364  0.90851401  0.93703704  0.93432203  0.9300106   0.92299522
  0.93942614  0.91223404  0.91693291  0.89712154],0.918495717338
macro precision scores = [ 0.88523777  0.91196328  0.93834889  0.93539675  0.93106979  0.92200027
  0.93932711  0.91237452  0.91761314  0.89754453],0.919087605276
macro recall scores = [ 0.8792914   0.90488484  0.9353831   0.93328119  0.92838103  0.92093379
  0.93654727  0.90788469  0.91467597  0.89453588],0.915579917578
macro f1 scores = [ 0.88004906  0.906547    0.93632022  0.9340713   0.9290163   0.92083257
  0.93751748  0.90903677  0.9154797   0.89516116],0.916403156914
weighted average precision scores = [ 0.88654844  0.91120005  0.93756061  0.93522314  0.9306466   0.92455639
  0.93975908  0.91304357  0.91791785  0.89976128],0.919621699897
weighted average recall scores = [ 0.88654844  0.91120005  0.93756061  0.93522314  0.9306466   0.92455639
  0.93975908  0.91304357  0.91791785  0.89976128],0.919621699897
weighted f1 scores = [ 0.88473456  0.9083606   0.93679123  0.93451174  0.92968827  0.92316602
  0.93923676  0.91174581  0.91681422  0.89754476],0.918259396576
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.919087605276 recall  0.915579917578 f1  0.916403156914
loaded (74549) terms
extended to (94709) terms
done loading vocabulary
vectorizing done, 94709 terms vocabulary tokenized
vectorizing done, 94709 terms vocabulary tokenized
accuracy scores = [ 0.85940803  0.89264939  0.92169312  0.91790254  0.91092259  0.91078067
  0.924017    0.89468085  0.89403621  0.87579957],0.900188998293
macro precision scores = [ 0.85669515  0.89626297  0.92314564  0.9188745   0.91082658  0.90925391
  0.92399593  0.89485133  0.89278471  0.87601534],0.900270607291
macro recall scores = [ 0.85183572  0.8899179   0.91880148  0.91630505  0.90878399  0.90824445
  0.92084852  0.889931    0.89134226  0.87148489],0.896749526269
macro f1 scores = [ 0.85188743  0.89149549  0.92011718  0.91722663  0.9090601   0.90777926
  0.92167633  0.89118731  0.89137536  0.87230379],0.897410886733
weighted average precision scores = [ 0.85931197  0.89502799  0.9229737   0.91892868  0.91125792  0.91247835
  0.92416654  0.89562452  0.89512429  0.87886957],0.901376353487
weighted average recall scores = [ 0.85931197  0.89502799  0.9229737   0.91892868  0.91125792  0.91247835
  0.92416654  0.89562452  0.89512429  0.87886957],0.901376353487
weighted f1 scores = [ 0.85739754  0.89253925  0.92153283  0.91806669  0.91041078  0.91067031
  0.92350027  0.8941683   0.89392516  0.87591138],0.89981225092
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.900270607291 recall  0.896749526269 f1  0.897410886733
loaded (149349) terms
vectorizing done, 149349 terms vocabulary tokenized
vectorizing done, 149349 terms vocabulary tokenized
accuracy scores = [ 0.87684989  0.90375463  0.93227513  0.93485169  0.92682927  0.91874668
  0.93198725  0.90904255  0.91267306  0.89392324],0.914093339597
macro precision scores = [ 0.87396516  0.90528643  0.93330569  0.93501845  0.92809886  0.91812286
  0.93139814  0.91011148  0.91408163  0.89503093],0.914441962875
macro recall scores = [ 0.86904569  0.90110565  0.93029357  0.93376353  0.9244385   0.91548701
  0.93005963  0.90492624  0.90984827  0.89127266],0.911024074349
macro f1 scores = [ 0.86918267  0.90213972  0.9312733   0.9341849   0.92527355  0.91573552
  0.93050498  0.90625257  0.91123483  0.89208245],0.911786448539
weighted average precision scores = [ 0.87646955  0.90496679  0.9327541   0.93536079  0.92735212  0.91978637
  0.93214741  0.91009083  0.91451303  0.89684237],0.915028335467
weighted average recall scores = [ 0.87646955  0.90496679  0.9327541   0.93536079  0.92735212  0.91978637
  0.93214741  0.91009083  0.91451303  0.89684237],0.915028335467
weighted f1 scores = [ 0.87482114  0.90348072  0.93204052  0.93489982  0.92626866  0.91835018
  0.93185431  0.90849075  0.91291186  0.89431706],0.913743502053
ng20_raw_stems_unigrams_df1_tf1  -->  precision  0.914441962875 recall  0.911024074349 f1  0.911786448539
loaded (1491727) terms
vectorizing done, 1491727 terms vocabulary tokenized
vectorizing done, 1491727 terms vocabulary tokenized
accuracy scores = [ 0.88477801  0.91433104  0.93915344  0.94226695  0.93478261  0.93096123
  0.94261424  0.9143617   0.91959531  0.89765458],0.922049912422
macro precision scores = [ 0.88483991  0.91737823  0.94168271  0.94350754  0.93694646  0.93195339
  0.94335597  0.9156491   0.92129878  0.89855697],0.92351690664
macro recall scores = [ 0.87538232  0.91085412  0.93657675  0.94132613  0.93301569  0.92873681
  0.94003754  0.90997684  0.91759646  0.89529799],0.918880066191
macro f1 scores = [ 0.87515693  0.91247189  0.93822182  0.94207188  0.93421357  0.92936893
  0.94117038  0.91135138  0.91865054  0.89590287],0.919858020482
weighted average precision scores = [ 0.885765    0.91687079  0.94009344  0.94317282  0.93630277  0.93361377
  0.9431302   0.91594596  0.92108227  0.90055069],0.923652770653
weighted average recall scores = [ 0.885765    0.91687079  0.94009344  0.94317282  0.93630277  0.93361377
  0.9431302   0.91594596  0.92108227  0.90055069],0.923652770653
weighted f1 scores = [ 0.88158182  0.91430137  0.93886234  0.94237929  0.93486739  0.93132044
  0.94242972  0.91391175  0.91959906  0.89812867],0.921738184068
ng20_raw_stems_bigrams_df1_tf1  -->  precision  0.92351690664 recall  0.918880066191 f1  0.919858020482
loaded (208752) terms
vectorizing done, 208752 terms vocabulary tokenized
vectorizing done, 208752 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.91115812  0.93227513  0.93538136  0.93107105  0.92193309
  0.93783209  0.90744681  0.91586794  0.8891258 ],0.91636981525
macro precision scores = [ 0.88002477  0.91341657  0.93332602  0.93637681  0.93198067  0.92131763
  0.9383565   0.90720429  0.91746575  0.89009864],0.916956765742
macro recall scores = [ 0.87375187  0.90790872  0.93019533  0.93429655  0.92881918  0.91905538
  0.9357055   0.90284179  0.91315009  0.8856915 ],0.913141592829
macro f1 scores = [ 0.87400159  0.90940664  0.93122606  0.93500227  0.92961825  0.9193634
  0.93669098  0.90397551  0.91446655  0.88666302],0.914041427589
weighted average precision scores = [ 0.88164103  0.91305571  0.9329169   0.93626183  0.93167854  0.92340584
  0.93815418  0.90817497  0.91776697  0.89266501],0.917572099126
weighted average recall scores = [ 0.88164103  0.91305571  0.9329169   0.93626183  0.93167854  0.92340584
  0.93815418  0.90817497  0.91776697  0.89266501],0.917572099126
weighted f1 scores = [ 0.8794349   0.91109594  0.93211177  0.93549136  0.93070959  0.92189382
  0.9377176   0.90691983  0.91604362  0.88967974],0.916109816734
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.916956765742 recall  0.913141592829 f1  0.914041427589
loaded (59403) terms
extended to (76544) terms
done loading vocabulary
vectorizing done, 76544 terms vocabulary tokenized
vectorizing done, 76544 terms vocabulary tokenized
accuracy scores = [ 0.85623679  0.89212057  0.92116402  0.91313559  0.9135737   0.91343601
  0.9261424   0.88776596  0.89403621  0.86567164],0.898328288898
macro precision scores = [ 0.85482904  0.89482628  0.92350379  0.91300474  0.91527278  0.91354799
  0.92614743  0.88681011  0.89327694  0.86472556],0.898594465063
macro recall scores = [ 0.849088    0.88854848  0.91858457  0.91148394  0.91177229  0.91108383
  0.92356587  0.88227392  0.89117132  0.86090045],0.894847266525
macro f1 scores = [ 0.84947988  0.89003168  0.92013174  0.91196698  0.91253126  0.91124203
  0.9242775   0.88332632  0.89167288  0.86163764],0.895629789658
weighted average precision scores = [ 0.85688243  0.89441635  0.92285895  0.91400882  0.91467047  0.91487334
  0.9267024   0.88797084  0.89510912  0.86752639],0.899501909724
weighted average recall scores = [ 0.85688243  0.89441635  0.92285895  0.91400882  0.91467047  0.91487334
  0.9267024   0.88797084  0.89510912  0.86752639],0.899501909724
weighted f1 scores = [ 0.85449865  0.89191689  0.92116811  0.91330185  0.91327375  0.91311589
  0.92595016  0.88686745  0.89404669  0.86544276],0.897958218292
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.898594465063 recall  0.894847266525 f1  0.895629789658
loaded (160445) terms
vectorizing done, 160445 terms vocabulary tokenized
vectorizing done, 160445 terms vocabulary tokenized
accuracy scores = [ 0.87737844  0.90481227  0.93333333  0.93538136  0.92417815  0.92033988
  0.93517535  0.90851064  0.91320554  0.89445629],0.914677124287
macro precision scores = [ 0.87588542  0.90760731  0.93483246  0.93561404  0.92580707  0.91999277
  0.93499013  0.90896252  0.91358916  0.89589179],0.915317268037
macro recall scores = [ 0.86942553  0.90110423  0.93146201  0.9344789   0.92188652  0.91703232
  0.93365628  0.90404244  0.9105294   0.89165918],0.911527679815
macro f1 scores = [ 0.86978453  0.90271376  0.93258402  0.93477894  0.92278466  0.91730563
  0.93408573  0.90540231  0.91153751  0.8926476 ],0.912362469205
weighted average precision scores = [ 0.87738745  0.9070789   0.93400699  0.93607483  0.92489525  0.92183083
  0.93542336  0.90934787  0.91454268  0.8979092 ],0.915849736509
weighted average recall scores = [ 0.87738745  0.9070789   0.93400699  0.93607483  0.92489525  0.92183083
  0.93542336  0.90934787  0.91454268  0.8979092 ],0.915849736509
weighted f1 scores = [ 0.87521692  0.90461859  0.93316055  0.93546037  0.92364457  0.9200289
  0.93507132  0.90802155  0.91338238  0.89506123],0.914366637366
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.915317268037 recall  0.911527679815 f1  0.912362469205
loaded (11096) terms
extended to (16351) terms
done loading vocabulary
vectorizing done, 16351 terms vocabulary tokenized
vectorizing done, 16351 terms vocabulary tokenized
accuracy scores = [ 0.79386892  0.83659439  0.86402116  0.86652542  0.85418876  0.86404673
  0.87460149  0.84734043  0.83493078  0.80703625],0.844315433531
macro precision scores = [ 0.78946298  0.84135506  0.86681031  0.86723511  0.85518795  0.86368683
  0.87430588  0.84724214  0.83344072  0.80779314],0.844652012088
macro recall scores = [ 0.78573669  0.8329935   0.85943168  0.86431081  0.85118561  0.86121142
  0.87238077  0.84132231  0.83220022  0.80183957],0.840261256037
macro f1 scores = [ 0.78439215  0.83504762  0.86100542  0.86530048  0.85168852  0.86105847
  0.87279217  0.84222815  0.83198742  0.80260052],0.840810093212
weighted average precision scores = [ 0.79232456  0.8403432   0.86591472  0.8682352   0.8550032   0.86402613
  0.87450253  0.8478942   0.83498649  0.81145944],0.845468966232
weighted average recall scores = [ 0.79232456  0.8403432   0.86591472  0.8682352   0.8550032   0.86402613
  0.87450253  0.8478942   0.83498649  0.81145944],0.845468966232
weighted f1 scores = [ 0.79064067  0.8367037   0.86324548  0.86690316  0.8532398   0.86276203
  0.8740809   0.84590742  0.83414866  0.80705571],0.843468752705
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.844652012088 recall  0.840261256037 f1  0.840810093212
loaded (185015) terms
vectorizing done, 185015 terms vocabulary tokenized
vectorizing done, 185015 terms vocabulary tokenized
accuracy scores = [ 0.87737844  0.90428345  0.93439153  0.93167373  0.92895016  0.92140202
  0.93411265  0.90638298  0.91373802  0.89339019],0.914570315967
macro precision scores = [ 0.8759506   0.90640597  0.93529911  0.93180851  0.93029671  0.92054344
  0.9336509   0.90664924  0.91568652  0.89453866],0.915082966948
macro recall scores = [ 0.86952002  0.90074458  0.93212921  0.93079215  0.92705729  0.91772794
  0.93181     0.90208182  0.91113609  0.89060557],0.911360467053
macro f1 scores = [ 0.86975411  0.9020966   0.9331438   0.93103894  0.92794351  0.9179949
  0.93246425  0.90333177  0.91266531  0.89154904],0.912198224929
weighted average precision scores = [ 0.87758677  0.90623797  0.93480073  0.93234146  0.92949554  0.92254929
  0.93452363  0.9071418   0.91584349  0.8961543 ],0.915667496876
weighted average recall scores = [ 0.87758677  0.90623797  0.93480073  0.93234146  0.92949554  0.92254929
  0.93452363  0.9071418   0.91584349  0.8961543 ],0.915667496876
weighted f1 scores = [ 0.87520431  0.90407255  0.93408504  0.93175036  0.92860942  0.92101809
  0.93406947  0.90588993  0.91410174  0.89373924],0.914254014211
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.915082966948 recall  0.911360467053 f1  0.912198224929
loaded (35666) terms
extended to (43305) terms
done loading vocabulary
vectorizing done, 43305 terms vocabulary tokenized
vectorizing done, 43305 terms vocabulary tokenized
accuracy scores = [ 0.81818182  0.86462189  0.90687831  0.88771186  0.88229056  0.8874137
  0.90382572  0.87287234  0.86741214  0.84328358],0.873449192663
macro precision scores = [ 0.81360203  0.86459531  0.9084688   0.88874001  0.88285972  0.88587277
  0.90426369  0.87068562  0.86566708  0.84287369],0.87276287053
macro recall scores = [ 0.80989089  0.85943605  0.90428093  0.88527585  0.88007005  0.88378216
  0.90054372  0.86657653  0.86366597  0.83823976],0.869176191053
macro f1 scores = [ 0.80905189  0.8606115   0.90574399  0.88641143  0.88044483  0.88380171
  0.90130181  0.86730528  0.86402827  0.83899486],0.869769557471
weighted average precision scores = [ 0.81776905  0.86588175  0.90782783  0.88979134  0.88263069  0.88829955
  0.90484936  0.87325341  0.86784117  0.8465405 ],0.87446846542
weighted average recall scores = [ 0.81776905  0.86588175  0.90782783  0.88979134  0.88263069  0.88829955
  0.90484936  0.87325341  0.86784117  0.8465405 ],0.87446846542
weighted f1 scores = [ 0.81571909  0.86411218  0.90682084  0.88815139  0.88149099  0.88689615
  0.90346072  0.87185472  0.86702375  0.84338982],0.87289196482
ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.87276287053 recall  0.869176191053 f1  0.869769557471
loaded (211394) terms
vectorizing done, 211394 terms vocabulary tokenized
vectorizing done, 211394 terms vocabulary tokenized
accuracy scores = [ 0.88107822  0.9106293   0.93439153  0.93538136  0.9300106   0.92246415
  0.93836344  0.90851064  0.91693291  0.88859275],0.916635490782
macro precision scores = [ 0.87956413  0.91337937  0.93588002  0.9364002   0.93078143  0.92194628
  0.93873191  0.90856465  0.91737219  0.8898301 ],0.917245026641
macro recall scores = [ 0.87324682  0.90739368  0.93222594  0.93430718  0.92782992  0.91970473
  0.93588796  0.90392249  0.91464256  0.88534958],0.91345108616
macro f1 scores = [ 0.873453    0.90897632  0.93345719  0.93501071  0.92856507  0.91997522
  0.93689918  0.90513446  0.91557035  0.88629663],0.914333812065
weighted average precision scores = [ 0.88109736  0.91265273  0.93508582  0.93625557  0.93044971  0.92406574
  0.93868638  0.90934327  0.91799396  0.8923645 ],0.917799503894
weighted average recall scores = [ 0.88109736  0.91265273  0.93508582  0.93625557  0.93044971  0.92406574
  0.93868638  0.90934327  0.91799396  0.8923645 ],0.917799503894
weighted f1 scores = [ 0.87882757  0.91050531  0.93421393  0.93548003  0.929609    0.92246378
  0.93819437  0.9079727   0.91705641  0.88921319],0.916353628049
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.917245026641 recall  0.91345108616 f1  0.914333812065
loaded (62045) terms
extended to (79424) terms
done loading vocabulary
vectorizing done, 79424 terms vocabulary tokenized
vectorizing done, 79424 terms vocabulary tokenized
accuracy scores = [ 0.85676533  0.89159175  0.92063492  0.91684322  0.9135737   0.9118428
  0.9250797   0.88776596  0.89190628  0.86833689],0.898434055422
macro precision scores = [ 0.85441889  0.89438018  0.92286635  0.91677824  0.91511008  0.91174564
  0.92494345  0.88677818  0.89093895  0.86781905],0.898577900192
macro recall scores = [ 0.84901115  0.88821668  0.91779618  0.91504264  0.91177229  0.90964104
  0.92243581  0.8824784   0.88904717  0.86363337],0.894907473184
macro f1 scores = [ 0.84907751  0.88962932  0.91940783  0.91561825  0.91251483  0.9095949
  0.92320802  0.88353675  0.88940676  0.86454847],0.895654266178
weighted average precision scores = [ 0.85696795  0.8938193   0.92215718  0.91785784  0.91449574  0.91323962
  0.9255711   0.88813245  0.8930536   0.87055335],0.899584813407
weighted average recall scores = [ 0.85696795  0.8938193   0.92215718  0.91785784  0.91449574  0.91323962
  0.9255711   0.88813245  0.8930536   0.87055335],0.899584813407
weighted f1 scores = [ 0.85467037  0.89132655  0.92056013  0.91705973  0.91325367  0.91146187
  0.92492284  0.88703424  0.89191855  0.86827453],0.898048247782
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.898577900192 recall  0.894907473184 f1  0.895654266178
loaded (227804) terms
vectorizing done, 227804 terms vocabulary tokenized
vectorizing done, 227804 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.91115812  0.93439153  0.93485169  0.93107105  0.92193309
  0.93783209  0.90957447  0.91480298  0.8901919 ],0.916794222975
macro precision scores = [ 0.88048604  0.91337925  0.93523286  0.93595761  0.93192861  0.92138716
  0.93821249  0.90943973  0.91665817  0.89078785],0.917346975809
macro recall scores = [ 0.87426734  0.90790367  0.93222079  0.93379655  0.92881908  0.91905012
  0.93537239  0.90518194  0.91210854  0.88684064],0.913556106723
macro f1 scores = [ 0.87441413  0.90936542  0.93320508  0.93453021  0.92958528  0.91942043
  0.93640368  0.90636174  0.91351494  0.88770825],0.914450916885
weighted average precision scores = [ 0.8820303   0.91311716  0.93486802  0.9357824   0.93165542  0.92345238
  0.93816103  0.91035149  0.91675303  0.89334346],0.917951467848
weighted average recall scores = [ 0.8820303   0.91311716  0.93486802  0.9357824   0.93165542  0.92345238
  0.93816103  0.91035149  0.91675303  0.89334346],0.917951467848
weighted f1 scores = [ 0.8798144   0.91111228  0.9341581   0.93497381  0.93069177  0.92194051
  0.93768906  0.90914445  0.91498872  0.89067212],0.916518523775
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.917346975809 recall  0.913556106723 f1  0.914450916885
loaded (78455) terms
extended to (96203) terms
done loading vocabulary
vectorizing done, 96203 terms vocabulary tokenized
vectorizing done, 96203 terms vocabulary tokenized
accuracy scores = [ 0.85782241  0.89370703  0.92169312  0.91260593  0.9135737   0.91449814
  0.9261424   0.8893617   0.8972311   0.86886994],0.899550547635
macro precision scores = [ 0.85455679  0.89698749  0.92376912  0.91276197  0.91498046  0.91468877
  0.92607908  0.88863028  0.89667303  0.86836359],0.899749058332
macro recall scores = [ 0.850004    0.89036749  0.91884422  0.91090742  0.91145782  0.91203822
  0.92328736  0.88438731  0.89453611  0.86434508],0.896017501836
macro f1 scores = [ 0.84952704  0.89203166  0.92043356  0.91156833  0.91217766  0.91235454
  0.92402593  0.88550604  0.89480179  0.86500042],0.896742697343
weighted average precision scores = [ 0.8574547   0.89624649  0.92340409  0.9135001   0.91443066  0.91590908
  0.92679318  0.8899773   0.89884542  0.87108   ],0.900764102186
weighted average recall scores = [ 0.8574547   0.89624649  0.92340409  0.9135001   0.91443066  0.91590908
  0.92679318  0.8899773   0.89884542  0.87108   ],0.900764102186
weighted f1 scores = [ 0.85537145  0.89363794  0.92173646  0.9127927   0.91313375  0.91423002
  0.92593907  0.8887917   0.89728803  0.86863904],0.899156016334
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.899749058332 recall  0.896017501836 f1  0.896742697343
loaded (191637) terms
vectorizing done, 191637 terms vocabulary tokenized
vectorizing done, 191637 terms vocabulary tokenized
accuracy scores = [ 0.87790698  0.90639873  0.93492063  0.93379237  0.92841994  0.92246415
  0.93623804  0.90585106  0.91373802  0.89339019],0.915312012423
macro precision scores = [ 0.87581309  0.90945091  0.93628876  0.9339463   0.92985291  0.92236841
  0.93551673  0.90555013  0.91444562  0.89446689],0.915769975185
macro recall scores = [ 0.86992574  0.90250897  0.93314     0.93282802  0.92654129  0.91921228
  0.93425794  0.90137652  0.91105002  0.89035336],0.912119413697
macro f1 scores = [ 0.87018908  0.90421892  0.93419535  0.93308119  0.92736576  0.91967812
  0.93466849  0.90249842  0.91214434  0.89127576],0.912931543446
weighted average precision scores = [ 0.87784764  0.90877909  0.93548237  0.93462115  0.9289616   0.92418163
  0.93638185  0.90643262  0.91527076  0.89660351],0.916456222673
weighted average recall scores = [ 0.87784764  0.90877909  0.93548237  0.93462115  0.9289616   0.92418163
  0.93638185  0.90643262  0.91527076  0.89660351],0.916456222673
weighted f1 scores = [ 0.87582062  0.90620338  0.9347339   0.93390372  0.92797563  0.92233336
  0.93610022  0.90533472  0.91393573  0.89386398],0.915020525727
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.915769975185 recall  0.912119413697 f1  0.912931543446
loaded (42288) terms
extended to (51312) terms
done loading vocabulary
vectorizing done, 51312 terms vocabulary tokenized
vectorizing done, 51312 terms vocabulary tokenized
accuracy scores = [ 0.81712474  0.87043892  0.90582011  0.89777542  0.89289502  0.89803505
  0.90223167  0.87925532  0.87060703  0.84381663],0.877799990031
macro precision scores = [ 0.81099854  0.87046043  0.90763466  0.8991328   0.89329641  0.89863582
  0.90182969  0.87835147  0.86977274  0.84376804],0.877388061419
macro recall scores = [ 0.80844043  0.86504036  0.90220555  0.89643958  0.89091565  0.89478468
  0.89893188  0.87382398  0.86743509  0.83897131],0.873698849687
macro f1 scores = [ 0.8073021   0.86618231  0.90394204  0.89739235  0.89134304  0.89529299
  0.89950123  0.87486599  0.86777132  0.83952461],0.874311798573
weighted average precision scores = [ 0.81637341  0.87209285  0.90686689  0.89947474  0.8926735   0.899497
  0.90290641  0.87951193  0.87208263  0.846919  ],0.878839833788
weighted average recall scores = [ 0.81637341  0.87209285  0.90686689  0.89947474  0.8926735   0.899497
  0.90290641  0.87951193  0.87208263  0.846919  ],0.878839833788
weighted f1 scores = [ 0.81459498  0.86997873  0.90557764  0.89822664  0.89208747  0.89748278
  0.9018188   0.87834782  0.87056518  0.84359794],0.877227798604
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.877388061419 recall  0.873698849687 f1  0.874311798573
loaded (230266) terms
vectorizing done, 230266 terms vocabulary tokenized
vectorizing done, 230266 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.9106293   0.93439153  0.93485169  0.92948038  0.92193309
  0.93730074  0.90904255  0.91693291  0.89072495],0.916742245092
macro precision scores = [ 0.88048065  0.91337302  0.93585653  0.93585281  0.93027649  0.92146981
  0.93761721  0.90898923  0.91851947  0.89205471],0.917448993823
macro recall scores = [ 0.87427249  0.90739368  0.9322311   0.93376794  0.92729867  0.91906053
  0.93485704  0.90443269  0.91471017  0.88750795],0.913553225347
macro f1 scores = [ 0.87444348  0.90901287  0.93342731  0.93443832  0.92805433  0.91947515
  0.93583888  0.90563477  0.91584886  0.8884757 ],0.914464967565
weighted average precision scores = [ 0.88205794  0.91265951  0.93506116  0.93591423  0.92993627  0.92356398
  0.9375416   0.90988111  0.91864132  0.8944392 ],0.917969631611
weighted average recall scores = [ 0.88205794  0.91265951  0.93506116  0.93591423  0.92993627  0.92356398
  0.9375416   0.90988111  0.91864132  0.8944392 ],0.917969631611
weighted f1 scores = [ 0.87985695  0.91055041  0.93417992  0.9350138   0.92909487  0.92200451
  0.93710356  0.90854105  0.91708118  0.89129658],0.916472282522
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.917448993823 recall  0.913553225347 f1  0.914464967565
loaded (80917) terms
extended to (98882) terms
done loading vocabulary
vectorizing done, 98882 terms vocabulary tokenized
vectorizing done, 98882 terms vocabulary tokenized
accuracy scores = [ 0.85570825  0.89476467  0.92222222  0.91419492  0.9135737   0.91449814
  0.92667375  0.88829787  0.89563365  0.87046908],0.899603625936
macro precision scores = [ 0.852791    0.89823789  0.92409334  0.91444628  0.91481714  0.91432931
  0.92671571  0.8878359   0.89535909  0.87050173],0.899912738906
macro recall scores = [ 0.84785322  0.89153439  0.91961045  0.91273704  0.91118983  0.91188834
  0.92367246  0.88354992  0.893169    0.86672828],0.896193293276
macro f1 scores = [ 0.84757545  0.89321531  0.92107203  0.91332914  0.91194852  0.91206402
  0.9245564   0.88471147  0.89355646  0.86746406],0.896949285082
weighted average precision scores = [ 0.85586925  0.897121    0.92344947  0.91523102  0.91435734  0.91587763
  0.92732536  0.88903659  0.89730381  0.87309622],0.900866768441
weighted average recall scores = [ 0.85586925  0.897121    0.92344947  0.91523102  0.91435734  0.91587763
  0.92732536  0.88903659  0.89730381  0.87309622],0.900866768441
weighted f1 scores = [ 0.85345795  0.89458843  0.92212991  0.91445843  0.9131213   0.9141796
  0.92648871  0.88780905  0.89579116  0.87062384],0.899264839017
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.899912738906 recall  0.896193293276 f1  0.896949285082
loaded (173377) terms
vectorizing done, 173377 terms vocabulary tokenized
vectorizing done, 173377 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.90322581  0.93597884  0.9375      0.92841994  0.91768455
  0.93517535  0.90638298  0.91267306  0.89712154],0.915629734702
macro precision scores = [ 0.88265463  0.90659347  0.93722895  0.9384888   0.92988056  0.9171863
  0.93592718  0.90595507  0.91271681  0.89840726],0.916503903519
macro recall scores = [ 0.87626283  0.90041309  0.93404667  0.93726008  0.92656245  0.9158027
  0.93263203  0.90216785  0.90985879  0.89464381],0.912965030122
macro f1 scores = [ 0.87749462  0.90184098  0.93516174  0.93761763  0.92745965  0.91588912
  0.93373018  0.90314845  0.91073668  0.89554414],0.913862318721
weighted average precision scores = [ 0.88280106  0.90569981  0.93627653  0.93848573  0.92899042  0.9187777
  0.93554011  0.90699275  0.91374237  0.89994012],0.916724659352
weighted average recall scores = [ 0.88280106  0.90569981  0.93627653  0.93848573  0.92899042  0.9187777
  0.93554011  0.90699275  0.91374237  0.89994012],0.916724659352
weighted f1 scores = [ 0.88086868  0.90309983  0.93572902  0.93773377  0.92806185  0.91763533
  0.93490682  0.90590859  0.91269003  0.89754888],0.915418278966
ng20_raw_unigrams_stopwords  -->  precision  0.916503903519 recall  0.912965030122 f1  0.913862318721
loaded (1726872) terms
vectorizing done, 1726872 terms vocabulary tokenized
vectorizing done, 1726872 terms vocabulary tokenized
accuracy scores = [ 0.89006342  0.90904283  0.94021164  0.93961864  0.92788971  0.91927775
  0.93995749  0.91170213  0.91533546  0.89498934],0.918808842763
macro precision scores = [ 0.89151882  0.91149598  0.94156105  0.94040429  0.93017996  0.91836493
  0.94024572  0.9109182   0.91617371  0.8962827 ],0.91971453858
macro recall scores = [ 0.88461774  0.90620165  0.93916943  0.93925209  0.92663865  0.91639086
  0.93775607  0.90841563  0.91338836  0.89238263],0.916421310696
macro f1 scores = [ 0.88619769  0.90742098  0.9398498   0.93959155  0.92752918  0.91640565
  0.93865038  0.90906437  0.91423434  0.89330058],0.917224453505
weighted average precision scores = [ 0.8912945   0.91122369  0.94062717  0.94043838  0.92925297  0.92053422
  0.94023181  0.91201842  0.91619523  0.89786277],0.919967917794
weighted average recall scores = [ 0.8912945   0.91122369  0.94062717  0.94043838  0.92925297  0.92053422
  0.94023181  0.91201842  0.91619523  0.89786277],0.919967917794
weighted f1 scores = [ 0.88919436  0.90897353  0.93992733  0.93978574  0.92778112  0.91900533
  0.93980572  0.91130581  0.91525263  0.89544641],0.918647797243
ng20_raw_bigrams_stopwords  -->  precision  0.91971453858 recall  0.916421310696 f1  0.917224453505
loaded (166113) terms
vectorizing done, 166113 terms vocabulary tokenized
vectorizing done, 166113 terms vocabulary tokenized
accuracy scores = [ 0.88424947  0.90375463  0.93809524  0.93273305  0.9300106   0.91874668
  0.93304995  0.90478723  0.91480298  0.89605544],0.915628527277
macro precision scores = [ 0.8837312   0.90713365  0.93897528  0.93354254  0.9312954   0.9171854
  0.93290769  0.90448486  0.91534923  0.89643133],0.916103658207
macro recall scores = [ 0.87839471  0.90092725  0.93637728  0.9318497   0.92821894  0.91634294
  0.93053155  0.90024372  0.91231043  0.89349959],0.912869610737
macro f1 scores = [ 0.87952979  0.90252868  0.93729893  0.93238219  0.92898968  0.91623208
  0.93139336  0.90128055  0.9132384   0.89419147],0.913706512175
weighted average precision scores = [ 0.88509488  0.90592918  0.93835501  0.93349468  0.93044241  0.91949043
  0.93316587  0.90534011  0.9159818   0.89838082],0.916567518684
weighted average recall scores = [ 0.88509488  0.90592918  0.93835501  0.93349468  0.93044241  0.91949043
  0.93316587  0.90534011  0.9159818   0.89838082],0.916567518684
weighted f1 scores = [ 0.88340153  0.9036265   0.93789155  0.9328035   0.9295791   0.91864483
  0.93284627  0.9041382   0.91484018  0.8964309 ],0.915420255655
ng20_raw_lemmas_unigrams_stopwords_df1_tf1  -->  precision  0.916103658207 recall  0.912869610737 f1  0.913706512175
loaded (1659720) terms
vectorizing done, 1659720 terms vocabulary tokenized
vectorizing done, 1659720 terms vocabulary tokenized
accuracy scores = [ 0.88689218  0.90745637  0.94179894  0.93538136  0.93107105  0.92140202
  0.94420829  0.90744681  0.91640043  0.89658849],0.91886459252
macro precision scores = [ 0.88675282  0.90928949  0.94327106  0.93621764  0.9333142   0.92150217
  0.94455855  0.90674287  0.917595    0.89789189],0.919713567063
macro recall scores = [ 0.8800337   0.90445865  0.94069577  0.93465149  0.92968497  0.91866796
  0.94179099  0.90320671  0.91430997  0.89400166],0.916150187819
macro f1 scores = [ 0.88104117  0.90565061  0.94146468  0.93516805  0.93070112  0.91918512
  0.94281637  0.90412352  0.91535665  0.89492852],0.91704358152
weighted average precision scores = [ 0.88750248  0.90865262  0.94230797  0.93611988  0.93247956  0.92299599
  0.94438929  0.90776151  0.91752383  0.89939589],0.919912901842
weighted average recall scores = [ 0.88750248  0.90865262  0.94230797  0.93611988  0.93247956  0.92299599
  0.94438929  0.90776151  0.91752383  0.89939589],0.919912901842
weighted f1 scores = [ 0.88534809  0.90710399  0.94155979  0.93548182  0.93106967  0.92135945
  0.94402305  0.90688725  0.91641696  0.89698038],0.91862304599
ng20_raw_lemmas_bigrams_stopwords_df1_tf1  -->  precision  0.919713567063 recall  0.916150187819 f1  0.91704358152
loaded (217211) terms
done loading vocabulary
vectorizing done, 217211 terms vocabulary tokenized
vectorizing done, 217211 terms vocabulary tokenized
accuracy scores = [ 0.88636364  0.90745637  0.93968254  0.93220339  0.9321315   0.92405736
  0.93783209  0.90797872  0.91906283  0.89712154],0.918388997358
macro precision scores = [ 0.88470825  0.90987421  0.94114796  0.93308269  0.93342378  0.92301929
  0.93771282  0.90742312  0.91994782  0.89750252],0.91878424661
macro recall scores = [ 0.87999346  0.90387926  0.93795801  0.9312509   0.93066403  0.92159475
  0.93497446  0.90364244  0.91654205  0.89484504],0.915534441084
macro f1 scores = [ 0.88084165  0.90533895  0.93902269  0.93185473  0.9313343   0.92172001
  0.93591588  0.90458522  0.91769476  0.89528187],0.916359005989
weighted average precision scores = [ 0.88640473  0.90943974  0.9401776   0.93303475  0.93256062  0.92552148
  0.93815254  0.90853892  0.92032951  0.89943256],0.919359245006
weighted average recall scores = [ 0.88640473  0.90943974  0.9401776   0.93303475  0.93256062  0.92552148
  0.93815254  0.90853892  0.92032951  0.89943256],0.919359245006
weighted f1 scores = [ 0.88510259  0.90721667  0.93945742  0.93231099  0.93173307  0.92425987
  0.93764264  0.90747539  0.91918731  0.89738423],0.918177017085
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.91878424661 recall  0.915534441084 f1  0.916359005989
loaded (51098) terms
extended to (68835) terms
done loading vocabulary
vectorizing done, 68835 terms vocabulary tokenized
vectorizing done, 68835 terms vocabulary tokenized
accuracy scores = [ 0.85887949  0.88841883  0.92063492  0.91419492  0.91304348  0.91237387
  0.91657811  0.88829787  0.89669862  0.87633262],0.898545272314
macro precision scores = [ 0.85822438  0.88967497  0.92193518  0.91511594  0.914354    0.91017392
  0.91603064  0.88850629  0.8956006   0.87607587],0.898569178249
macro recall scores = [ 0.85404149  0.8858349   0.91835621  0.91287477  0.91152688  0.91017977
  0.91343234  0.88312601  0.89409365  0.87271407],0.895618009454
macro f1 scores = [ 0.85485075  0.88674192  0.91945821  0.91350321  0.91216482  0.90976231
  0.91405755  0.88435558  0.89449865  0.87319721],0.896259020066
weighted average precision scores = [ 0.85963894  0.88986766  0.92166224  0.91540452  0.91378368  0.91282456
  0.91667769  0.88893844  0.89763493  0.87857627],0.899500892941
weighted average recall scores = [ 0.85963894  0.88986766  0.92166224  0.91540452  0.91378368  0.91282456
  0.91667769  0.88893844  0.89763493  0.87857627],0.899500892941
weighted f1 scores = [ 0.85807827  0.88828536  0.92050022  0.91431605  0.91270083  0.91217679
  0.91607608  0.88736899  0.89683084  0.87624772],0.898258115337
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.898569178249 recall  0.895618009454 f1  0.896259020066
loaded (174244) terms
done loading vocabulary
vectorizing done, 174244 terms vocabulary tokenized
vectorizing done, 174244 terms vocabulary tokenized
accuracy scores = [ 0.88424947  0.90639873  0.93862434  0.93220339  0.92948038  0.91980882
  0.934644    0.90265957  0.91586794  0.89658849],0.91605251292
macro precision scores = [ 0.88283707  0.90969874  0.93947457  0.93280108  0.93075047  0.91865417
  0.93443485  0.90196848  0.91621819  0.89687353],0.916371116108
macro recall scores = [ 0.87770047  0.90347333  0.93691392  0.9312509   0.92730509  0.91795118
  0.93191829  0.89775412  0.91305706  0.89430604],0.913163040422
macro f1 scores = [ 0.87863158  0.90504549  0.9378018   0.93174832  0.92817158  0.91781934
  0.93278099  0.89880759  0.91407589  0.89488965],0.913977223309
weighted average precision scores = [ 0.88439649  0.90861748  0.93886928  0.93286911  0.92998176  0.92073515
  0.93472603  0.90298003  0.91691301  0.8987751 ],0.916886344275
weighted average recall scores = [ 0.88439649  0.90861748  0.93886928  0.93286911  0.92998176  0.92073515
  0.93472603  0.90298003  0.91691301  0.8987751 ],0.916886344275
weighted f1 scores = [ 0.88298251  0.90625283  0.93839593  0.93225942  0.9290203   0.91981682
  0.93436902  0.90195947  0.91587239  0.89697248],0.915790116511
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.916371116108 recall  0.913163040422 f1  0.913977223309
loaded (8131) terms
extended to (13305) terms
done loading vocabulary
vectorizing done, 13305 terms vocabulary tokenized
vectorizing done, 13305 terms vocabulary tokenized
accuracy scores = [ 0.78224101  0.82337388  0.85555556  0.84745763  0.84517497  0.84705258
  0.8618491   0.82765957  0.80830671  0.79317697],0.829184797562
macro precision scores = [ 0.77968449  0.82610882  0.85487477  0.84751699  0.84465727  0.84356473
  0.86049547  0.82662425  0.8082672   0.79232311],0.828411709899
macro recall scores = [ 0.77549835  0.81897422  0.85224288  0.84433429  0.8436391   0.84361285
  0.85816244  0.82016455  0.80461082  0.7867359 ],0.824797539103
macro f1 scores = [ 0.77529542  0.8210077   0.85283285  0.84528685  0.84330044  0.84244609
  0.85857789  0.82069787  0.80506562  0.78780229],0.825231301886
weighted average precision scores = [ 0.78243002  0.82646685  0.85627806  0.84833573  0.84532017  0.84671577
  0.86167332  0.82779815  0.81067135  0.79801339],0.830370280697
weighted average recall scores = [ 0.78243002  0.82646685  0.85627806  0.84833573  0.84532017  0.84671577
  0.86167332  0.82779815  0.81067135  0.79801339],0.830370280697
weighted f1 scores = [ 0.78058362  0.82362417  0.85520784  0.8472706   0.84440223  0.84575527
  0.86108803  0.82553667  0.80811965  0.79387213],0.828546020501
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.828411709899 recall  0.824797539103 f1  0.825231301886
loaded (206782) terms
vectorizing done, 206782 terms vocabulary tokenized
vectorizing done, 206782 terms vocabulary tokenized
accuracy scores = [ 0.88477801  0.90904283  0.93915344  0.93167373  0.92841994  0.92193309
  0.9357067   0.90638298  0.91853035  0.89605544],0.917167649927
macro precision scores = [ 0.8830058   0.9121271   0.94017067  0.93262316  0.92981185  0.92059575
  0.93570827  0.90557196  0.91893289  0.8965751 ],0.917512255475
macro recall scores = [ 0.87878216  0.90570988  0.93740341  0.93075606  0.9263993   0.91897147
  0.93325702  0.90163036  0.91605826  0.89365154],0.914261944266
macro f1 scores = [ 0.87966884  0.90730228  0.93828789  0.93136688  0.92717272  0.91909166
  0.93412284  0.90270298  0.91696448  0.89420585],0.915088641327
weighted average precision scores = [ 0.88490888  0.91117538  0.9396101   0.93252567  0.92901932  0.9232898
  0.93605428  0.90670597  0.91982942  0.89883865],0.918195748548
weighted average recall scores = [ 0.88490888  0.91117538  0.9396101   0.93252567  0.92901932  0.9232898
  0.93605428  0.90670597  0.91982942  0.89883865],0.918195748548
weighted f1 scores = [ 0.88381496  0.90880938  0.9389196   0.93177975  0.92793171  0.92201596
  0.93558141  0.90581228  0.91868565  0.89652775],0.916987845436
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.917512255475 recall  0.914261944266 f1  0.915088641327
loaded (40669) terms
extended to (49080) terms
done loading vocabulary
vectorizing done, 49080 terms vocabulary tokenized
vectorizing done, 49080 terms vocabulary tokenized
accuracy scores = [ 0.82452431  0.86144897  0.9021164   0.89036017  0.8854719   0.88104089
  0.89744952  0.86755319  0.8658147   0.84381663],0.871959668458
macro precision scores = [ 0.82301908  0.86224837  0.90197417  0.89073676  0.88524572  0.8801919
  0.89695313  0.8677054   0.86445023  0.84354823],0.871607297633
macro recall scores = [ 0.81709455  0.85843816  0.89990384  0.88883668  0.88412966  0.87872516
  0.8941383   0.86114917  0.86240002  0.83872172],0.868353725588
macro f1 scores = [ 0.81732927  0.85949042  0.90063925  0.88929367  0.88407118  0.87842367
  0.89484067  0.86259875  0.86289771  0.83928777],0.868887234858
weighted average precision scores = [ 0.8253301   0.86314587  0.90251852  0.89104677  0.88538924  0.88140591
  0.89868473  0.86842366  0.86691839  0.84765647],0.873051967166
weighted average recall scores = [ 0.8253301   0.86314587  0.90251852  0.89104677  0.88538924  0.88140591
  0.89868473  0.86842366  0.86691839  0.84765647],0.873051967166
weighted f1 scores = [ 0.8226583   0.86155134  0.90203566  0.89021195  0.8848385   0.88021799
  0.89742551  0.866501    0.86586421  0.84390585],0.871521030167
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.871607297633 recall  0.868353725588 f1  0.868887234858
loaded (218249) terms
vectorizing done, 218249 terms vocabulary tokenized
vectorizing done, 218249 terms vocabulary tokenized
accuracy scores = [ 0.88530655  0.90745637  0.93915344  0.93220339  0.9321315   0.92405736
  0.93730074  0.90691489  0.91906283  0.89765458],0.918124166023
macro precision scores = [ 0.8836294   0.90987421  0.9405746   0.93308269  0.93342378  0.92301929
  0.93717685  0.90632129  0.91994782  0.89788768],0.918493761548
macro recall scores = [ 0.87898325  0.90387926  0.93745296  0.9312509   0.93066403  0.92159475
  0.93446426  0.90262193  0.91654205  0.89535524],0.915280864183
macro f1 scores = [ 0.87980909  0.90533895  0.93850063  0.93185473  0.9313343   0.92172001
  0.93539514  0.9035387   0.91769476  0.89571113],0.916089743483
weighted average precision scores = [ 0.88540643  0.90943974  0.93957695  0.93303475  0.93256062  0.92552148
  0.93758932  0.90750362  0.92032951  0.90006614],0.919102853544
weighted average recall scores = [ 0.88540643  0.90943974  0.93957695  0.93303475  0.93256062  0.92552148
  0.93758932  0.90750362  0.92032951  0.90006614],0.919102853544
weighted f1 scores = [ 0.88408182  0.90721667  0.9389105   0.93231099  0.93173307  0.92425987
  0.9370978   0.90644203  0.91918731  0.89795271],0.917919276926
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.918493761548 recall  0.915280864183 f1  0.916089743483
loaded (52136) terms
extended to (70081) terms
done loading vocabulary
vectorizing done, 70081 terms vocabulary tokenized
vectorizing done, 70081 terms vocabulary tokenized
accuracy scores = [ 0.85729387  0.89053411  0.92222222  0.91366525  0.91145281  0.91131174
  0.91604676  0.8893617   0.89350373  0.87633262],0.898172481195
macro precision scores = [ 0.85668402  0.89124099  0.92336913  0.91408318  0.91294372  0.90916533
  0.91555383  0.8898487   0.89225358  0.87584877],0.898099124027
macro recall scores = [ 0.85225418  0.88758764  0.91988693  0.91208112  0.91001668  0.90900607
  0.91278299  0.88418567  0.89091226  0.87258545],0.895129898062
macro f1 scores = [ 0.85313329  0.88844779  0.92101181  0.91262379  0.91070655  0.90863566
  0.91346834  0.88548489  0.89120897  0.87303256],0.895775363592
weighted average precision scores = [ 0.85810691  0.89174129  0.92311305  0.91472256  0.91230093  0.91174524
  0.91623158  0.89018965  0.89452649  0.87848194],0.899115962305
weighted average recall scores = [ 0.85810691  0.89174129  0.92311305  0.91472256  0.91230093  0.91174524
  0.91623158  0.89018965  0.89452649  0.87848194],0.899115962305
weighted f1 scores = [ 0.85646618  0.89032826  0.92209236  0.91374261  0.91116647  0.91107189
  0.91556381  0.88846135  0.89365553  0.87622001],0.897876847607
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.898099124027 recall  0.895129898062 f1  0.895775363592
loaded (241441) terms
vectorizing done, 241441 terms vocabulary tokenized
vectorizing done, 241441 terms vocabulary tokenized
accuracy scores = [ 0.8858351   0.90798519  0.94021164  0.93273305  0.9321315   0.92246415
  0.93836344  0.90851064  0.92066028  0.89498934],0.918388432474
macro precision scores = [ 0.88394606  0.91044223  0.94167618  0.93360447  0.93351487  0.92132525
  0.93829211  0.90796512  0.92137669  0.89581501],0.918795797864
macro recall scores = [ 0.87949871  0.90438431  0.93846822  0.93176616  0.93066403  0.91977039
  0.93576811  0.90405374  0.91821181  0.89266497],0.915525044507
macro f1 scores = [ 0.88025812  0.90585394  0.93950951  0.93238001  0.93134533  0.91988766
  0.93665258  0.90504144  0.91931448  0.8931873 ],0.916343037893
weighted average precision scores = [ 0.88590132  0.9100345   0.94071594  0.93356577  0.93264275  0.92393556
  0.9387177   0.90910551  0.92175083  0.89795421],0.919432410458
weighted average recall scores = [ 0.88590132  0.9100345   0.94071594  0.93356577  0.93264275  0.92393556
  0.9387177   0.90910551  0.92175083  0.89795421],0.919432410458
weighted f1 scores = [ 0.88462398  0.9077559   0.93995715  0.93284791  0.93173782  0.92261482
  0.9382232   0.90800314  0.92076056  0.89542441],0.918194888617
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.918795797864 recall  0.915525044507 f1  0.916343037893
loaded (75328) terms
extended to (94090) terms
done loading vocabulary
vectorizing done, 94090 terms vocabulary tokenized
vectorizing done, 94090 terms vocabulary tokenized
accuracy scores = [ 0.85782241  0.88736118  0.92275132  0.9157839   0.91463415  0.91396707
  0.91870351  0.88776596  0.89669862  0.87846482],0.899395293459
macro precision scores = [ 0.85715469  0.88829459  0.9235622   0.91633199  0.91666495  0.91154651
  0.91829791  0.88908756  0.89565986  0.87808432],0.899468457367
macro recall scores = [ 0.85215559  0.88424209  0.92020186  0.91435594  0.91248524  0.91144007
  0.91520901  0.88308006  0.89427158  0.87493263],0.89623740711
macro f1 scores = [ 0.85301353  0.88513382  0.92120566  0.91494535  0.91345464  0.91101538
  0.91607357  0.88454564  0.89449856  0.87527711],0.896916327137
weighted average precision scores = [ 0.85876134  0.88862828  0.92379635  0.91694507  0.91566214  0.91438194
  0.91877645  0.88901983  0.89794982  0.88081252],0.900473373991
weighted average recall scores = [ 0.85876134  0.88862828  0.92379635  0.91694507  0.91566214  0.91438194
  0.91877645  0.88901983  0.89794982  0.88081252],0.900473373991
weighted f1 scores = [ 0.85681905  0.88706303  0.92262441  0.91597974  0.91419493  0.91369505
  0.91818393  0.88709818  0.89687724  0.87839697],0.899093252336
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.899468457367 recall  0.89623740711 f1  0.896916327137
loaded (210546) terms
vectorizing done, 210546 terms vocabulary tokenized
vectorizing done, 210546 terms vocabulary tokenized
accuracy scores = [ 0.88477801  0.9106293   0.93862434  0.93167373  0.92788971  0.92193309
  0.93623804  0.90478723  0.91906283  0.89818763],0.917380392071
macro precision scores = [ 0.88287561  0.9135022   0.93967436  0.93235477  0.92943246  0.92068277
  0.9362652   0.9039661   0.91935815  0.89871032],0.917682192077
macro recall scores = [ 0.87837361  0.90750353  0.93690877  0.93075606  0.92589972  0.91898715
  0.93358257  0.90008386  0.9165791   0.89600449],0.914467884456
macro f1 scores = [ 0.87919713  0.90899893  0.93777852  0.93127093  0.92665446  0.91913836
  0.93449312  0.90114176  0.91743227  0.89643327],0.915253875781
weighted average precision scores = [ 0.88483686  0.91258273  0.93909875  0.93238387  0.92862667  0.92329848
  0.93666066  0.90501844  0.92028245  0.90099835],0.918378726102
weighted average recall scores = [ 0.88483686  0.91258273  0.93909875  0.93238387  0.92862667  0.92329848
  0.93666066  0.90501844  0.92028245  0.90099835],0.918378726102
weighted f1 scores = [ 0.88360106  0.91038804  0.93838487  0.93174442  0.92738793  0.9220092
  0.93609634  0.904186    0.91917313  0.8986613 ],0.917163229094
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.917682192077 recall  0.914467884456 f1  0.915253875781
loaded (44433) terms
extended to (54188) terms
done loading vocabulary
vectorizing done, 54188 terms vocabulary tokenized
vectorizing done, 54188 terms vocabulary tokenized
accuracy scores = [ 0.82928118  0.8699101   0.90793651  0.89459746  0.8902439   0.89272438
  0.90063762  0.87819149  0.87167199  0.84754797],0.878274260322
macro precision scores = [ 0.82870463  0.87076121  0.90834118  0.89505935  0.89057471  0.89011913
  0.90064263  0.87959683  0.87070729  0.84575125],0.878025821322
macro recall scores = [ 0.82331452  0.86639754  0.90594692  0.89263035  0.88861774  0.8891655
  0.89739953  0.87199974  0.86820686  0.84243015],0.874610886643
macro f1 scores = [ 0.82376624  0.8674128   0.90656556  0.89343797  0.88907178  0.88862146
  0.89824932  0.87385178  0.86884378  0.84276529],0.875258596806
weighted average precision scores = [ 0.83059903  0.87165632  0.9086198   0.89552735  0.89031893  0.89312161
  0.90167505  0.8797372   0.87274875  0.84957457],0.8793578617
weighted average recall scores = [ 0.83059903  0.87165632  0.9086198   0.89552735  0.89031893  0.89312161
  0.90167505  0.8797372   0.87274875  0.84957457],0.8793578617
weighted f1 scores = [ 0.82799168  0.86981036  0.9077313   0.89466419  0.88980672  0.89192063
  0.90050213  0.87740161  0.87163969  0.84726728],0.877873558566
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.878025821322 recall  0.874610886643 f1  0.875258596806
loaded (242282) terms
vectorizing done, 242282 terms vocabulary tokenized
vectorizing done, 242282 terms vocabulary tokenized
accuracy scores = [ 0.8858351   0.90798519  0.94021164  0.93273305  0.9321315   0.92246415
  0.93889479  0.90691489  0.92066028  0.89498934],0.918281992969
macro precision scores = [ 0.88440141  0.91038706  0.94167618  0.93360447  0.93347082  0.92132525
  0.93872828  0.90626488  0.92115699  0.89582668],0.91868420169
macro recall scores = [ 0.87949871  0.90438431  0.93846822  0.93176616  0.93066403  0.91977039
  0.93627316  0.90240823  0.91821181  0.89266497],0.915410998115
macro f1 scores = [ 0.88034798  0.90582399  0.93950951  0.93238001  0.93134348  0.91988766
  0.93714704  0.90338737  0.91924009  0.89318627],0.916225340128
weighted average precision scores = [ 0.88604799  0.90998554  0.94071594  0.93356577  0.93260543  0.92393556
  0.93916795  0.90745912  0.92166575  0.8979702 ],0.919311926764
weighted average recall scores = [ 0.88604799  0.90998554  0.94071594  0.93356577  0.93260543  0.92393556
  0.93916795  0.90745912  0.92166575  0.8979702 ],0.919311926764
weighted f1 scores = [ 0.88459828  0.90772928  0.93995715  0.93284791  0.93174036  0.92261482
  0.93873865  0.90640295  0.92074733  0.89542543],0.918080213767
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.91868420169 recall  0.915410998115 f1  0.916225340128
loaded (76169) terms
extended to (95111) terms
done loading vocabulary
vectorizing done, 95111 terms vocabulary tokenized
vectorizing done, 95111 terms vocabulary tokenized
accuracy scores = [ 0.85676533  0.88947647  0.92486772  0.9157839   0.91516437  0.91343601
  0.91976621  0.88723404  0.89616613  0.87793177],0.899659194638
macro precision scores = [ 0.85605705  0.89031947  0.92546123  0.91622762  0.9173632   0.91103929
  0.91930102  0.88902813  0.89497773  0.87752863],0.89973033658
macro recall scores = [ 0.85112992  0.8864191   0.92252623  0.91435594  0.91298524  0.91104961
  0.91634422  0.88216536  0.89365184  0.8742938 ],0.896492124559
macro f1 scores = [ 0.85196511  0.88727308  0.92343254  0.91490168  0.91405354  0.91056585
  0.91714628  0.88373258  0.89381     0.87467124],0.897155189578
weighted average precision scores = [ 0.85759275  0.89072399  0.92574137  0.91683169  0.91628072  0.9138349
  0.91982837  0.88884922  0.89748746  0.88026434],0.900743480553
weighted average recall scores = [ 0.85759275  0.89072399  0.92574137  0.91683169  0.91628072  0.9138349
  0.91982837  0.88884922  0.89748746  0.88026434],0.900743480553
weighted f1 scores = [ 0.85571992  0.88919543  0.92476525  0.91593184  0.91476816  0.91315884
  0.91924626  0.88649683  0.8963511   0.87785692],0.899349055501
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.89973033658 recall  0.896492124559 f1  0.897155189578
loaded (149113) terms
vectorizing done, 149113 terms vocabulary tokenized
vectorizing done, 149113 terms vocabulary tokenized
accuracy scores = [ 0.87737844  0.90269699  0.93439153  0.93273305  0.92788971  0.91927775
  0.93092455  0.90531915  0.91001065  0.88965885],0.913028066396
macro precision scores = [ 0.87714386  0.90489716  0.93526213  0.93373667  0.92921882  0.91808397
  0.93128779  0.90601791  0.91096344  0.89164153],0.913825327692
macro recall scores = [ 0.86991268  0.89953479  0.93277297  0.93198536  0.92615729  0.9154358
  0.92872342  0.90095569  0.90700889  0.88748545],0.909997234142
macro f1 scores = [ 0.87046037  0.90084409  0.93361869  0.93260795  0.92683786  0.91574866
  0.92956694  0.90221032  0.90837483  0.88853548],0.91088051854
weighted average precision scores = [ 0.877953    0.90452675  0.93454131  0.93356536  0.9283483   0.92020587
  0.93135762  0.90634312  0.91177082  0.89269762],0.914130974015
weighted average recall scores = [ 0.877953    0.90452675  0.93454131  0.93356536  0.9283483   0.92020587
  0.93135762  0.90634312  0.91177082  0.89269762],0.914130974015
weighted f1 scores = [ 0.87531478  0.90248483  0.934121    0.93289476  0.92738535  0.91887904
  0.9307597   0.90478043  0.91032491  0.89013609],0.912708089431
ng20_raw_stems_unigrams_stopwords_df1_tf1  -->  precision  0.913825327692 recall  0.909997234142 f1  0.91088051854
loaded (1587711) terms
vectorizing done, 1587711 terms vocabulary tokenized
vectorizing done, 1587711 terms vocabulary tokenized
accuracy scores = [ 0.88424947  0.90851401  0.94021164  0.93908898  0.9321315   0.92724376
  0.93942614  0.91117021  0.9142705   0.89339019],0.918969641125
macro precision scores = [ 0.88396917  0.9110564   0.94171408  0.94016248  0.93354426  0.92672661
  0.94067958  0.91083574  0.9158161   0.89522195],0.919972636845
macro recall scores = [ 0.87691558  0.90523937  0.93942175  0.93833313  0.93031752  0.92396011
  0.93704412  0.90685675  0.91215447  0.89132683],0.916156963904
macro f1 scores = [ 0.87781964  0.90674001  0.94010653  0.9390169   0.93129868  0.92440723
  0.93833899  0.907967    0.91328034  0.89245978],0.917143510779
weighted average precision scores = [ 0.88469993  0.91040233  0.94060035  0.93991496  0.93306721  0.92863163
  0.94004756  0.91177597  0.91568889  0.89619511],0.920102394873
weighted average recall scores = [ 0.88469993  0.91040233  0.94060035  0.93991496  0.93306721  0.92863163
  0.94004756  0.91177597  0.91568889  0.89619511],0.920102394873
weighted f1 scores = [ 0.88245803  0.90831646  0.93996973  0.93927046  0.93206225  0.9271166
  0.93931701  0.91072619  0.91432327  0.89398644],0.9187546451
ng20_raw_stems_bigrams_stopwords_df1_tf1  -->  precision  0.919972636845 recall  0.916156963904 f1  0.917143510779
loaded (206785) terms
vectorizing done, 206785 terms vocabulary tokenized
vectorizing done, 206785 terms vocabulary tokenized
accuracy scores = [ 0.88266385  0.90745637  0.93809524  0.93220339  0.93160127  0.92193309
  0.93730074  0.90904255  0.91373802  0.8891258 ],0.916316032186
macro precision scores = [ 0.88228651  0.90997521  0.93927133  0.93329696  0.93255737  0.92058799
  0.93643725  0.90895965  0.9145294   0.89080069],0.916870235604
macro recall scores = [ 0.87538368  0.90422137  0.93668904  0.93139708  0.92963473  0.9179708
  0.93473161  0.90514195  0.91134946  0.88671888],0.913323860815
macro f1 scores = [ 0.87610497  0.90569995  0.93755579  0.93206916  0.93046543  0.91831425
  0.93532634  0.90619508  0.91240249  0.88779566],0.914192912292
weighted average precision scores = [ 0.88326933  0.90954754  0.93833666  0.93295906  0.93188091  0.92274476
  0.93742599  0.90980242  0.91518553  0.89189001],0.917304220586
weighted average recall scores = [ 0.88326933  0.90954754  0.93833666  0.93295906  0.93188091  0.92274476
  0.93742599  0.90980242  0.91518553  0.89189001],0.917304220586
weighted f1 scores = [ 0.88089865  0.90736404  0.93784445  0.93230595  0.93123623  0.9215195
  0.93713571  0.90871219  0.91395177  0.88954711],0.916051560069
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.916870235604 recall  0.913323860815 f1  0.914192912292
loaded (57672) terms
extended to (73779) terms
done loading vocabulary
vectorizing done, 73779 terms vocabulary tokenized
vectorizing done, 73779 terms vocabulary tokenized
accuracy scores = [ 0.85306554  0.89106293  0.91957672  0.91631356  0.91092259  0.90918747
  0.91976621  0.88723404  0.8887114   0.86780384],0.896364428374
macro precision scores = [ 0.85276175  0.89275507  0.92176395  0.91580933  0.91313271  0.90877834
  0.92030728  0.88765991  0.88856419  0.86644918],0.896798172729
macro recall scores = [ 0.84548719  0.88756471  0.917145    0.91492663  0.90992468  0.90573288
  0.91644881  0.88311444  0.88590259  0.86318336],0.892943027882
macro f1 scores = [ 0.84621641  0.88888823  0.91853666  0.91514081  0.9106318   0.90634421
  0.91753397  0.88441324  0.88676711  0.86373044],0.893820288569
weighted average precision scores = [ 0.85454531  0.89291262  0.92093803  0.91667727  0.91138781  0.90933657
  0.92048332  0.88807857  0.89046149  0.86950591],0.897432690479
weighted average recall scores = [ 0.85454531  0.89291262  0.92093803  0.91667727  0.91138781  0.90933657
  0.92048332  0.88807857  0.89046149  0.86950591],0.897432690479
weighted f1 scores = [ 0.85142019  0.8909472   0.91940734  0.91626937  0.9104096   0.90845807
  0.91946828  0.8868135   0.88912968  0.86758518],0.895990842103
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.896798172729 recall  0.892943027882 f1  0.893820288569
loaded (157884) terms
vectorizing done, 157884 terms vocabulary tokenized
vectorizing done, 157884 terms vocabulary tokenized
accuracy scores = [ 0.87737844  0.90163934  0.93597884  0.93167373  0.92841994  0.91821561
  0.9325186   0.90585106  0.90947817  0.8901919 ],0.913134562131
macro precision scores = [ 0.87731369  0.9043915   0.93650673  0.93295241  0.92988822  0.91686764
  0.93262204  0.90691499  0.91069048  0.8916821 ],0.913982980568
macro recall scores = [ 0.86991278  0.89792161  0.93454318  0.93086012  0.92667255  0.91431638
  0.93020469  0.90183378  0.90693945  0.88786703],0.910107156242
macro f1 scores = [ 0.87067232  0.89944103  0.93514905  0.93162772  0.92730515  0.91462555
  0.93098391  0.90320971  0.90814018  0.88884673],0.911000136807
weighted average precision scores = [ 0.87809806  0.90396006  0.93616502  0.93245008  0.92905877  0.91907177
  0.93283053  0.90694958  0.91143456  0.89287934],0.914289778364
weighted average recall scores = [ 0.87809806  0.90396006  0.93616502  0.93245008  0.92905877  0.91907177
  0.93283053  0.90694958  0.91143456  0.89287934],0.914289778364
weighted f1 scores = [ 0.87552332  0.90142183  0.93572477  0.93178686  0.92787546  0.9178267
  0.9323022   0.90543018  0.90982266  0.89060238],0.912831636304
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.913982980568 recall  0.910107156242 f1  0.911000136807
loaded (8771) terms
extended to (13555) terms
done loading vocabulary
vectorizing done, 13555 terms vocabulary tokenized
vectorizing done, 13555 terms vocabulary tokenized
accuracy scores = [ 0.77801268  0.82496034  0.85555556  0.85540254  0.84146341  0.84917685
  0.86663124  0.83244681  0.81789137  0.79157783],0.831311863229
macro precision scores = [ 0.77719052  0.8269335   0.85666924  0.85574867  0.84152435  0.84652002
  0.86693563  0.83139159  0.81788556  0.79167185],0.831247090749
macro recall scores = [ 0.77120847  0.82041835  0.85119196  0.85251957  0.83943435  0.84652149
  0.86360854  0.82503467  0.81485194  0.7857436 ],0.827053293864
macro f1 scores = [ 0.770947    0.82213008  0.85234716  0.85345587  0.83952674  0.84577522
  0.86439156  0.82573177  0.81511503  0.78670006],0.827612049191
weighted average precision scores = [ 0.77824919  0.82797909  0.85721815  0.85673103  0.84079441  0.84823106
  0.86765557  0.83238089  0.8199006   0.79651951],0.832565949949
weighted average recall scores = [ 0.77824919  0.82797909  0.85721815  0.85673103  0.84079441  0.84823106
  0.86765557  0.83238089  0.8199006   0.79651951],0.832565949949
weighted f1 scores = [ 0.77557823  0.82514882  0.8549397   0.85538695  0.84026854  0.84796214
  0.86633677  0.83043369  0.81769216  0.79204003],0.830578703558
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.831247090749 recall  0.827053293864 f1  0.827612049191
loaded (196881) terms
vectorizing done, 196881 terms vocabulary tokenized
vectorizing done, 196881 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90481227  0.93703704  0.93220339  0.9300106   0.92246415
  0.93517535  0.90478723  0.91267306  0.88752665],0.914829650655
macro precision scores = [ 0.88123906  0.90786002  0.93830187  0.93349531  0.93097374  0.92112439
  0.93528879  0.90539345  0.91412989  0.88935023],0.915715675829
macro recall scores = [ 0.8745191   0.9012767   0.93511205  0.93177891  0.92820852  0.91848704
  0.93276634  0.90063236  0.90999541  0.88530045],0.911807686902
macro f1 scores = [ 0.87509176  0.90283504  0.93614066  0.9324104   0.92889707  0.91885529
  0.93360518  0.90189149  0.91140084  0.88634447],0.912747219366
weighted average precision scores = [ 0.88233337  0.90714083  0.93759601  0.93299868  0.93016202  0.92322346
  0.93573453  0.90572669  0.91469794  0.89031656],0.915993010389
weighted average recall scores = [ 0.88233337  0.90714083  0.93759601  0.93299868  0.93016202  0.92322346
  0.93573453  0.90572669  0.91469794  0.89031656],0.915993010389
weighted f1 scores = [ 0.87984696  0.90457668  0.93681794  0.93237257  0.92951575  0.92204052
  0.93509106  0.9043367   0.91306921  0.88793495],0.914560234327
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.915715675829 recall  0.911807686902 f1  0.912747219366
loaded (47768) terms
extended to (55661) terms
done loading vocabulary
vectorizing done, 55661 terms vocabulary tokenized
vectorizing done, 55661 terms vocabulary tokenized
accuracy scores = [ 0.81871036  0.86567953  0.90687831  0.8871822   0.88123012  0.88635157
  0.90170032  0.87819149  0.87273695  0.84808102],0.874674187344
macro precision scores = [ 0.8162106   0.86636355  0.90876872  0.88746447  0.88187431  0.88464293
  0.90231504  0.87762599  0.87098376  0.84891825],0.874516763163
macro recall scores = [ 0.80995294  0.86141635  0.90399106  0.88529077  0.87949572  0.88384029
  0.89851697  0.87339515  0.86927107  0.84369189],0.870886220298
macro f1 scores = [ 0.80903109  0.86264531  0.90560682  0.88600813  0.87965055  0.88326851
  0.89939561  0.87455178  0.86960211  0.84447117],0.871423107772
weighted average precision scores = [ 0.81938423  0.86776804  0.90810185  0.88826143  0.88163195  0.88627173
  0.90305227  0.87858728  0.87379352  0.85200927],0.875886156257
weighted average recall scores = [ 0.81938423  0.86776804  0.90810185  0.88826143  0.88163195  0.88627173
  0.90305227  0.87858728  0.87379352  0.85200927],0.875886156257
weighted f1 scores = [ 0.81580524  0.86566083  0.90681074  0.88735457  0.88042997  0.88539683
  0.90155592  0.8775364   0.87275368  0.84822405],0.874152822484
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.874516763163 recall  0.870886220298 f1  0.871423107772
loaded (207882) terms
vectorizing done, 207882 terms vocabulary tokenized
vectorizing done, 207882 terms vocabulary tokenized
accuracy scores = [ 0.88213531  0.90745637  0.93756614  0.93220339  0.93160127  0.92193309
  0.9357067   0.90851064  0.91320554  0.8891258 ],0.915944423496
macro precision scores = [ 0.88157388  0.90991319  0.93874554  0.93329696  0.93260418  0.92054842
  0.93492164  0.90842577  0.91392361  0.89082718],0.916478036783
macro recall scores = [ 0.87459508  0.90421622  0.93606404  0.93139708  0.92963473  0.9179708
  0.93316165  0.90462649  0.910834    0.88658499],0.912908507475
macro f1 scores = [ 0.87515519  0.90567819  0.93697582  0.93206916  0.9304934   0.91831438
  0.93374824  0.90567451  0.91185819  0.88768286],0.913764995391
weighted average precision scores = [ 0.88271649  0.9094791   0.93777485  0.93295906  0.93193956  0.92272404
  0.93594235  0.90924169  0.91456416  0.89195723],0.916929853849
weighted average recall scores = [ 0.88271649  0.9094791   0.93777485  0.93295906  0.93193956  0.92272404
  0.93594235  0.90924169  0.91456416  0.89195723],0.916929853849
weighted f1 scores = [ 0.88021724  0.90734199  0.93729761  0.93230595  0.93127022  0.92152978
  0.93555986  0.90816998  0.91339199  0.88952881],0.915661344902
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.916478036783 recall  0.912908507475 f1  0.913764995391
loaded (58769) terms
extended to (75015) terms
done loading vocabulary
vectorizing done, 75015 terms vocabulary tokenized
vectorizing done, 75015 terms vocabulary tokenized
accuracy scores = [ 0.85200846  0.89053411  0.91957672  0.9157839   0.91145281  0.9102496
  0.91923486  0.88723404  0.88764643  0.86727079],0.896099171573
macro precision scores = [ 0.85275039  0.89198738  0.92152459  0.91531099  0.91365714  0.91005276
  0.91977005  0.88787535  0.88777592  0.86605012],0.896675467451
macro recall scores = [ 0.84447699  0.88677642  0.91713985  0.91442158  0.91033047  0.90686808
  0.91622184  0.88298571  0.88489248  0.86253401],0.892664742344
macro f1 scores = [ 0.84543528  0.88809472  0.91848136  0.91463433  0.9110548   0.90752206
  0.91725703  0.8843708   0.88585695  0.86313557],0.893584289981
weighted average precision scores = [ 0.85410332  0.89203396  0.9206731   0.91614457  0.91192686  0.91052749
  0.91991675  0.88836354  0.88963842  0.86914103],0.897246904559
weighted average recall scores = [ 0.85410332  0.89203396  0.9206731   0.91614457  0.91192686  0.91052749
  0.91991675  0.88836354  0.88963842  0.86914103],0.897246904559
weighted f1 scores = [ 0.85047083  0.89025469  0.91934511  0.91573326  0.91089833  0.90955258
  0.91899675  0.88686847  0.88817416  0.86707447],0.89573686424
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.896675467451 recall  0.892664742344 f1  0.893584289981
loaded (235766) terms
vectorizing done, 235766 terms vocabulary tokenized
vectorizing done, 235766 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90851401  0.93862434  0.93432203  0.93160127  0.92405736
  0.93676939  0.90904255  0.91480298  0.8901919 ],0.916953260642
macro precision scores = [ 0.88096762  0.91090518  0.93989115  0.93524433  0.93260672  0.92278101
  0.93627277  0.90895505  0.91620277  0.89216095],0.917598755897
macro recall scores = [ 0.8741056   0.90510065  0.9368714   0.93341739  0.92961379  0.92042401
  0.9341849   0.90515258  0.91238028  0.88775002],0.913900062236
macro f1 scores = [ 0.87460639  0.90657723  0.93782838  0.93406213  0.93042263  0.92072356
  0.93488781  0.90620959  0.91365538  0.88881013],0.914778322276
weighted average precision scores = [ 0.88208448  0.91050188  0.93916634  0.93508209  0.93195002  0.92486374
  0.9369415   0.90979208  0.91680104  0.89332385],0.918050702589
weighted average recall scores = [ 0.88208448  0.91050188  0.93916634  0.93508209  0.93195002  0.92486374
  0.9369415   0.90979208  0.91680104  0.89332385],0.918050702589
weighted f1 scores = [ 0.87963643  0.90835884  0.9384062   0.9344331   0.93121103  0.92370547
  0.93655648  0.90871888  0.91519623  0.89060929],0.916683194982
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.917598755897 recall  0.913900062236 f1  0.914778322276
loaded (86653) terms
extended to (103595) terms
done loading vocabulary
vectorizing done, 103595 terms vocabulary tokenized
vectorizing done, 103595 terms vocabulary tokenized
accuracy scores = [ 0.85412262  0.89000529  0.92222222  0.91684322  0.9135737   0.91502921
  0.92242295  0.8893617   0.89350373  0.87206823],0.898915287608
macro precision scores = [ 0.85372391  0.89262286  0.92397331  0.91656626  0.91498265  0.91524883
  0.92202123  0.88995955  0.89303741  0.87130507],0.89934411037
macro recall scores = [ 0.84645988  0.88650131  0.91966005  0.9153977   0.9119861   0.91163581
  0.9194312   0.88501632  0.89063048  0.8671209 ],0.895383974887
macro f1 scores = [ 0.84695939  0.88808735  0.92093217  0.91568435  0.91259504  0.91248189
  0.9201996   0.88636404  0.89126043  0.86779579],0.896236005976
weighted average precision scores = [ 0.85518777  0.8919804   0.92324346  0.91745781  0.91399122  0.9163481
  0.92280482  0.89047047  0.89509451  0.87437339],0.900095195633
weighted average recall scores = [ 0.85518777  0.8919804   0.92324346  0.91745781  0.91399122  0.9163481
  0.92280482  0.89047047  0.89509451  0.87437339],0.900095195633
weighted f1 scores = [ 0.85217823  0.88982203  0.92191783  0.91685092  0.9130415   0.91482431
  0.9221869   0.88894596  0.89372918  0.87183446],0.898533131731
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.89934411037 recall  0.895383974887 f1  0.896236005976
loaded (200920) terms
vectorizing done, 200920 terms vocabulary tokenized
vectorizing done, 200920 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90639873  0.93756614  0.93273305  0.93160127  0.92087095
  0.93676939  0.90478723  0.91267306  0.88965885],0.915466544108
macro precision scores = [ 0.88120839  0.90894916  0.93862267  0.93385308  0.93267368  0.9194601
  0.93699806  0.90484483  0.91382768  0.89117978],0.916161743065
macro recall scores = [ 0.87417599  0.90292267  0.93563256  0.93176058  0.92974472  0.91692408
  0.93428675  0.90063215  0.91014508  0.88721274],0.912343732275
macro f1 scores = [ 0.87473076  0.90444436  0.93657832  0.93250012  0.93044797  0.91719332
  0.93519458  0.90174615  0.91136124  0.88819914],0.913239596349
weighted average precision scores = [ 0.88225301  0.90850445  0.93804674  0.93370398  0.9319395   0.92173673
  0.93739348  0.90552391  0.91467152  0.89226709],0.916604039861
weighted average recall scores = [ 0.88225301  0.90850445  0.93804674  0.93370398  0.9319395   0.92173673
  0.93739348  0.90552391  0.91467152  0.89226709],0.916604039861
weighted f1 scores = [ 0.87969228  0.90624441  0.9373229   0.93291256  0.93112963  0.92045409
  0.93668993  0.9043307   0.91307977  0.88996814],0.915182442344
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.916161743065 recall  0.912343732275 f1  0.913239596349
loaded (51807) terms
extended to (60709) terms
done loading vocabulary
vectorizing done, 60709 terms vocabulary tokenized
vectorizing done, 60709 terms vocabulary tokenized
accuracy scores = [ 0.82399577  0.86673718  0.91005291  0.89088983  0.89130435  0.89272438
  0.90063762  0.88138298  0.87380192  0.84488273],0.877640965657
macro precision scores = [ 0.82204371  0.8677024   0.91081739  0.89092732  0.89266538  0.89160158
  0.90097755  0.8809538   0.87345516  0.84488159],0.877602588309
macro recall scores = [ 0.81578589  0.86267864  0.90727959  0.88921495  0.88988142  0.88950175
  0.89738802  0.87600032  0.870703    0.84003462],0.873846821032
macro f1 scores = [ 0.81533313  0.86389162  0.90854857  0.88972278  0.89039672  0.88928144
  0.89821615  0.87731282  0.87141683  0.84065893],0.874477898493
weighted average precision scores = [ 0.82513278  0.86920658  0.91092014  0.89204592  0.89163439  0.89338109
  0.90169515  0.88205462  0.87548554  0.84820491],0.878976110396
weighted average recall scores = [ 0.82513278  0.86920658  0.91092014  0.89204592  0.89163439  0.89338109
  0.90169515  0.88205462  0.87548554  0.84820491],0.878976110396
weighted f1 scores = [ 0.82154731  0.86685541  0.91005272  0.89112039  0.89067571  0.89189734
  0.90038512  0.88070733  0.87400347  0.84475124],0.877199605611
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.877602588309 recall  0.873846821032 f1  0.874477898493
loaded (236636) terms
vectorizing done, 236636 terms vocabulary tokenized
vectorizing done, 236636 terms vocabulary tokenized
accuracy scores = [ 0.88160677  0.90798519  0.93915344  0.93432203  0.93160127  0.92405736
  0.93623804  0.90797872  0.91480298  0.8901919 ],0.916793770681
macro precision scores = [ 0.88096762  0.91037871  0.94044618  0.93524433  0.93260672  0.92274144
  0.93574922  0.90787038  0.91616563  0.89216095],0.917433117668
macro recall scores = [ 0.8741056   0.90459045  0.9373816   0.93341739  0.92961379  0.92042401
  0.93363545  0.90411629  0.91237502  0.88775002],0.913740961473
macro f1 scores = [ 0.87460639  0.90603622  0.93836672  0.93406213  0.93042263  0.92072368
  0.93433607  0.90515167  0.91362849  0.88881013],0.914614413733
weighted average precision scores = [ 0.88208448  0.90996083  0.939721    0.93508209  0.93195002  0.92484302
  0.93651057  0.90865695  0.91677352  0.89332385],0.917890634562
weighted average recall scores = [ 0.88208448  0.90996083  0.939721    0.93508209  0.93195002  0.92484302
  0.93651057  0.90865695  0.91677352  0.89332385],0.917890634562
weighted f1 scores = [ 0.87963643  0.90780036  0.93895362  0.9344331   0.93121103  0.92371575
  0.93605942  0.90762215  0.91517647  0.89060929],0.916521761885
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.917433117668 recall  0.913740961473 f1  0.914614413733
loaded (87523) terms
extended to (104579) terms
done loading vocabulary
vectorizing done, 104579 terms vocabulary tokenized
vectorizing done, 104579 terms vocabulary tokenized
accuracy scores = [ 0.85359408  0.89212057  0.92169312  0.91631356  0.9135737   0.91449814
  0.92029756  0.88829787  0.89350373  0.87420043],0.898809275664
macro precision scores = [ 0.85372034  0.8944503   0.92342637  0.91612705  0.91505098  0.91463773
  0.92000567  0.88879481  0.89290698  0.87336295],0.899248318109
macro recall scores = [ 0.84594967  0.88867327  0.919155    0.91487686  0.91199673  0.91112561
  0.91736387  0.88386192  0.89074527  0.86942905],0.895317724557
macro f1 scores = [ 0.8464765   0.89014541  0.92041372  0.91517029  0.91257079  0.91192942
  0.91814099  0.88521033  0.89129676  0.87006541],0.896141960969
weighted average precision scores = [ 0.85515083  0.89393665  0.92267112  0.91696322  0.91406215  0.91573279
  0.92070373  0.88942324  0.89483785  0.87646974],0.899995131602
weighted average recall scores = [ 0.85515083  0.89393665  0.92267112  0.91696322  0.91406215  0.91573279
  0.92070373  0.88942324  0.89483785  0.87646974],0.899995131602
weighted f1 scores = [ 0.85165978  0.89190991  0.92137485  0.9163038   0.91301053  0.9142591
  0.92005588  0.88789619  0.89364339  0.87402334],0.898413675756
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.899248318109 recall  0.895317724557 f1  0.896141960969
done!

