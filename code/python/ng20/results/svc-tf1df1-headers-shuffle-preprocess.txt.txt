IPython Notebookng20_classifier Last Checkpoint: Dec 24 16:51 (autosaved)
File
Edit
View
Insert
Cell
Kernel
Help
 Cell Toolbar:
Classify 20ng docs
Classifiy 20ng docs using unigrams and bigrams features with different classifiers and report classification resultsÂ¶
In [1]:

def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = CountVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    # generate tfidf vectors
    transformer = TfidfTransformer()
    corpus_tfidf_vectors = transformer.fit_transform(corpus_vectors)
 
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-1-743655218ee8>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
In [2]:

def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import TfidfVectorizer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = TfidfVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_tfidf_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-2-f88374f887f0>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
In [3]:

# given classifier predictions probabilities, return predictions with top n probabilities > 0.5 for each instance or greatest one if all are <=0.5
def get_max_n_pred(pred_proba, n_pred, threshold):
    import heapq
    import numpy
    max_n_pred = numpy.ndarray(shape=pred_proba.shape)
    for i in range(len(pred_proba)):
        largest_n_proba = heapq.nlargest(n_pred,pred_proba[i])
        max_n_pred[i] = numpy.array(((pred_proba[i]>threshold) & (pred_proba[i]>=largest_n_proba[len(largest_n_proba)-1]) & 1))
        if max_n_pred[i].sum(axis=0)==0: # at least one label should be returned
            max_n_pred[i] = numpy.array(((pred_proba[i]>=max(pred_proba[i])) & 1))
    return max_n_pred
In [4]:

# reference: http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification
def classify(x_train,y_train,x_test,y_test,max_labels):
    from sklearn.preprocessing import MultiLabelBinarizer
    from sklearn.multiclass import OneVsRestClassifier
    from sklearn.svm import SVC
    from sklearn.svm import LinearSVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.preprocessing import binarize
    from sklearn.cross_validation import train_test_split
    from sklearn import metrics
    import numpy
        
    # binarize the labels
    #mlb = MultiLabelBinarizer()
    #y_train_binarized = mlb.fit_transform(y_train)
    
    # train/test split
    #corpus_tfidf_vectors, labels_binarized = shuffle(corpus_tfidf_vectors, labels_binarized)
    #x_train, x_test, y_train, y_test = train_test_split(corpus_tfidf_vectors, labels_binarized, test_size=test_size, random_state=1)
    
    # classify
    #cls = OneVsRestClassifier(LogisticRegression(class_weight='auto'))
    #cls = OneVsRestClassifier(LogisticRegression())
    #cls = MultinomialNB(alpha=0.01)
    #cls = OneVsRestClassifier(BernoulliNB()need binarize(x_train and x_test))
    #cls = OneVsRestClassifier(SVC(kernel='linear',probability=True,max_iter=1000))
    #cls = OneVsRestClassifier(SVC(kernel='linear'))
    cls = LinearSVC()
    cls.fit(x_train, y_train)
    y_train_pred = cls.predict(x_train)
    print 'training F1: ', metrics.f1_score(y_train, y_train_pred, average='micro')
    print 'training accuracy: ', metrics.accuracy_score(y_train, y_train_pred)
    #pred_proba = 1/(1+numpy.exp(-1*cls.decision_function(x_test)))
    #threshold = 0.45#1/(1+numpy.exp(-1))
    #y_pred = mlb.inverse_transform(get_max_n_pred(pred_proba, max_labels,threshold))
    #y_pred = mlb.inverse_transform(cls.predict(x_test))
    y_pred = cls.predict(x_test)
    print 'testing accuracy: ', metrics.f1_score(y_test, y_pred)
    # evaluate
    #pred_proba = cls.predict_proba(x_test)
    #print len(pred_proba[0]) # make sure it is 121
    #actual_labels = mlb.inverse_transform(y_test)
    #precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred, pos_label=0)
    #print precision
    #print recall
    #print thresholds
    return {'precision':metrics.precision_score(y_test, y_pred, average='micro'),
            'recall':metrics.recall_score(y_test, y_pred, average='micro'),
            'f1':metrics.f1_score(y_test, y_pred, average='micro')}
In [5]:

import sklearn
from sklearn.svm import LinearSVC
c = LinearSVC()
print sklearn.__version__
0.15.2
In [6]:

def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_unigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-6-5bcc0f6a848c>:1: SyntaxWarning: import * only allowed at module level
  def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [7]:

def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-7-094e349cf724>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [8]:

def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_bigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-8-c28207c92f80>:1: SyntaxWarning: import * only allowed at module level
  def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [9]:

def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-9-781cd4f52dc5>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [10]:

def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    from sklearn.decomposition import TruncatedSVD
    from scipy import sparse
    import numpy
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # apply LSA
    #print numpy.max(corpus_train_tfidf_vectors)
    #print numpy.min(corpus_train_tfidf_vectors)
    lsa = TruncatedSVD(n_components=num_components)
    lsa.fit(corpus_train_tfidf_vectors)
    #corpus_train_tfidf_vectors = numpy.dot(corpus_train_tfidf_vectors,pca.components_.transpose())
    corpus_train_tfidf_vectors = lsa.transform(corpus_train_tfidf_vectors)
    corpus_test_tfidf_vectors = lsa.transform(corpus_test_tfidf_vectors)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print 'LSA ^' , vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-10-0ae0e12f66cc>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
In [11]:

def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)    
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-11-d27651528d70>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [12]:

def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-12-8129eac551f8>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [13]:

def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-13-180bdc332cbe>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [14]:

def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-14-cd1ea993b277>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [15]:

def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-15-98c5bdcd6b4f>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [16]:

def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-16-1c5602c28486>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [17]:

def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-17-c5ecc72d6e7c>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [18]:

def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-18-60ce875247ce>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [19]:

def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-19-2010f39a430e>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [20]:

def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-20-a08ffa055f62>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [21]:

def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-21-781d3020ecf2>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [22]:

def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-22-69e08236a4c4>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [23]:

def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-23-bdd713c1f2ac>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [24]:

def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-24-6b79430f2923>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [25]:

def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'stem')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-25-a650503cc609>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [26]:

def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-26-3444b80fb7e1>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [27]:

def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-27-dd4a635e1842>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [28]:

def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-28-ce43e0732809>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [29]:

def test():
    from ng20_corpus_loader import load_corpus_and_labels
    from ng20_corpus_loader import load_corpus_with_labels_mappings
    
    # load 20ng docs with class lables from DB
    corpus_train_data = load_corpus_and_labels('train')
    print 'done loading {0} train records and {1} labels.'.format(len(corpus_train_data['corpus']),len(corpus_train_data['labels_dic']))
 
    corpus_test_data = load_corpus_with_labels_mappings('test',corpus_train_data['labels_dic'])
    print 'done loading {0} test records.'.format(len(corpus_test_data['corpus']))
    
    stopwords_removal_mask = 1
    chi_features_mask = 2
    raw_tokens_mask = 4
    for i in range(4,6): # test w/o stopword removal and w/o chi square features and w/o raw tokens
        stopwords_removal = i&stopwords_removal_mask==stopwords_removal_mask
        use_chi_features = i&chi_features_mask==chi_features_mask
        use_raw_tokens = i&raw_tokens_mask==raw_tokens_mask
        
        test_all_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        #test_lemmatized_bigrams_with_LSA({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
        #                         {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
        #                         stopwords_removal,use_chi_features,use_raw_tokens,113240)
        
        test_lemmatized_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
In [30]:

# test using all vocabulary
test()
 
print 'done!'
loaded 11314 records.
done loading 11314 train records and 20 labels.
loaded 7532 records.
done loading 7532 test records.
loaded (122770) terms
vectorizing done, 122770 terms vocabulary tokenized
vectorizing done, 122770 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.848506520519
ng20_raw_unigrams  -->  precision  0.849707912905 recall  0.849707912905 f1  0.849707912905
loaded (1469366) terms
vectorizing done, 1469366 terms vocabulary tokenized
vectorizing done, 1469366 terms vocabulary tokenized
training F1:  0.999469683578
training accuracy:  0.999469683578
testing accuracy:  0.856449809882
ng20_raw_bigrams  -->  precision  0.857673924588 recall  0.857673924588 f1  0.857673924588
loaded (115473) terms
vectorizing done, 115473 terms vocabulary tokenized
vectorizing done, 115473 terms vocabulary tokenized
training F1:  0.998850981085
training accuracy:  0.998850981085
testing accuracy:  0.85219634167
ng20_raw_lemmas_unigrams_df1_tf1  -->  precision  0.853292618163 recall  0.853292618163 f1  0.853292618163
loaded (1397637) terms
vectorizing done, 1397637 terms vocabulary tokenized
vectorizing done, 1397637 terms vocabulary tokenized
training F1:  0.999469683578
training accuracy:  0.999469683578
testing accuracy:  0.85640501485
ng20_raw_lemmas_bigrams_df1_tf1  -->  precision  0.857541157727 recall  0.857541157727 f1  0.857541157727
loaded (168948) terms
done loading vocabulary
vectorizing done, 168948 terms vocabulary tokenized
vectorizing done, 168948 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.853754546424
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.854885820499 recall  0.854885820499 f1  0.854885820499
loaded (53475) terms
extended to (71921) terms
done loading vocabulary
vectorizing done, 71921 terms vocabulary tokenized
vectorizing done, 71921 terms vocabulary tokenized
training F1:  0.998585822874
training accuracy:  0.998585822874
testing accuracy:  0.829698895729
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.830855018587 recall  0.830855018587 f1  0.830855018587
loaded (126586) terms
done loading vocabulary
vectorizing done, 126586 terms vocabulary tokenized
vectorizing done, 126586 terms vocabulary tokenized
training F1:  0.998939367156
training accuracy:  0.998939367156
testing accuracy:  0.852329261101
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.853425385024 recall  0.853425385024 f1  0.853425385024
loaded (11113) terms
extended to (17035) terms
done loading vocabulary
vectorizing done, 17035 terms vocabulary tokenized
vectorizing done, 17035 terms vocabulary tokenized
training F1:  0.993636202934
training accuracy:  0.993636202934
testing accuracy:  0.755548366807
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.756903876792 recall  0.756903876792 f1  0.756903876792
loaded (146950) terms
vectorizing done, 146950 terms vocabulary tokenized
vectorizing done, 146950 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.85376670277
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.854753053638 recall  0.854753053638 f1  0.854753053638
loaded (31477) terms
extended to (39578) terms
done loading vocabulary
vectorizing done, 39578 terms vocabulary tokenized
vectorizing done, 39578 terms vocabulary tokenized
training F1:  0.996199398975
training accuracy:  0.996199398975
testing accuracy:  0.795403786799
ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.796866702071 recall  0.796866702071 f1  0.796866702071
loaded (171969) terms
vectorizing done, 171969 terms vocabulary tokenized
vectorizing done, 171969 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.85435465069
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.855416887945 recall  0.855416887945 f1  0.855416887945
loaded (56496) terms
extended to (75380) terms
done loading vocabulary
vectorizing done, 75380 terms vocabulary tokenized
vectorizing done, 75380 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.82852962614
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.829792883696 recall  0.829792883696 f1  0.829792883696
loaded (185472) terms
vectorizing done, 185472 terms vocabulary tokenized
vectorizing done, 185472 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.85417894345
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.855416887945 recall  0.855416887945 f1  0.855416887945
loaded (69999) terms
extended to (89202) terms
done loading vocabulary
vectorizing done, 89202 terms vocabulary tokenized
vectorizing done, 89202 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.832751124076
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.833908656399 recall  0.833908656399 f1  0.833908656399
loaded (153867) terms
vectorizing done, 153867 terms vocabulary tokenized
vectorizing done, 153867 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.853459918835
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.854487519915 recall  0.854487519915 f1  0.854487519915
loaded (38394) terms
extended to (48487) terms
done loading vocabulary
vectorizing done, 48487 terms vocabulary tokenized
vectorizing done, 48487 terms vocabulary tokenized
training F1:  0.99752519003
training accuracy:  0.99752519003
testing accuracy:  0.801343160037
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.802708443972 recall  0.802708443972 f1  0.802708443972
loaded (188338) terms
vectorizing done, 188338 terms vocabulary tokenized
vectorizing done, 188338 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.854889594529
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.85594795539 recall  0.85594795539 f1  0.85594795539
loaded (72865) terms
extended to (92479) terms
done loading vocabulary
vectorizing done, 92479 terms vocabulary tokenized
vectorizing done, 92479 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.83244391521
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.833643122677 recall  0.833643122677 f1  0.833643122677
loaded (98451) terms
vectorizing done, 98451 terms vocabulary tokenized
vectorizing done, 98451 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.846371048294
ng20_raw_stems_unigrams_df1_tf1  -->  precision  0.847583643123 recall  0.847583643123 f1  0.847583643123
loaded (1294667) terms
vectorizing done, 1294667 terms vocabulary tokenized
vectorizing done, 1294667 terms vocabulary tokenized
training F1:  0.999558069648
training accuracy:  0.999558069648
testing accuracy:  0.855545724697
ng20_raw_stems_bigrams_df1_tf1  -->  precision  0.856744556559 recall  0.856744556559 f1  0.856744556559
loaded (155942) terms
vectorizing done, 155942 terms vocabulary tokenized
vectorizing done, 155942 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.849999018151
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.85116834838 recall  0.85116834838 f1  0.85116834838
loaded (57491) terms
extended to (74114) terms
done loading vocabulary
vectorizing done, 74114 terms vocabulary tokenized
vectorizing done, 74114 terms vocabulary tokenized
training F1:  0.998762595015
training accuracy:  0.998762595015
testing accuracy:  0.830230918442
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.831253319172 recall  0.831253319172 f1  0.831253319172
loaded (109557) terms
vectorizing done, 109557 terms vocabulary tokenized
vectorizing done, 109557 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.849564436778
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.850902814657 recall  0.850902814657 f1  0.850902814657
loaded (11106) terms
extended to (16350) terms
done loading vocabulary
vectorizing done, 16350 terms vocabulary tokenized
vectorizing done, 16350 terms vocabulary tokenized
training F1:  0.992840728301
training accuracy:  0.992840728301
testing accuracy:  0.761589342888
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.762480084971 recall  0.762480084971 f1  0.762480084971
loaded (134473) terms
vectorizing done, 134473 terms vocabulary tokenized
vectorizing done, 134473 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.849916377567
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.851035581519 recall  0.851035581519 f1  0.851035581519
loaded (36022) terms
extended to (43618) terms
done loading vocabulary
vectorizing done, 43618 terms vocabulary tokenized
vectorizing done, 43618 terms vocabulary tokenized
training F1:  0.997171645749
training accuracy:  0.997171645749
testing accuracy:  0.800980027582
ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.802177376527 recall  0.802177376527 f1  0.802177376527
loaded (158605) terms
vectorizing done, 158605 terms vocabulary tokenized
vectorizing done, 158605 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.84917111769
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.850371747212 recall  0.850371747212 f1  0.850371747212
loaded (60154) terms
extended to (77021) terms
done loading vocabulary
vectorizing done, 77021 terms vocabulary tokenized
vectorizing done, 77021 terms vocabulary tokenized
training F1:  0.998850981085
training accuracy:  0.998850981085
testing accuracy:  0.828681276228
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.829792883696 recall  0.829792883696 f1  0.829792883696
loaded (175332) terms
vectorizing done, 175332 terms vocabulary tokenized
vectorizing done, 175332 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.850163632596
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.851301115242 recall  0.851301115242 f1  0.851301115242
loaded (76881) terms
extended to (94100) terms
done loading vocabulary
vectorizing done, 94100 terms vocabulary tokenized
vectorizing done, 94100 terms vocabulary tokenized
training F1:  0.998850981085
training accuracy:  0.998850981085
testing accuracy:  0.832130429262
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.833112055231 recall  0.833112055231 f1  0.833112055231
loaded (141098) terms
vectorizing done, 141098 terms vocabulary tokenized
vectorizing done, 141098 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.850513720504
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.851699415826 recall  0.851699415826 f1  0.851699415826
loaded (42647) terms
extended to (51619) terms
done loading vocabulary
vectorizing done, 51619 terms vocabulary tokenized
vectorizing done, 51619 terms vocabulary tokenized
training F1:  0.9976135761
training accuracy:  0.9976135761
testing accuracy:  0.805049977359
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.806558682953 recall  0.806558682953 f1  0.806558682953
loaded (177813) terms
vectorizing done, 177813 terms vocabulary tokenized
vectorizing done, 177813 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.850912552187
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.85209771641 recall  0.85209771641 f1  0.85209771641
loaded (79362) terms
extended to (96804) terms
done loading vocabulary
vectorizing done, 96804 terms vocabulary tokenized
vectorizing done, 96804 terms vocabulary tokenized
training F1:  0.998850981085
training accuracy:  0.998850981085
testing accuracy:  0.830995934992
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.83204992034 recall  0.83204992034 f1  0.83204992034
loaded (122412) terms
vectorizing done, 122412 terms vocabulary tokenized
vectorizing done, 122412 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.848752388733
ng20_raw_unigrams_stopwords  -->  precision  0.849973446628 recall  0.849973446628 f1  0.849973446628
loaded (1533239) terms
vectorizing done, 1533239 terms vocabulary tokenized
vectorizing done, 1533239 terms vocabulary tokenized
training F1:  0.999381297508
training accuracy:  0.999381297508
testing accuracy:  0.855181151213
ng20_raw_bigrams_stopwords  -->  precision  0.856213489113 recall  0.856213489113 f1  0.856213489113
loaded (115123) terms
vectorizing done, 115123 terms vocabulary tokenized
vectorizing done, 115123 terms vocabulary tokenized
training F1:  0.998939367156
training accuracy:  0.998939367156
testing accuracy:  0.849552407695
ng20_raw_lemmas_unigrams_stopwords_df1_tf1  -->  precision  0.850637280935 recall  0.850637280935 f1  0.850637280935
loaded (1464182) terms
vectorizing done, 1464182 terms vocabulary tokenized
vectorizing done, 1464182 terms vocabulary tokenized
training F1:  0.999292911437
training accuracy:  0.999292911437
testing accuracy:  0.855589572639
ng20_raw_lemmas_bigrams_stopwords_df1_tf1  -->  precision  0.856611789697 recall  0.856611789697 f1  0.856611789697
loaded (164528) terms
done loading vocabulary
vectorizing done, 164528 terms vocabulary tokenized
vectorizing done, 164528 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.851718125077
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.852761550717 recall  0.852761550717 f1  0.852761550717
loaded (49405) terms
extended to (66588) terms
done loading vocabulary
vectorizing done, 66588 terms vocabulary tokenized
vectorizing done, 66588 terms vocabulary tokenized
training F1:  0.998497436804
training accuracy:  0.998497436804
testing accuracy:  0.82715224718
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.828465215082 recall  0.828465215082 f1  0.828465215082
loaded (123271) terms
done loading vocabulary
vectorizing done, 123271 terms vocabulary tokenized
vectorizing done, 123271 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.84936084033
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.850504514073 recall  0.850504514073 f1  0.850504514073
loaded (8148) terms
extended to (13314) terms
done loading vocabulary
vectorizing done, 13314 terms vocabulary tokenized
vectorizing done, 13314 terms vocabulary tokenized
training F1:  0.989128513346
training accuracy:  0.989128513346
testing accuracy:  0.749635298098
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.75092936803 recall  0.75092936803 f1  0.75092936803
loaded (156323) terms
vectorizing done, 156323 terms vocabulary tokenized
vectorizing done, 156323 terms vocabulary tokenized
training F1:  0.998939367156
training accuracy:  0.998939367156
testing accuracy:  0.850464562335
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.851433882103 recall  0.851433882103 f1  0.851433882103
loaded (41200) terms
extended to (49568) terms
done loading vocabulary
vectorizing done, 49568 terms vocabulary tokenized
vectorizing done, 49568 terms vocabulary tokenized
training F1:  0.996552943256
training accuracy:  0.996552943256
testing accuracy:  0.791796684563
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.793016463091 recall  0.793016463091 f1  0.793016463091
loaded (165583) terms
vectorizing done, 165583 terms vocabulary tokenized
vectorizing done, 165583 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.851701024948
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.852761550717 recall  0.852761550717 f1  0.852761550717
loaded (50460) terms
extended to (67859) terms
done loading vocabulary
vectorizing done, 67859 terms vocabulary tokenized
vectorizing done, 67859 terms vocabulary tokenized
training F1:  0.998497436804
training accuracy:  0.998497436804
testing accuracy:  0.826628775377
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.827934147637 recall  0.827934147637 f1  0.827934147637
loaded (189246) terms
vectorizing done, 189246 terms vocabulary tokenized
vectorizing done, 189246 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.852363093897
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.853425385024 recall  0.853425385024 f1  0.853425385024
loaded (74123) terms
extended to (92329) terms
done loading vocabulary
vectorizing done, 92329 terms vocabulary tokenized
vectorizing done, 92329 terms vocabulary tokenized
training F1:  0.998585822874
training accuracy:  0.998585822874
testing accuracy:  0.828665779049
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.829792883696 recall  0.829792883696 f1  0.829792883696
loaded (160095) terms
vectorizing done, 160095 terms vocabulary tokenized
vectorizing done, 160095 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.85001905971
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.851035581519 recall  0.851035581519 f1  0.851035581519
loaded (44972) terms
extended to (54679) terms
done loading vocabulary
vectorizing done, 54679 terms vocabulary tokenized
vectorizing done, 54679 terms vocabulary tokenized
training F1:  0.997348417889
training accuracy:  0.997348417889
testing accuracy:  0.800226778297
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.801646309081 recall  0.801646309081 f1  0.801646309081
loaded (190103) terms
vectorizing done, 190103 terms vocabulary tokenized
vectorizing done, 190103 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.852625110226
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.853690918747 recall  0.853690918747 f1  0.853690918747
loaded (74980) terms
extended to (93374) terms
done loading vocabulary
vectorizing done, 93374 terms vocabulary tokenized
vectorizing done, 93374 terms vocabulary tokenized
training F1:  0.998585822874
training accuracy:  0.998585822874
testing accuracy:  0.828712139935
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.829792883696 recall  0.829792883696 f1  0.829792883696
loaded (98215) terms
vectorizing done, 98215 terms vocabulary tokenized
vectorizing done, 98215 terms vocabulary tokenized
training F1:  0.999027753226
training accuracy:  0.999027753226
testing accuracy:  0.846797522322
ng20_raw_stems_unigrams_stopwords_df1_tf1  -->  precision  0.847981943707 recall  0.847981943707 f1  0.847981943707
loaded (1390308) terms
vectorizing done, 1390308 terms vocabulary tokenized
vectorizing done, 1390308 terms vocabulary tokenized
training F1:  0.999381297508
training accuracy:  0.999381297508
testing accuracy:  0.853276673233
ng20_raw_stems_bigrams_stopwords_df1_tf1  -->  precision  0.854354753054 recall  0.854354753054 f1  0.854354753054
loaded (154264) terms
vectorizing done, 154264 terms vocabulary tokenized
vectorizing done, 154264 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.85094133908
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.85209771641 recall  0.85209771641 f1  0.85209771641
loaded (56049) terms
extended to (71625) terms
done loading vocabulary
vectorizing done, 71625 terms vocabulary tokenized
vectorizing done, 71625 terms vocabulary tokenized
training F1:  0.998585822874
training accuracy:  0.998585822874
testing accuracy:  0.828006330257
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.829261816251 recall  0.829261816251 f1  0.829261816251
loaded (107010) terms
vectorizing done, 107010 terms vocabulary tokenized
vectorizing done, 107010 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.846016403267
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.847185342539 recall  0.847185342539 f1  0.847185342539
loaded (8795) terms
extended to (13569) terms
done loading vocabulary
vectorizing done, 13569 terms vocabulary tokenized
vectorizing done, 13569 terms vocabulary tokenized
training F1:  0.99010076012
training accuracy:  0.99010076012
testing accuracy:  0.752090307676
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.752788104089 recall  0.752788104089 f1  0.752788104089
loaded (146536) terms
vectorizing done, 146536 terms vocabulary tokenized
vectorizing done, 146536 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.849491846775
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.850637280935 recall  0.850637280935 f1  0.850637280935
loaded (48321) terms
extended to (56168) terms
done loading vocabulary
vectorizing done, 56168 terms vocabulary tokenized
vectorizing done, 56168 terms vocabulary tokenized
training F1:  0.997260031819
training accuracy:  0.997260031819
testing accuracy:  0.796798741245
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.797928836962 recall  0.797928836962 f1  0.797928836962
loaded (155386) terms
vectorizing done, 155386 terms vocabulary tokenized
vectorizing done, 155386 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.850365521747
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.851566648964 recall  0.851566648964 f1  0.851566648964
loaded (57171) terms
extended to (72894) terms
done loading vocabulary
vectorizing done, 72894 terms vocabulary tokenized
vectorizing done, 72894 terms vocabulary tokenized
training F1:  0.998585822874
training accuracy:  0.998585822874
testing accuracy:  0.826781306602
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.828066914498 recall  0.828066914498 f1  0.828066914498
loaded (183740) terms
vectorizing done, 183740 terms vocabulary tokenized
vectorizing done, 183740 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.850307965484
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.851566648964 recall  0.851566648964 f1  0.851566648964
loaded (85525) terms
extended to (101923) terms
done loading vocabulary
vectorizing done, 101923 terms vocabulary tokenized
vectorizing done, 101923 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.829909482663
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.830987785449 recall  0.830987785449 f1  0.830987785449
loaded (150588) terms
vectorizing done, 150588 terms vocabulary tokenized
vectorizing done, 150588 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.848779488134
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.849840679766 recall  0.849840679766 f1  0.849840679766
loaded (52373) terms
extended to (61221) terms
done loading vocabulary
vectorizing done, 61221 terms vocabulary tokenized
vectorizing done, 61221 terms vocabulary tokenized
training F1:  0.99752519003
training accuracy:  0.99752519003
testing accuracy:  0.8001032655
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.801380775358 recall  0.801380775358 f1  0.801380775358
loaded (184632) terms
vectorizing done, 184632 terms vocabulary tokenized
vectorizing done, 184632 terms vocabulary tokenized
training F1:  0.999116139296
training accuracy:  0.999116139296
testing accuracy:  0.8503416103
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.851566648964 recall  0.851566648964 f1  0.851566648964
loaded (86417) terms
extended to (102936) terms
done loading vocabulary
vectorizing done, 102936 terms vocabulary tokenized
vectorizing done, 102936 terms vocabulary tokenized
training F1:  0.998674208945
training accuracy:  0.998674208945
testing accuracy:  0.829007970237
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.83019118428 recall  0.83019118428 f1  0.83019118428
done!

