IPython Notebookng20_classifier-cv Last Checkpoint: Dec 31 19:24 (autosaved)
File
Edit
View
Insert
Cell
Kernel
Help
Checkpoint created: 19:24:56
Cell Toolbar:
Classify 20ng docs
Classifiy 20ng docs using unigrams and bigrams features with different classifiers and report classification results
In [31]:

def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.feature_extraction.text import TfidfTransformer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = CountVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    # generate tfidf vectors
    transformer = TfidfTransformer()
    corpus_tfidf_vectors = transformer.fit_transform(corpus_vectors)
 
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-31-743655218ee8>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus(corpus,tokenizer,vocabulary,max_ngram_size):
In [32]:

def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
    # tokenize text
    from sklearn.feature_extraction.text import TfidfVectorizer
    from ng20_globals import *
    
    # generate corpus vectors
    vectorizer = TfidfVectorizer(min_df=min_df,tokenizer=tokenizer,ngram_range=(1,max_ngram_size),vocabulary=vocabulary,stop_words={})
    corpus_tfidf_vectors = vectorizer.fit_transform(corpus)
    
    print 'vectorizing done, {0} terms vocabulary tokenized'.format(len(vectorizer.vocabulary_))
    
    return corpus_tfidf_vectors
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-32-f88374f887f0>:1: SyntaxWarning: import * only allowed at module level
  def vectorize_corpus_new(corpus,tokenizer,vocabulary,max_ngram_size):
In [33]:

# given classifier predictions probabilities, return predictions with top n probabilities > 0.5 for each instance or greatest one if all are <=0.5
def get_max_n_pred(pred_proba, n_pred, threshold):
    import heapq
    import numpy
    max_n_pred = numpy.ndarray(shape=pred_proba.shape)
    for i in range(len(pred_proba)):
        largest_n_proba = heapq.nlargest(n_pred,pred_proba[i])
        max_n_pred[i] = numpy.array(((pred_proba[i]>threshold) & (pred_proba[i]>=largest_n_proba[len(largest_n_proba)-1]) & 1))
        if max_n_pred[i].sum(axis=0)==0: # at least one label should be returned
            max_n_pred[i] = numpy.array(((pred_proba[i]>=max(pred_proba[i])) & 1))
    return max_n_pred
In [34]:

# reference: http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification
def classify(x_train,y_train,x_test,y_test,max_labels):
    from sklearn.preprocessing import MultiLabelBinarizer
    from sklearn.multiclass import OneVsRestClassifier
    from sklearn.svm import SVC
    from sklearn.svm import LinearSVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.preprocessing import binarize
    from sklearn.cross_validation import train_test_split
    from sklearn import metrics
    import numpy
    from numpy import mean
    import scipy
    from sklearn.cross_validation import cross_val_score
    from sklearn.metrics import make_scorer
    from sklearn.metrics import precision_score
    from sklearn.metrics import recall_score
    from sklearn.metrics import f1_score
    
    # combine train and test vectors
    #print 'merging training and testing samples x({0}),x({1})'.format(x_train.shape,x_test.shape)
    #print 'merging training and testing samples y({0}),y({1})'.format(len(y_train),len(y_test))
    if x_test.shape[0]>0:
        x = scipy.sparse.vstack((x_train,x_test))
        y = y_train + y_test
    else:
        x = x_train
        y = y_train
    #print 'merged into x({0})'.format(x.shape)
    #print 'merged into y({0})'.format(len(y))
    # binarize the labels
    #mlb = MultiLabelBinarizer()
    #y_train_binarized = mlb.fit_transform(y_train)
    
    # train/test split
    #corpus_tfidf_vectors, labels_binarized = shuffle(corpus_tfidf_vectors, labels_binarized)
    #x_train, x_test, y_train, y_test = train_test_split(corpus_tfidf_vectors, labels_binarized, test_size=test_size, random_state=1)
    
    # classify
    #cls = OneVsRestClassifier(LogisticRegression(class_weight='auto'))
    #cls = OneVsRestClassifier(LogisticRegression())
    #cls = MultinomialNB(alpha=0.01)
    #cls = OneVsRestClassifier(BernoulliNB()need binarize(x_train and x_test))
    #cls = OneVsRestClassifier(SVC(kernel='linear',probability=True,max_iter=1000))
    cls = LinearSVC()
    acc_scores = cross_val_score(cls,x,y,scoring='accuracy',cv=10,n_jobs=-1)
    print 'accuracy scores = {0},{1}'.format(acc_scores,mean(acc_scores))
    macro_p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro precision scores = {0},{1}'.format(macro_p_scores,mean(macro_p_scores))
    macro_r_scores = cross_val_score(cls,x,y,scoring=make_scorer(recall_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro recall scores = {0},{1}'.format(macro_r_scores,mean(macro_r_scores))
    macro_f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='macro'),cv=10,n_jobs=-1)
    print 'macro f1 scores = {0},{1}'.format(macro_f1_scores,mean(macro_f1_scores))
    p_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average precision scores = {0},{1}'.format(p_scores,mean(p_scores))
    r_scores = cross_val_score(cls,x,y,scoring=make_scorer(precision_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted average recall scores = {0},{1}'.format(r_scores,mean(r_scores))
    f1_scores = cross_val_score(cls,x,y,scoring=make_scorer(f1_score,average='weighted'),cv=10,n_jobs=-1)
    print 'weighted f1 scores = {0},{1}'.format(f1_scores,mean(f1_scores))
   
    return {'precision':mean(macro_p_scores),
            'recall':mean(macro_r_scores),
            'f1':mean(macro_f1_scores)}
In [35]:

import sklearn
from sklearn.svm import LinearSVC
c = LinearSVC()
print sklearn.__version__
0.15.2
In [36]:

def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_unigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-36-5bcc0f6a848c>:1: SyntaxWarning: import * only allowed at module level
  def test_all_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [37]:

def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-37-094e349cf724>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [38]:

def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = None
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}{1}_bigrams{2}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-38-c28207c92f80>:1: SyntaxWarning: import * only allowed at module level
  def test_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [39]:

def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-39-781cd4f52dc5>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [40]:

def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    from sklearn.decomposition import TruncatedSVD
    from scipy import sparse
    import numpy
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # apply LSA
    #print numpy.max(corpus_train_tfidf_vectors)
    #print numpy.min(corpus_train_tfidf_vectors)
    lsa = TruncatedSVD(n_components=num_components)
    lsa.fit(corpus_train_tfidf_vectors)
    #corpus_train_tfidf_vectors = numpy.dot(corpus_train_tfidf_vectors,pca.components_.transpose())
    corpus_train_tfidf_vectors = lsa.transform(corpus_train_tfidf_vectors)
    corpus_test_tfidf_vectors = lsa.transform(corpus_test_tfidf_vectors)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print 'LSA ^' , vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-40-0ae0e12f66cc>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_with_LSA(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens,num_components):
In [41]:

def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 1
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)    
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-41-d27651528d70>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_unigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [42]:

def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer    
    from ng20_globals import *
    from ng20_vocabulary_loader import load_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary = load_vocabulary(vocabulary_tbl_name)
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-42-8129eac551f8>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [43]:

def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-43-180bdc332cbe>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [44]:

def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-44-cd1ea993b277>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [45]:

def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
    print 'done loading vocabulary'
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-45-98c5bdcd6b4f>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [46]:

def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-46-1c5602c28486>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [47]:

def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-47-c5ecc72d6e7c>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [48]:

def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-48-60ce875247ce>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [49]:

def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-49-2010f39a430e>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [50]:

def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-50-a08ffa055f62>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [51]:

def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-51-781d3020ecf2>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [52]:

def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-52-69e08236a4c4>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [53]:

def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from lemmatizing_tokenizer import LemmaTokenizer
    from lemmatizing_tokenizer import RawLemmaTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = LemmaTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawLemmaTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_lemmas{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_lemmas{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'lemma')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-53-bdd713c1f2ac>:1: SyntaxWarning: import * only allowed at module level
  def test_lemmatized_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [54]:

def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()    
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()    
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')    
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-54-6b79430f2923>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiki_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [55]:

def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary_extend_unigrams
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    if len(bigrams_src)==1:
        vocabulary_tbl_intersect = '{0}_bigrams'.format(bigrams_src[0])
    else:
        vocabulary_tbl_intersect = '{0}_'.format(bigrams_src[0])
        for i in range(len(bigrams_src)-1):
            vocabulary_tbl_intersect = '{0}{1}_'.format(vocabulary_tbl_intersect,bigrams_src[i+1])
        vocabulary_tbl_intersect = '{0}bigrams_vw'.format(vocabulary_tbl_intersect)
        
    vocabulary = load_common_vocabulary_extend_unigrams(vocabulary_tbl_name,vocabulary_tbl_intersect,'stem')
    print 'done loading vocabulary'
    
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name,'^',vocabulary_tbl_intersect,'(extended unigrams) --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-55-a650503cc609>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_bigrams_unigrams(bigrams_src,corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [56]:

def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiktionary_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-56-3444b80fb7e1>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_wiktionary_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [57]:

def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
        
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'google_bigrams'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-57-dd4a635e1842>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_google_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [58]:

def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
    from stemming_tokenizer import StemmingTokenizer
    from stemming_tokenizer import RawStemmingTokenizer
    from ng20_globals import *
    from ng20_vocabulary_loader import load_common_vocabulary
    
    max_ngram_size = 2
    
    if with_stopwords_removal==False:
        stopwords_pattern = ''
    else:
        stopwords_pattern = '_stopwords'
    if use_chi_features==False:
        chi_features_pattern = ''
    else:
        chi_features_pattern = '_chi'
    if use_raw_tokens==False:
        raw_tokens_pattern = ''
        tokenizer = StemmingTokenizer()
    else:
        raw_tokens_pattern = '_raw'
        tokenizer = RawStemmingTokenizer()
    
    # load vocabulary
    vocabulary_tbl_name1 = 'ng20{0}_stems{1}_unigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    vocabulary_tbl_name2 = 'ng20{0}_stems{1}_bigrams{2}_df{3}_tf{4}'.format(raw_tokens_pattern,chi_features_pattern,stopwords_pattern,min_df,min_tf)
    
    vocabulary_tbl_intersect = 'wiki_wiktionary_google_bigrams_vw'
    vocabulary = load_common_vocabulary(vocabulary_tbl_name1,vocabulary_tbl_name2,vocabulary_tbl_intersect,'stem')
 
    # generate tfidf vectors
    corpus_train_tfidf_vectors = vectorize_corpus(corpus_train_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    corpus_test_tfidf_vectors = vectorize_corpus(corpus_test_data['corpus'],tokenizer,vocabulary,max_ngram_size)
    
    # classify & evaluate    
    results = classify(corpus_train_tfidf_vectors,corpus_train_data['labels'],
                       corpus_test_tfidf_vectors,corpus_test_data['labels'],
                       max_labels)
    
    print vocabulary_tbl_name1,'^',vocabulary_tbl_name2,'^',vocabulary_tbl_intersect,' --> ','precision ',results['precision'],'recall ',results['recall'],'f1 ',results['f1']
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<input>:1: SyntaxWarning: import * only allowed at module level
<ipython-input-58-ce43e0732809>:1: SyntaxWarning: import * only allowed at module level
  def test_stemmed_all_bigrams(corpus_train_data,corpus_test_data,with_stopwords_removal,use_chi_features,use_raw_tokens):
In [59]:

def test():
    from ng20_corpus_loader import load_corpus_and_labels
    from ng20_corpus_loader import load_corpus_with_labels_mappings
    
    # load 20ng docs with class lables from DB
    corpus_train_data = load_corpus_and_labels('train')
    print 'done loading {0} train records and {1} labels.'.format(len(corpus_train_data['corpus']),len(corpus_train_data['labels_dic']))
 
    corpus_test_data = load_corpus_with_labels_mappings('test',corpus_train_data['labels_dic'])
    print 'done loading {0} test records.'.format(len(corpus_test_data['corpus']))
    
    stopwords_removal_mask = 1
    chi_features_mask = 2
    raw_tokens_mask = 4
    for i in range(4,6): # test w/o stopword removal and w/o chi square features and w/o raw tokens
        stopwords_removal = i&stopwords_removal_mask==stopwords_removal_mask
        use_chi_features = i&chi_features_mask==chi_features_mask
        use_raw_tokens = i&raw_tokens_mask==raw_tokens_mask
        
        test_all_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        #test_lemmatized_bigrams_with_LSA({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
        #                         {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
        #                         stopwords_removal,use_chi_features,use_raw_tokens,113240)
        
        test_lemmatized_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_lemmatized_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_unigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_wiktionary_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiki_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_wiktionary_google_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_all_bigrams({'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
        
        test_stemmed_bigrams_unigrams(['wiki','wiktionary','google'],{'corpus':corpus_train_data['corpus'],'labels':corpus_train_data['labels']},
                                 {'corpus':corpus_test_data['corpus'],'labels':corpus_test_data['labels']},
                                 stopwords_removal,use_chi_features,use_raw_tokens)
In [60]:

# test using all vocabulary
test()
 
print 'done!'
loaded 18828 records.
done loading 18828 train records and 20 labels.
loaded 0 records.
done loading 0 test records.
loaded (167750) terms
vectorizing done, 167750 terms vocabulary tokenized
vectorizing done, 167750 terms vocabulary tokenized
accuracy scores = [ 0.86938128  0.90307203  0.9300106   0.93050398  0.92140202  0.92291334
  0.92929293  0.92336349  0.91480298  0.89552239],0.914026504937
macro precision scores = [ 0.86822554  0.90550384  0.93223625  0.93105072  0.92200187  0.92317643
  0.92924023  0.92305512  0.91450111  0.8942132 ],0.914320430048
macro recall scores = [ 0.86198849  0.89939382  0.92696483  0.92935231  0.91976847  0.92032804
  0.92405256  0.92120067  0.91125869  0.89130829],0.910561614306
macro f1 scores = [ 0.86199287  0.90094391  0.92861734  0.92999872  0.92039039  0.92073901
  0.92547035  0.92176228  0.91233098  0.89163247],0.911387832767
weighted average precision scores = [ 0.86988846  0.9052897   0.93114951  0.93114413  0.92154726  0.92418901
  0.93005903  0.92400381  0.91573093  0.89752151],0.915052334798
weighted average recall scores = [ 0.86988846  0.9052897   0.93114951  0.93114413  0.92154726  0.92418901
  0.93005903  0.92400381  0.91573093  0.89752151],0.915052334798
weighted f1 scores = [ 0.86731202  0.9029547   0.92976904  0.93062726  0.92103678  0.92259254
  0.92866347  0.92334384  0.91476286  0.89545867],0.913652117712
ng20_raw_unigrams  -->  precision  0.914320430048 recall  0.910561614306 f1  0.911387832767
loaded (1605094) terms
vectorizing done, 1605094 terms vocabulary tokenized
vectorizing done, 1605094 terms vocabulary tokenized
accuracy scores = [ 0.88471708  0.91525424  0.93584305  0.93687003  0.92830589  0.92929293
  0.94524189  0.92602448  0.92598509  0.89712154],0.922465622237
macro precision scores = [ 0.88478404  0.91869598  0.93853058  0.93759553  0.92941172  0.93069274
  0.94618281  0.92783423  0.92657587  0.89913149],0.923943498527
macro recall scores = [ 0.8756585   0.9119842   0.9320936   0.93477603  0.92701923  0.92629596
  0.94102385  0.9246193   0.92342943  0.89378696],0.91906870569
macro f1 scores = [ 0.87524107  0.91361763  0.93395485  0.93588139  0.9278342   0.92725367
  0.94253559  0.92554054  0.92445059  0.89442015],0.920072966862
weighted average precision scores = [ 0.88547118  0.91777553  0.93743419  0.93747286  0.92905908  0.93131194
  0.94659715  0.9271729   0.92692454  0.90150823],0.9240727587
weighted average recall scores = [ 0.88547118  0.91777553  0.93743419  0.93747286  0.92905908  0.93131194
  0.94659715  0.9271729   0.92692454  0.90150823],0.9240727587
weighted f1 scores = [ 0.88146474  0.91516372  0.93548103  0.93690097  0.92832777  0.92916676
  0.94497148  0.92596564  0.92594868  0.89741831],0.9220809097
ng20_raw_bigrams  -->  precision  0.923943498527 recall  0.91906870569 f1  0.920072966862
loaded (160532) terms
vectorizing done, 160532 terms vocabulary tokenized
vectorizing done, 160532 terms vocabulary tokenized
accuracy scores = [ 0.87308302  0.89989407  0.93531283  0.92785146  0.91980882  0.92450824
  0.92663477  0.91857371  0.91373802  0.89392324],0.913332817721
macro precision scores = [ 0.87280033  0.90256687  0.93813049  0.92917006  0.91989596  0.92410439
  0.92723794  0.91904172  0.91366259  0.89241398],0.913902433498
macro recall scores = [ 0.86551687  0.89657033  0.93230953  0.92661705  0.91810729  0.92149229
  0.92145441  0.91657056  0.90968774  0.89025332],0.909857938717
macro f1 scores = [ 0.86573744  0.8979391   0.93415842  0.92756032  0.9185032   0.92174429
  0.92301986  0.91728033  0.91082333  0.89014285],0.910690914526
weighted average precision scores = [ 0.8736506   0.90254248  0.93672463  0.92863359  0.91971572  0.92598836
  0.9276028   0.91959365  0.91465016  0.89626226],0.914536425681
weighted average recall scores = [ 0.8736506   0.90254248  0.93672463  0.92863359  0.91971572  0.92598836
  0.9276028   0.91959365  0.91465016  0.89626226],0.914536425681
weighted f1 scores = [ 0.87082403  0.89988268  0.93513129  0.9279253   0.91929971  0.92429793
  0.92599028  0.91859365  0.9134334   0.89398402],0.912936230196
ng20_raw_lemmas_unigrams_df1_tf1  -->  precision  0.913902433498 recall  0.909857938717 f1  0.910690914526
loaded (1535281) terms
vectorizing done, 1535281 terms vocabulary tokenized
vectorizing done, 1535281 terms vocabulary tokenized
accuracy scores = [ 0.88313062  0.91366525  0.93796394  0.93421751  0.93361657  0.93035619
  0.9404572   0.92496009  0.92332268  0.89712154],0.921881159492
macro precision scores = [ 0.8842823   0.91815576  0.94037757  0.93583757  0.93404201  0.93059448
  0.94088315  0.92677391  0.92405423  0.898638  ],0.923363900025
macro recall scores = [ 0.87346178  0.91024196  0.93468606  0.93192522  0.93182424  0.92715331
  0.93594279  0.92315197  0.92028731  0.89432325],0.918299789352
macro f1 scores = [ 0.87230301  0.91208591  0.93639099  0.9333842   0.93259731  0.92773099
  0.9373016   0.92416002  0.92145932  0.89464503],0.919205837455
weighted average precision scores = [ 0.88439007  0.91699203  0.93931827  0.93528034  0.93395423  0.93232449
  0.94162782  0.92630835  0.92446273  0.90084286],0.923550118795
weighted average recall scores = [ 0.88439007  0.91699203  0.93931827  0.93528034  0.93395423  0.93232449
  0.94162782  0.92630835  0.92446273  0.90084286],0.923550118795
weighted f1 scores = [ 0.87906914  0.91369347  0.93764908  0.93430214  0.93351077  0.93029782
  0.940041    0.92490238  0.92325202  0.8972902 ],0.921400801002
ng20_raw_lemmas_bigrams_df1_tf1  -->  precision  0.923363900025 recall  0.918299789352 f1  0.919205837455
loaded (214720) terms
done loading vocabulary
vectorizing done, 214720 terms vocabulary tokenized
vectorizing done, 214720 terms vocabulary tokenized
accuracy scores = [ 0.87731359  0.90254237  0.93743372  0.93050398  0.92405736  0.92450824
  0.93354599  0.92442789  0.91906283  0.89445629],0.916785225623
macro precision scores = [ 0.87840496  0.90484511  0.9396294   0.93166797  0.92379648  0.92429883
  0.9335385   0.92514639  0.91835821  0.89429977],0.917398560943
macro recall scores = [ 0.86936461  0.8990825   0.93436119  0.92857573  0.92244518  0.92177037
  0.92861267  0.92268421  0.91506595  0.89124968],0.913321208067
macro f1 scores = [ 0.86965266  0.90039124  0.93606437  0.92978542  0.92265696  0.92210975
  0.92992538  0.92348143  0.91597885  0.89125874],0.914130480382
weighted average precision scores = [ 0.87846523  0.90472458  0.93853316  0.93125965  0.92382684  0.92611286
  0.93456264  0.9251461   0.91985256  0.89735191],0.917983552061
weighted average recall scores = [ 0.87846523  0.90472458  0.93853316  0.93125965  0.92382684  0.92611286
  0.93456264  0.9251461   0.91985256  0.89735191],0.917983552061
weighted f1 scores = [ 0.87484308  0.90236051  0.93720484  0.93058112  0.92351843  0.92447594
  0.93304191  0.92438165  0.91880319  0.89449184],0.916370250379
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.917398560943 recall  0.913321208067 f1  0.914130480382
loaded (54188) terms
extended to (72897) terms
done loading vocabulary
vectorizing done, 72897 terms vocabulary tokenized
vectorizing done, 72897 terms vocabulary tokenized
accuracy scores = [ 0.85034373  0.87870763  0.91781548  0.9061008   0.90015932  0.90909091
  0.91706539  0.91112294  0.89616613  0.86513859],0.895171092359
macro precision scores = [ 0.84935828  0.88108647  0.92028666  0.90713209  0.90009334  0.90802575
  0.91634697  0.91297423  0.89387584  0.86519035],0.895436996627
macro recall scores = [ 0.84197419  0.87471336  0.91474416  0.90351053  0.89835381  0.90612362
  0.91245244  0.9096354   0.89153172  0.86184164],0.891488086381
macro f1 scores = [ 0.84106007  0.87608913  0.91646158  0.90489301  0.89883506  0.90623243
  0.91344323  0.91066242  0.89217214  0.86168309],0.892153215495
weighted average precision scores = [ 0.85091367  0.88107019  0.91917196  0.90750729  0.9000514   0.90974409
  0.91793864  0.9120604   0.89652599  0.86895453],0.896393815371
weighted average recall scores = [ 0.85091367  0.88107019  0.91917196  0.90750729  0.9000514   0.90974409
  0.91793864  0.9120604   0.89652599  0.86895453],0.896393815371
weighted f1 scores = [ 0.8471601   0.87843735  0.91757983  0.90640918  0.89975478  0.9086472
  0.91663979  0.91100334  0.895845    0.86531193],0.89467884845
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.895436996627 recall  0.891488086381 f1  0.892153215495
loaded (171574) terms
done loading vocabulary
vectorizing done, 171574 terms vocabulary tokenized
vectorizing done, 171574 terms vocabulary tokenized
accuracy scores = [ 0.8725542   0.8940678   0.9321315   0.93156499  0.91980882  0.92610314
  0.92663477  0.92283129  0.91054313  0.89285714],0.912909677088
macro precision scores = [ 0.87418532  0.89635119  0.93475226  0.93274602  0.92010964  0.92581954
  0.92633619  0.92330851  0.91073082  0.89152326],0.913586276863
macro recall scores = [ 0.86495611  0.89069207  0.92913831  0.93019428  0.91792099  0.92399803
  0.92136261  0.92101894  0.90719501  0.88915869],0.909563503453
macro f1 scores = [ 0.86550502  0.8918844   0.93093278  0.93113253  0.91842445  0.92401753
  0.92270144  0.92169286  0.90830418  0.88917937],0.91037745536
weighted average precision scores = [ 0.87456054  0.89630567  0.93336571  0.93236377  0.9198026   0.9277599
  0.92743909  0.92381467  0.91153659  0.89523306],0.914218159928
weighted average recall scores = [ 0.87456054  0.89630567  0.93336571  0.93236377  0.9198026   0.9277599
  0.92743909  0.92381467  0.91153659  0.89523306],0.914218159928
weighted f1 scores = [ 0.87059283  0.89385088  0.93189323  0.93164041  0.91924824  0.92610463
  0.92604754  0.92288862  0.91043344  0.89298099],0.91256807981
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.913586276863 recall  0.909563503453 f1  0.91037745536
loaded (11042) terms
extended to (16946) terms
done loading vocabulary
vectorizing done, 16946 terms vocabulary tokenized
vectorizing done, 16946 terms vocabulary tokenized
accuracy scores = [ 0.77736647  0.82362288  0.8621421   0.83872679  0.85130112  0.85380117
  0.85539607  0.85311336  0.82800852  0.79850746],0.834198593557
macro precision scores = [ 0.77375626  0.82758978  0.86233779  0.83927299  0.84947755  0.85395691
  0.85307595  0.85314307  0.82539084  0.79884659],0.83368477251
macro recall scores = [ 0.76842488  0.81750888  0.8574806   0.83548945  0.84970529  0.85006563
  0.84857226  0.85199218  0.82246051  0.79270843],0.829440812357
macro f1 scores = [ 0.7668404   0.81917001  0.85859647  0.83659636  0.84923695  0.85024867
  0.84907985  0.85176755  0.82246522  0.79354734],0.829754881117
weighted average precision scores = [ 0.77817417  0.8272147   0.86326727  0.84206737  0.85090649  0.85302593
  0.85585926  0.85375078  0.8283094   0.80516556],0.835774093167
weighted average recall scores = [ 0.77817417  0.8272147   0.86326727  0.84206737  0.85090649  0.85302593
  0.85585926  0.85375078  0.8283094   0.80516556],0.835774093167
weighted f1 scores = [ 0.77439218  0.82290482  0.86153195  0.83959848  0.85074369  0.8519798
  0.85409534  0.8526572   0.82688329  0.79965383],0.833444057657
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.83368477251 recall  0.829440812357 f1  0.829754881117
loaded (190903) terms
vectorizing done, 190903 terms vocabulary tokenized
vectorizing done, 190903 terms vocabulary tokenized
accuracy scores = [ 0.87308302  0.90254237  0.93796394  0.92891247  0.92033988  0.92078682
  0.92982456  0.9217669   0.91373802  0.89658849],0.914554647212
macro precision scores = [ 0.87348107  0.90481489  0.94038679  0.93040676  0.92036117  0.92012053
  0.93114336  0.92238252  0.91399543  0.89582285],0.915291536827
macro recall scores = [ 0.86529328  0.8989708   0.93514947  0.92762715  0.91828428  0.91793974
  0.92459192  0.9196945   0.90979684  0.89316527],0.91105132522
macro f1 scores = [ 0.86547891  0.90024997  0.9368628   0.92868908  0.91885871  0.91805878
  0.9263439   0.92053394  0.91108466  0.89303646],0.911919723201
weighted average precision scores = [ 0.87437806  0.90486312  0.9390631   0.92978453  0.92027089  0.9219668
  0.93115565  0.92275862  0.91479391  0.89934643],0.915838110628
weighted average recall scores = [ 0.87437806  0.90486312  0.9390631   0.92978453  0.92027089  0.9219668
  0.93115565  0.92275862  0.91479391  0.89934643],0.915838110628
weighted f1 scores = [ 0.87089046  0.90238796  0.93775701  0.92903894  0.91989569  0.92050182
  0.92920704  0.92178713  0.9135658   0.89662066],0.914165251494
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.915291536827 recall  0.91105132522 f1  0.911919723201
loaded (30371) terms
extended to (38414) terms
done loading vocabulary
vectorizing done, 38414 terms vocabulary tokenized
vectorizing done, 38414 terms vocabulary tokenized
accuracy scores = [ 0.82072977  0.84798729  0.89395546  0.87692308  0.87838555  0.88197767
  0.88835726  0.88025546  0.86261981  0.83742004],0.866861138813
macro precision scores = [ 0.82060028  0.84878937  0.89436421  0.8764409   0.87671867  0.88201266
  0.88702122  0.88016294  0.86274294  0.83658862],0.866544181035
macro recall scores = [ 0.81318879  0.84357937  0.89054781  0.87442254  0.87559908  0.87864512
  0.8822275   0.87743796  0.85914137  0.8321315 ],0.862692103
macro f1 scores = [ 0.81310873  0.84464553  0.89184564  0.87508212  0.87555279  0.8790995
  0.88312741  0.87802354  0.86016006  0.8328222 ],0.863346751227
weighted average precision scores = [ 0.82267706  0.84943634  0.89502271  0.8777001   0.87817701  0.88308553
  0.88912239  0.88069946  0.86406532  0.84214521],0.868213113737
weighted average recall scores = [ 0.82267706  0.84943634  0.89502271  0.8777001   0.87817701  0.88308553
  0.88912239  0.88069946  0.86406532  0.84214521],0.868213113737
weighted f1 scores = [ 0.81869522  0.84739707  0.89394475  0.87696658  0.87767896  0.88137836
  0.88742632  0.87974019  0.86258181  0.83826307],0.866407232125
ng20_raw_lemmas_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.866544181035 recall  0.862692103 f1  0.863346751227
loaded (217713) terms
vectorizing done, 217713 terms vocabulary tokenized
vectorizing done, 217713 terms vocabulary tokenized
accuracy scores = [ 0.87784241  0.90254237  0.93902439  0.93050398  0.92352629  0.9255715
  0.93195109  0.92442789  0.91746539  0.89498934],0.916784465044
macro precision scores = [ 0.87921542  0.90475769  0.94112595  0.9317334   0.92330128  0.92518031
  0.93168888  0.92573166  0.91677917  0.89539365],0.917490739287
macro recall scores = [ 0.86971714  0.89950697  0.9361805   0.92859108  0.92184308  0.92279088
  0.92679861  0.92310318  0.91342043  0.89206665],0.913401853547
macro f1 scores = [ 0.86984708  0.90074178  0.93781598  0.92981652  0.92220852  0.92310134
  0.92804631  0.92392264  0.91441544  0.8920923 ],0.914200790331
weighted average precision scores = [ 0.87939249  0.90448966  0.94004438  0.9313224   0.92331605  0.92694019
  0.93282471  0.92554095  0.91822093  0.8981152 ],0.91802069527
weighted average recall scores = [ 0.87939249  0.90448966  0.94004438  0.9313224   0.92331605  0.92694019
  0.93282471  0.92554095  0.91822093  0.8981152 ],0.91802069527
weighted f1 scores = [ 0.87527256  0.90238167  0.93882512  0.9306025   0.92310166  0.92545714
  0.93134467  0.92451638  0.91723861  0.89505017],0.916379048257
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.917490739287 recall  0.913401853547 f1  0.914200790331
loaded (57181) terms
extended to (76318) terms
done loading vocabulary
vectorizing done, 76318 terms vocabulary tokenized
vectorizing done, 76318 terms vocabulary tokenized
accuracy scores = [ 0.85298784  0.87976695  0.91940615  0.90875332  0.90281466  0.90643275
  0.91600213  0.90739755  0.89616613  0.86780384],0.895753130906
macro precision scores = [ 0.85391221  0.88209142  0.92110752  0.90957394  0.90277179  0.90518004
  0.91578571  0.90943542  0.89390671  0.86698975],0.896075450118
macro recall scores = [ 0.84402014  0.87616942  0.91616577  0.90638359  0.90084767  0.90334301
  0.91112754  0.90549093  0.89142998  0.86401667],0.8918994717
macro f1 scores = [ 0.84302972  0.87755909  0.91775793  0.90763368  0.90140572  0.90346709
  0.91231806  0.9065608   0.89200246  0.86391334],0.892564789062
weighted average precision scores = [ 0.85470245  0.88169486  0.92027846  0.90987455  0.90270853  0.9070031
  0.9168706   0.90872356  0.89651575  0.87089837],0.896927021099
weighted average recall scores = [ 0.85470245  0.88169486  0.92027846  0.90987455  0.90270853  0.9070031
  0.9168706   0.90872356  0.89651575  0.87089837],0.896927021099
weighted f1 scores = [ 0.84938756  0.87945793  0.91908429  0.90900107  0.90239904  0.90598365
  0.91542744  0.90724858  0.89570698  0.86785757],0.895155410818
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.896075450118 recall  0.8918994717 f1  0.892564789062
loaded (230421) terms
vectorizing done, 230421 terms vocabulary tokenized
vectorizing done, 230421 terms vocabulary tokenized
accuracy scores = [ 0.87784241  0.90519068  0.93849417  0.92997347  0.92352629  0.92397661
  0.93301435  0.92389569  0.91906283  0.89552239],0.917049889189
macro precision scores = [ 0.87861738  0.90736737  0.9407061   0.93112543  0.92352573  0.92380114
  0.93302573  0.92519348  0.91875508  0.89541846],0.917753589157
macro recall scores = [ 0.86958622  0.90162879  0.93538685  0.92807583  0.9217547   0.92127079
  0.92780324  0.92228859  0.91524192  0.89228608],0.913532302166
macro f1 scores = [ 0.86961709  0.9029619   0.93709319  0.92929139  0.92209506  0.92154215
  0.92916554  0.92320816  0.91629388  0.8922952 ],0.914356356768
weighted average precision scores = [ 0.87894097  0.90726993  0.93962977  0.93067544  0.92327781  0.92559242
  0.93406896  0.9250006   0.92009372  0.89852274],0.91830723426
weighted average recall scores = [ 0.87894097  0.90726993  0.93962977  0.93067544  0.92327781  0.92559242
  0.93406896  0.9250006   0.92009372  0.89852274],0.91830723426
weighted f1 scores = [ 0.87518396  0.90498755  0.93825913  0.93005195  0.92291053  0.92387803
  0.93244549  0.92395694  0.91894278  0.89556829],0.916618465035
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.917753589157 recall  0.913532302166 f1  0.914356356768
loaded (69889) terms
extended to (89352) terms
done loading vocabulary
vectorizing done, 89352 terms vocabulary tokenized
vectorizing done, 89352 terms vocabulary tokenized
accuracy scores = [ 0.85510312  0.88347458  0.92099682  0.9061008   0.90228359  0.90855928
  0.91812865  0.90952634  0.90042599  0.87206823],0.897666739187
macro precision scores = [ 0.85549118  0.88537202  0.92324115  0.90719954  0.90220195  0.9070808
  0.91766733  0.91135849  0.89906904  0.8715781 ],0.898025960263
macro recall scores = [ 0.84642598  0.87984095  0.91806711  0.90381372  0.90039495  0.90510027
  0.91346758  0.90768483  0.8965579   0.86868513],0.894003842897
macro f1 scores = [ 0.84584037  0.88115384  0.91971864  0.90513868  0.9009298   0.90519467
  0.91454727  0.90878983  0.89723614  0.86857824],0.894712748007
weighted average precision scores = [ 0.85652791  0.88550798  0.92221699  0.90753048  0.90214339  0.90938164
  0.91902856  0.91073777  0.90095545  0.87553375],0.898956393077
weighted average recall scores = [ 0.85652791  0.88550798  0.92221699  0.90753048  0.90214339  0.90938164
  0.91902856  0.91073777  0.90095545  0.87553375],0.898956393077
weighted f1 scores = [ 0.85194429  0.88329997  0.92080675  0.90647634  0.90188486  0.90813312
  0.91766229  0.90947185  0.90014432  0.8723451 ],0.897216889061
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.898025960263 recall  0.894003842897 f1  0.894712748007
loaded (197794) terms
vectorizing done, 197794 terms vocabulary tokenized
vectorizing done, 197794 terms vocabulary tokenized
accuracy scores = [ 0.87625595  0.90148305  0.93743372  0.92997347  0.92087095  0.92238171
  0.93141946  0.9222991   0.91160809  0.89392324],0.914764874716
macro precision scores = [ 0.8773913   0.90376212  0.93969188  0.93120215  0.92129122  0.9219146
  0.93200954  0.92314209  0.91206399  0.89332717],0.915579605454
macro recall scores = [ 0.86790953  0.89822353  0.93434519  0.92866882  0.91875763  0.92002825
  0.92614894  0.92021466  0.90809437  0.89035209],0.911274300386
macro f1 scores = [ 0.86809594  0.89946488  0.93610906  0.92961221  0.91938833  0.92002722
  0.92775054  0.92116239  0.90937149  0.89040755],0.912138961916
weighted average precision scores = [ 0.87803008  0.9036017   0.93852887  0.93077897  0.92062962  0.923745
  0.93251361  0.92330791  0.91262147  0.89676734],0.91605245772
weighted average recall scores = [ 0.87803008  0.9036017   0.93852887  0.93077897  0.92062962  0.923745
  0.93251361  0.92330791  0.91262147  0.89676734],0.91605245772
weighted f1 scores = [ 0.87386597  0.90130011  0.93722428  0.93006718  0.92020842  0.92218773
  0.93084893  0.92233016  0.91149362  0.89404383],0.91435702216
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.915579605454 recall  0.911274300386 f1  0.912138961916
loaded (37262) terms
extended to (47296) terms
done loading vocabulary
vectorizing done, 47296 terms vocabulary tokenized
vectorizing done, 47296 terms vocabulary tokenized
accuracy scores = [ 0.82072977  0.85963983  0.90562036  0.88488064  0.88847584  0.89473684
  0.89420521  0.88823842  0.87007455  0.84968017],0.875628163146
macro precision scores = [ 0.81930288  0.86166237  0.90718441  0.88565453  0.88808169  0.89527066
  0.89393518  0.88932033  0.86911182  0.84821516],0.875773903117
macro recall scores = [ 0.81233287  0.85589246  0.90227144  0.88373995  0.88605816  0.89172285
  0.88954607  0.88594986  0.86685851  0.84382016],0.871819233081
macro f1 scores = [ 0.81124155  0.85711021  0.90381464  0.88433385  0.88628206  0.89235223
  0.8903341   0.88689737  0.86701313  0.84418547],0.872356460489
weighted average precision scores = [ 0.82144209  0.8613663   0.90660959  0.88625045  0.88835125  0.89582411
  0.89534371  0.88946625  0.87128335  0.85406669],0.877000378416
weighted average recall scores = [ 0.82144209  0.8613663   0.90660959  0.88625045  0.88835125  0.89582411
  0.89534371  0.88946625  0.87128335  0.85406669],0.877000378416
weighted f1 scores = [ 0.81759563  0.85909714  0.90533417  0.88519158  0.88765706  0.89423485
  0.89350164  0.88821751  0.86971267  0.85013241],0.875067466061
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.875773903117 recall  0.871819233081 f1  0.872356460489
loaded (233262) terms
vectorizing done, 233262 terms vocabulary tokenized
vectorizing done, 233262 terms vocabulary tokenized
accuracy scores = [ 0.87837123  0.90360169  0.93796394  0.92891247  0.92246415  0.92503987
  0.93354599  0.92336349  0.91586794  0.89605544],0.916518622324
macro precision scores = [ 0.8798091   0.90584239  0.94002797  0.93008133  0.92216117  0.92469852
  0.93336084  0.92480648  0.91568702  0.89630292],0.917277775462
macro recall scores = [ 0.87019543  0.90039183  0.9351601   0.92676671  0.92073376  0.92229657
  0.92831881  0.92207214  0.91189564  0.89309769],0.91309286842
macro f1 scores = [ 0.87032014  0.90170037  0.93674294  0.92803321  0.92107476  0.9224949
  0.9296121   0.92292006  0.91307485  0.89308226],0.913905560547
weighted average precision scores = [ 0.88000689  0.90548038  0.93889707  0.92963865  0.92212358  0.92643565
  0.93457207  0.92459012  0.91682753  0.89907673],0.917764866323
weighted average recall scores = [ 0.88000689  0.90548038  0.93889707  0.92963865  0.92212358  0.92643565
  0.93457207  0.92459012  0.91682753  0.89907673],0.917764866323
weighted f1 scores = [ 0.87577752  0.90338758  0.93770697  0.92893321  0.92196328  0.92481584
  0.93298434  0.92348373  0.9157175   0.89608559],0.916085555468
ng20_raw_lemmas_unigrams_df1_tf1 ^ ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.917277775462 recall  0.91309286842 f1  0.913905560547
loaded (72730) terms
extended to (92594) terms
done loading vocabulary
vectorizing done, 92594 terms vocabulary tokenized
vectorizing done, 92594 terms vocabulary tokenized
accuracy scores = [ 0.85668958  0.88135593  0.92205726  0.90875332  0.90546999  0.90643275
  0.91653376  0.90792975  0.89882854  0.86940299],0.897345387194
macro precision scores = [ 0.8567809   0.88345413  0.92414706  0.90988996  0.9052018   0.9052888
  0.9159117   0.91002058  0.89753949  0.86803866],0.897627307743
macro recall scores = [ 0.84799058  0.8779892   0.91900724  0.90643325  0.90347996  0.9031986
  0.91163774  0.90599061  0.89494122  0.86556833],0.893623672485
macro f1 scores = [ 0.84728178  0.87941452  0.92067013  0.90779107  0.90393816  0.90322788
  0.91269143  0.90713404  0.89555592  0.86537714],0.894308206823
weighted average precision scores = [ 0.85823957  0.88332719  0.9229954   0.90990678  0.90521488  0.90698834
  0.91726543  0.90950108  0.8994605   0.87195774],0.898485690373
weighted average recall scores = [ 0.85823957  0.88332719  0.9229954   0.90990678  0.90521488  0.90698834
  0.91726543  0.90950108  0.8994605   0.87195774],0.898485690373
weighted f1 scores = [ 0.85361126  0.88125961  0.92176517  0.90899939  0.90497808  0.90577912
  0.91593083  0.90793878  0.89848728  0.86935691],0.896810643392
ng20_raw_lemmas_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.897627307743 recall  0.893623672485 f1  0.894308206823
loaded (143566) terms
vectorizing done, 143566 terms vocabulary tokenized
vectorizing done, 143566 terms vocabulary tokenized
accuracy scores = [ 0.86515071  0.89936441  0.93054083  0.92201592  0.92299522  0.91919192
  0.92822967  0.91484832  0.90841321  0.8869936 ],0.909774380014
macro precision scores = [ 0.86528069  0.90142389  0.93292925  0.92176657  0.92370546  0.91915768
  0.92878249  0.91601852  0.90634085  0.88525164],0.910065702175
macro recall scores = [ 0.85791447  0.89583289  0.92814604  0.92010283  0.92123945  0.9168354
  0.92300838  0.91291166  0.9039236   0.88259179],0.906250649504
macro f1 scores = [ 0.85833292  0.89691525  0.92979217  0.9207135   0.92196323  0.91716208
  0.92453482  0.91381247  0.90458895  0.88279616],0.907061154287
weighted average precision scores = [ 0.86624927  0.90162938  0.93161838  0.92272883  0.92315958  0.92022446
  0.9291761   0.91632584  0.90880743  0.88919797],0.91091172535
weighted average recall scores = [ 0.86624927  0.90162938  0.93161838  0.92272883  0.92315958  0.92022446
  0.9291761   0.91632584  0.90880743  0.88919797],0.91091172535
weighted f1 scores = [ 0.86321785  0.89908583  0.93043728  0.92215122  0.92266847  0.91895516
  0.92757093  0.91494698  0.90813793  0.88699539],0.909416702995
ng20_raw_stems_unigrams_df1_tf1  -->  precision  0.910065702175 recall  0.906250649504 f1  0.907061154287
loaded (1434241) terms
vectorizing done, 1434241 terms vocabulary tokenized
vectorizing done, 1434241 terms vocabulary tokenized
accuracy scores = [ 0.87890005  0.91472458  0.93902439  0.93899204  0.93096123  0.93035619
  0.94098884  0.92389569  0.92492013  0.89658849],0.921935162629
macro precision scores = [ 0.87838957  0.91802853  0.94054674  0.94013234  0.93142393  0.93148627
  0.94229789  0.92635791  0.92553958  0.89758266],0.923178542034
macro recall scores = [ 0.86949353  0.91134814  0.93533149  0.93676352  0.92831299  0.92701922
  0.93592524  0.92208256  0.92192263  0.89394146],0.918214076885
macro f1 scores = [ 0.86871153  0.91310377  0.93692876  0.93803696  0.9293064   0.92790722
  0.93772565  0.92343579  0.92304397  0.89410164],0.919230169387
weighted average precision scores = [ 0.87921892  0.91757532  0.94000821  0.93986283  0.93142212  0.93239671
  0.9423309   0.92556107  0.92579717  0.90009835],0.923427161046
weighted average recall scores = [ 0.87921892  0.91757532  0.94000821  0.93986283  0.93142212  0.93239671
  0.9423309   0.92556107  0.92579717  0.90009835],0.923427161046
weighted f1 scores = [ 0.87525754  0.91489656  0.93864608  0.93906109  0.93075041  0.93015043
  0.94046827  0.92401878  0.92475638  0.89682084],0.921482637218
ng20_raw_stems_bigrams_df1_tf1  -->  precision  0.923178542034 recall  0.918214076885 f1  0.919230169387
loaded (201544) terms
vectorizing done, 201544 terms vocabulary tokenized
vectorizing done, 201544 terms vocabulary tokenized
accuracy scores = [ 0.87361185  0.90254237  0.93319194  0.92519894  0.92618163  0.93195109
  0.93141946  0.91750931  0.91160809  0.8880597 ],0.914127437939
macro precision scores = [ 0.87475478  0.90465522  0.9351887   0.92586075  0.92627494  0.93242059
  0.93165552  0.91870688  0.91006091  0.88774379],0.914732207079
macro recall scores = [ 0.86491017  0.89927231  0.93043968  0.92270919  0.92388146  0.93013472
  0.92655597  0.91535784  0.90694949  0.88497594],0.910518676751
macro f1 scores = [ 0.86438939  0.90058098  0.93195386  0.92383584  0.92459781  0.93047236
  0.92798102  0.91642632  0.90777687  0.88498887],0.91130033252
weighted average precision scores = [ 0.87495473  0.90470889  0.93421607  0.92568606  0.92612232  0.93347632
  0.93231035  0.91884944  0.91213228  0.89092249],0.915337895064
weighted average recall scores = [ 0.87495473  0.90470889  0.93421607  0.92568606  0.92612232  0.93347632
  0.93231035  0.91884944  0.91213228  0.89092249],0.915337895064
weighted f1 scores = [ 0.87040669  0.90247941  0.93295347  0.92507173  0.92577184  0.93194204
  0.93091086  0.91761395  0.91125058  0.88820416],0.91366047295
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams  -->  precision  0.914732207079 recall  0.910518676751 f1  0.91130033252
loaded (57978) terms
extended to (74840) terms
done loading vocabulary
vectorizing done, 74840 terms vocabulary tokenized
vectorizing done, 74840 terms vocabulary tokenized
accuracy scores = [ 0.84769963  0.88559322  0.92152704  0.90557029  0.9070632   0.90802764
  0.92131845  0.90526876  0.89243876  0.86833689],0.896284388444
macro precision scores = [ 0.84914355  0.88776921  0.92360759  0.90538531  0.90592832  0.90778357
  0.92126122  0.90716128  0.88976109  0.86773659],0.896553772242
macro recall scores = [ 0.83997308  0.88197401  0.91864758  0.90292106  0.90499196  0.90552591
  0.91569916  0.90306843  0.88696947  0.86408318],0.89238538251
macro f1 scores = [ 0.83928976  0.88344088  0.92026224  0.90376199  0.90517783  0.90566919
  0.91702931  0.90413916  0.88746975  0.86447882],0.893071892484
weighted average precision scores = [ 0.84982248  0.88758189  0.92282685  0.90651293  0.90648467  0.90899085
  0.92251617  0.90686257  0.89265879  0.8712627 ],0.897551989728
weighted average recall scores = [ 0.84982248  0.88758189  0.92282685  0.90651293  0.90648467  0.90899085
  0.92251617  0.90686257  0.89265879  0.8712627 ],0.897551989728
weighted f1 scores = [ 0.84474836  0.88541973  0.92140503  0.9056545   0.9065327   0.90756928
  0.92068533  0.90517226  0.89173631  0.86845448],0.895737798047
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.896553772242 recall  0.89238538251 f1  0.893071892484
loaded (154593) terms
vectorizing done, 154593 terms vocabulary tokenized
vectorizing done, 154593 terms vocabulary tokenized
accuracy scores = [ 0.86620836  0.89830508  0.93107105  0.92466844  0.92246415  0.92238171
  0.92929293  0.91697712  0.90841321  0.88859275],0.910837479062
macro precision scores = [ 0.86676315  0.90009878  0.93327688  0.92454601  0.92322083  0.92209021
  0.93040265  0.91799645  0.90697705  0.88781729],0.911318931404
macro recall scores = [ 0.85878891  0.89463848  0.9290104   0.92249464  0.92003657  0.92046888
  0.92419488  0.91503711  0.90389925  0.88517653],0.907374564491
macro f1 scores = [ 0.85930691  0.89588401  0.93041763  0.9231342   0.92101055  0.92069063
  0.92589892  0.91584222  0.90476988  0.88539489],0.908234984816
weighted average precision scores = [ 0.86744989  0.90028834  0.93213783  0.92536846  0.92249062  0.9232215
  0.93059556  0.91860143  0.90908553  0.89118717],0.912042631918
weighted average recall scores = [ 0.86744989  0.90028834  0.93213783  0.92536846  0.92249062  0.9232215
  0.93059556  0.91860143  0.90908553  0.89118717],0.912042631918
weighted f1 scores = [ 0.86423613  0.89809163  0.93094866  0.92464434  0.92200881  0.92226593
  0.92876161  0.91712529  0.90818519  0.88883316],0.910510074667
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.911318931404 recall  0.907374564491 f1  0.908234984816
loaded (11027) terms
extended to (16256) terms
done loading vocabulary
vectorizing done, 16256 terms vocabulary tokenized
vectorizing done, 16256 terms vocabulary tokenized
accuracy scores = [ 0.78001058  0.82097458  0.85790032  0.84456233  0.85236325  0.85805423
  0.86230728  0.86109633  0.82587859  0.79850746],0.836165494977
macro precision scores = [ 0.77526857  0.82408271  0.85900496  0.84490713  0.84979856  0.85972026
  0.86045992  0.86160793  0.82557887  0.79736608],0.835779499722
macro recall scores = [ 0.77212572  0.81531962  0.85241043  0.84106594  0.84996736  0.85344396
  0.85611084  0.85970254  0.82051333  0.79284809],0.831350782809
macro f1 scores = [ 0.77051364  0.81695362  0.85374259  0.84226227  0.84920429  0.85427319
  0.85680951  0.85986596  0.82169873  0.79340028],0.831872409729
weighted average precision scores = [ 0.77941697  0.82434966  0.85928941  0.84671105  0.85106488  0.85858276
  0.86295641  0.86148393  0.82686117  0.8027822 ],0.837349842883
weighted average recall scores = [ 0.77941697  0.82434966  0.85928941  0.84671105  0.85106488  0.85858276
  0.86295641  0.86148393  0.82686117  0.8027822 ],0.837349842883
weighted f1 scores = [ 0.77709805  0.82054426  0.85691943  0.84491267  0.85107923  0.85655613
  0.86128685  0.86053092  0.82524595  0.79897885],0.835315234594
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.835779499722 recall  0.831350782809 f1  0.831872409729
loaded (178372) terms
vectorizing done, 178372 terms vocabulary tokenized
vectorizing done, 178372 terms vocabulary tokenized
accuracy scores = [ 0.86673718  0.89830508  0.93107105  0.92466844  0.92511949  0.92185008
  0.93088783  0.91538052  0.90841321  0.88859275],0.911102561887
macro precision scores = [ 0.86558388  0.90036998  0.93300068  0.92478674  0.92547652  0.92131166
  0.93175438  0.91633469  0.90752075  0.88693422],0.911307349507
macro recall scores = [ 0.85886456  0.89468663  0.9283776   0.92274136  0.92314474  0.91923784
  0.92557583  0.91331408  0.9039531   0.88405538],0.907395112902
macro f1 scores = [ 0.85839732  0.89590386  0.9298889   0.92346548  0.92392026  0.91956074
  0.92724879  0.91421829  0.90508365  0.88421585],0.90819031472
weighted average precision scores = [ 0.86718768  0.90054012  0.93203408  0.92524301  0.92514771  0.92299725
  0.9321204   0.9168257   0.90930471  0.89091983],0.912232049156
weighted average recall scores = [ 0.86718768  0.90054012  0.93203408  0.92524301  0.92514771  0.92299725
  0.9321204   0.9168257   0.90930471  0.89091983],0.912232049156
weighted f1 scores = [ 0.86412649  0.89808703  0.93085417  0.92467363  0.92482245  0.92175489
  0.93031479  0.91551827  0.90830884  0.88852746],0.910698803362
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams  -->  precision  0.911307349507 recall  0.907395112902 f1  0.90819031472
loaded (34806) terms
extended to (42343) terms
done loading vocabulary
vectorizing done, 42343 terms vocabulary tokenized
vectorizing done, 42343 terms vocabulary tokenized
accuracy scores = [ 0.81438392  0.84904661  0.90402969  0.88116711  0.88050982  0.88304094
  0.89207868  0.88451304  0.86634718  0.8336887 ],0.868880569328
macro precision scores = [ 0.80904072  0.84803821  0.90535557  0.88086006  0.87851257  0.88374288
  0.89164603  0.88514318  0.86645961  0.83389365],0.868269248241
macro recall scores = [ 0.80590077  0.84360643  0.90046992  0.87907838  0.87785587  0.88061947
  0.88563893  0.88164971  0.86235921  0.82945825],0.864663694542
macro f1 scores = [ 0.8044322   0.84436246  0.90209334  0.87966942  0.87747964  0.88085972
  0.88683506  0.88247342  0.86357748  0.82988929],0.865167203266
weighted average precision scores = [ 0.81429668  0.85008866  0.90517564  0.88176896  0.87958024  0.88415425
  0.89340954  0.88579073  0.86803783  0.83870874],0.870101126431
weighted average recall scores = [ 0.81429668  0.85008866  0.90517564  0.88176896  0.87958024  0.88415425
  0.89340954  0.88579073  0.86803783  0.83870874],0.870101126431
weighted f1 scores = [ 0.81188209  0.84834111  0.90393583  0.88117719  0.87937277  0.88237371
  0.89118094  0.88427142  0.86640195  0.83447696],0.868341397851
ng20_raw_stems_bigrams_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.868269248241 recall  0.864663694542 f1  0.865167203266
loaded (204179) terms
vectorizing done, 204179 terms vocabulary tokenized
vectorizing done, 204179 terms vocabulary tokenized
accuracy scores = [ 0.87361185  0.90201271  0.93531283  0.92732095  0.92565056  0.92982456
  0.93195109  0.91750931  0.91107561  0.89072495],0.914499442513
macro precision scores = [ 0.87491518  0.90439466  0.93745556  0.92769201  0.92543427  0.9299409
  0.93211396  0.91898809  0.90952624  0.89001451],0.915047538097
macro recall scores = [ 0.86505774  0.8987777   0.93251533  0.92469025  0.92326642  0.92785326
  0.92734458  0.91537867  0.90631924  0.88727357],0.910847674905
macro f1 scores = [ 0.86477832  0.90024936  0.93408648  0.92577247  0.92395622  0.92809978
  0.9287704   0.91650928  0.90723489  0.88735936],0.911681655637
weighted average precision scores = [ 0.8750598   0.90413503  0.93620699  0.9277817   0.92553723  0.93142757
  0.93263378  0.91914354  0.91160735  0.89343912],0.915697211131
weighted average recall scores = [ 0.8750598   0.90413503  0.93620699  0.9277817   0.92553723  0.93142757
  0.93263378  0.91914354  0.91160735  0.89343912],0.915697211131
weighted f1 scores = [ 0.87058912  0.90197946  0.93499665  0.9271923   0.92527959  0.92984962
  0.9314808   0.91769088  0.91076164  0.89086018],0.914068023432
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.915047538097 recall  0.910847674905 f1  0.911681655637
loaded (60613) terms
extended to (77715) terms
done loading vocabulary
vectorizing done, 77715 terms vocabulary tokenized
vectorizing done, 77715 terms vocabulary tokenized
accuracy scores = [ 0.84822845  0.88559322  0.92311771  0.90875332  0.90971853  0.90909091
  0.91972355  0.90633316  0.8887114   0.86727079],0.896654103058
macro precision scores = [ 0.84942569  0.88780272  0.92427513  0.90866873  0.90873131  0.90948932
  0.91921864  0.90776506  0.886424    0.86671355],0.896851414627
macro recall scores = [ 0.84035323  0.8816751   0.92000461  0.90607151  0.90747265  0.90629479
  0.91374595  0.90406702  0.88347323  0.86311411],0.892627219884
macro f1 scores = [ 0.83963727  0.88315875  0.92143886  0.90701795  0.90783386  0.90675009
  0.91495188  0.90512656  0.88412119  0.86354042],0.893357683062
weighted average precision scores = [ 0.85019104  0.88770032  0.92390266  0.90941402  0.90927563  0.91035082
  0.92067218  0.90776759  0.8892002   0.87019682],0.897867126276
weighted average recall scores = [ 0.85019104  0.88770032  0.92390266  0.90941402  0.90927563  0.91035082
  0.92067218  0.90776759  0.8892002   0.87019682],0.897867126276
weighted f1 scores = [ 0.84520901  0.88535794  0.92290102  0.90875265  0.90927132  0.90865626
  0.91890639  0.90632642  0.88819352  0.86744344],0.896101796216
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.896851414627 recall  0.892627219884 f1  0.893357683062
loaded (220033) terms
vectorizing done, 220033 terms vocabulary tokenized
vectorizing done, 220033 terms vocabulary tokenized
accuracy scores = [ 0.87519831  0.90307203  0.93478261  0.92625995  0.92618163  0.93301435
  0.93301435  0.91750931  0.91001065  0.88859275],0.914763594414
macro precision scores = [ 0.87620178  0.90530615  0.93668019  0.92706155  0.92623745  0.93331064
  0.93397406  0.91869785  0.90852763  0.88817643],0.915417372173
macro recall scores = [ 0.86668264  0.89986574  0.93197029  0.92344594  0.92387105  0.93128902
  0.92808143  0.91536847  0.90529883  0.88518463],0.911105803592
macro f1 scores = [ 0.8663206   0.90115063  0.93347783  0.92469977  0.92459032  0.93159499
  0.92971923  0.91644001  0.90616293  0.88535386],0.91195101649
weighted average precision scores = [ 0.87634271  0.90537216  0.93578963  0.92692159  0.92608046  0.93435599
  0.93411348  0.91883831  0.91053083  0.89147058],0.91598157311
weighted average recall scores = [ 0.87634271  0.90537216  0.93578963  0.92692159  0.92608046  0.93435599
  0.93411348  0.91883831  0.91053083  0.89147058],0.91598157311
weighted f1 scores = [ 0.87211374  0.90302896  0.93454953  0.92613276  0.92576795  0.93301607
  0.93247251  0.91762197  0.909625    0.88877532],0.91431038158
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.915417372173 recall  0.911105803592 f1  0.91195101649
loaded (76467) terms
extended to (93926) terms
done loading vocabulary
vectorizing done, 93926 terms vocabulary tokenized
vectorizing done, 93926 terms vocabulary tokenized
accuracy scores = [ 0.84928609  0.8845339   0.92629905  0.90822281  0.90918747  0.91068581
  0.92238171  0.90686535  0.89563365  0.86886994],0.898196577444
macro precision scores = [ 0.85137631  0.88718123  0.9286701   0.90779228  0.90793359  0.91082367
  0.92231794  0.90852925  0.89376889  0.86801509],0.898640834575
macro recall scores = [ 0.84159313  0.88085637  0.92346933  0.90539674  0.90701258  0.90807672
  0.91698733  0.90483127  0.89105001  0.86459875],0.894387225594
macro f1 scores = [ 0.84078633  0.882571    0.92521676  0.90623555  0.90716119  0.90846446
  0.91835343  0.90583198  0.89159672  0.86497329],0.895119071346
weighted average precision scores = [ 0.85145447  0.88688402  0.92741022  0.90900669  0.90845134  0.91184976
  0.92325339  0.90838154  0.89624468  0.871865  ],0.899480111157
weighted average recall scores = [ 0.85145447  0.88688402  0.92741022  0.90900669  0.90845134  0.91184976
  0.92325339  0.90838154  0.89624468  0.871865  ],0.899480111157
weighted f1 scores = [ 0.84607103  0.8845441   0.92614215  0.90826137  0.90854698  0.91034562
  0.92173003  0.90686947  0.89517997  0.86909945],0.897679018312
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.898640834575 recall  0.894387225594 f1  0.895119071346
loaded (184965) terms
vectorizing done, 184965 terms vocabulary tokenized
vectorizing done, 184965 terms vocabulary tokenized
accuracy scores = [ 0.8699101   0.89883475  0.93107105  0.92732095  0.92352629  0.92291334
  0.93248272  0.91431613  0.90947817  0.891258  ],0.912111149435
macro precision scores = [ 0.87034657  0.90051215  0.93337395  0.92748463  0.92380245  0.92302061
  0.93340916  0.915341    0.9084442   0.89050905],0.912624378255
macro recall scores = [ 0.86205285  0.89529992  0.92872113  0.92534805  0.92121532  0.92092931
  0.92752924  0.9124701   0.90548893  0.8875894 ],0.908664424462
macro f1 scores = [ 0.8619508   0.89645895  0.93026384  0.92611386  0.92206191  0.92130471
  0.92916413  0.91326941  0.90637895  0.88790003],0.909486659128
weighted average precision scores = [ 0.87099596  0.90073462  0.9320762   0.9280229   0.92343991  0.92376141
  0.93371737  0.91595789  0.91009043  0.8939193 ],0.913271599074
weighted average recall scores = [ 0.87099596  0.90073462  0.9320762   0.9280229   0.92343991  0.92376141
  0.93371737  0.91595789  0.91009043  0.8939193 ],0.913271599074
weighted f1 scores = [ 0.86734781  0.8986018   0.9308963   0.92738623  0.92313586  0.92273364
  0.93198637  0.91451599  0.90928966  0.89149641],0.911739006996
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.912624378255 recall  0.908664424462 f1  0.909486659128
loaded (41399) terms
extended to (50316) terms
done loading vocabulary
vectorizing done, 50316 terms vocabulary tokenized
vectorizing done, 50316 terms vocabulary tokenized
accuracy scores = [ 0.82125859  0.85858051  0.90774125  0.88806366  0.8890069   0.88888889
  0.89845827  0.88717403  0.87060703  0.84328358],0.875306271284
macro precision scores = [ 0.81889708  0.85872536  0.90971537  0.88813874  0.88803663  0.88880809
  0.89865191  0.88905912  0.86967434  0.84259182],0.875229847074
macro recall scores = [ 0.81355613  0.85366916  0.9043606   0.88647614  0.8870435   0.88633753
  0.89337935  0.88517232  0.86681111  0.83866016],0.871546599441
macro f1 scores = [ 0.81269323  0.85464604  0.90607457  0.88703806  0.88680701  0.88665605
  0.89462806  0.88627839  0.8673533   0.83848293],0.872065763483
weighted average precision scores = [ 0.82268723  0.85991019  0.90876617  0.88910905  0.88842662  0.88963028
  0.89954576  0.88872323  0.87157583  0.84795087],0.876632523346
weighted average recall scores = [ 0.82268723  0.85991019  0.90876617  0.88910905  0.88842662  0.88963028
  0.89954576  0.88872323  0.87157583  0.84795087],0.876632523346
weighted f1 scores = [ 0.81901029  0.85796386  0.90746927  0.88830847  0.88799819  0.88839317
  0.89778235  0.88716408  0.87023818  0.84356156],0.874788942605
ng20_raw_stems_bigrams_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.875229847074 recall  0.871546599441 f1  0.872065763483
loaded (222491) terms
vectorizing done, 222491 terms vocabulary tokenized
vectorizing done, 222491 terms vocabulary tokenized
accuracy scores = [ 0.8725542   0.90095339  0.93637328  0.92838196  0.92671269  0.92982456
  0.93195109  0.91750931  0.90894569  0.89179104],0.91449972225
macro precision scores = [ 0.87374502  0.90333661  0.93819877  0.92888713  0.92646058  0.93020874
  0.93278583  0.91933058  0.90746396  0.89164064],0.915205787141
macro recall scores = [ 0.86415234  0.89746322  0.93353574  0.92544267  0.92467501  0.92795753
  0.92706113  0.91549883  0.90415836  0.88856347],0.910850830248
macro f1 scores = [ 0.86367398  0.89899617  0.93500626  0.92666858  0.92519476  0.92829427
  0.92865399  0.91674217  0.90512036  0.88865887],0.911700941077
weighted average precision scores = [ 0.87395187  0.9030583   0.93715219  0.92904899  0.92657071  0.93139763
  0.93308591  0.91917496  0.90944628  0.89481313],0.91576999594
weighted average recall scores = [ 0.87395187  0.9030583   0.93715219  0.92904899  0.92657071  0.93139763
  0.93308591  0.91917496  0.90944628  0.89481313],0.91576999594
weighted f1 scores = [ 0.86944093  0.90086963  0.93603101  0.92829385  0.92633038  0.92985851
  0.93144087  0.91772496  0.90860971  0.89192692],0.914052676359
ng20_raw_stems_unigrams_df1_tf1 ^ ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.915205787141 recall  0.910850830248 f1  0.911700941077
loaded (78925) terms
extended to (96603) terms
done loading vocabulary
vectorizing done, 96603 terms vocabulary tokenized
vectorizing done, 96603 terms vocabulary tokenized
accuracy scores = [ 0.84928609  0.8845339   0.92682927  0.90981432  0.9118428   0.91015417
  0.91972355  0.90633316  0.89563365  0.87100213],0.898515305182
macro precision scores = [ 0.85233131  0.88661504  0.92868801  0.90986504  0.91079262  0.91073677
  0.91920327  0.90779994  0.89376387  0.86998537],0.89897812498
macro recall scores = [ 0.84118468  0.88046361  0.924019    0.9069393   0.9095898   0.90760874
  0.91385289  0.90433149  0.89095548  0.86690138],0.894584635206
macro f1 scores = [ 0.84025378  0.88201187  0.92565348  0.90797025  0.90990929  0.9081557
  0.91504828  0.90530404  0.89159794  0.86711054],0.895301517059
weighted average precision scores = [ 0.85189338  0.88639252  0.92762487  0.91061836  0.91133875  0.91150955
  0.92061514  0.90781367  0.89617691  0.87367877],0.899766192276
weighted average recall scores = [ 0.85189338  0.88639252  0.92762487  0.91061836  0.91133875  0.91150955
  0.92061514  0.90781367  0.89617691  0.87367877],0.899766192276
weighted f1 scores = [ 0.84573696  0.88424225  0.92664984  0.90981061  0.9113507   0.90989677
  0.91891164  0.90638365  0.89520581  0.87109487],0.897928309607
ng20_raw_stems_bigrams_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.89897812498 recall  0.894584635206 f1  0.895301517059
loaded (167391) terms
vectorizing done, 167391 terms vocabulary tokenized
vectorizing done, 167391 terms vocabulary tokenized
accuracy scores = [ 0.87308302  0.89989407  0.93160127  0.93209549  0.92352629  0.91972355
  0.93088783  0.9207025   0.91586794  0.89658849],0.914397045276
macro precision scores = [ 0.87458515  0.90148919  0.93269181  0.93285034  0.92444622  0.92040277
  0.93052028  0.92045811  0.91580203  0.89542143],0.914866732235
macro recall scores = [ 0.86662708  0.89611848  0.92870061  0.93048727  0.92153262  0.91682844
  0.92693002  0.91858507  0.91263183  0.89277122],0.911121264851
macro f1 scores = [ 0.86756387  0.89744709  0.93000061  0.93142106  0.92221172  0.91754225
  0.92803304  0.91917775  0.91378616  0.8929046 ],0.912008814073
weighted average precision scores = [ 0.87474996  0.90172422  0.93231071  0.93284465  0.92387217  0.92115685
  0.93138084  0.92161955  0.91713151  0.89856788],0.915535833646
weighted average recall scores = [ 0.87474996  0.90172422  0.93231071  0.93284465  0.92387217  0.92115685
  0.93138084  0.92161955  0.91713151  0.89856788],0.915535833646
weighted f1 scores = [ 0.87164489  0.89970118  0.93136791  0.93223677  0.92301301  0.91945818
  0.93051651  0.92083078  0.91611627  0.89643144],0.914131692069
ng20_raw_unigrams_stopwords  -->  precision  0.914866732235 recall  0.911121264851 f1  0.912008814073
loaded (1674190) terms
vectorizing done, 1674190 terms vocabulary tokenized
vectorizing done, 1674190 terms vocabulary tokenized
accuracy scores = [ 0.88313062  0.91631356  0.9416755   0.93527851  0.92936803  0.92769803
  0.93992557  0.92496009  0.92492013  0.89872068],0.92219907258
macro precision scores = [ 0.88567962  0.91930833  0.94358803  0.93581326  0.93095927  0.92903785
  0.939523    0.92620873  0.92523525  0.89831351],0.923366684879
macro recall scores = [ 0.87651765  0.91293468  0.93880693  0.93328708  0.92801869  0.92422117
  0.93542143  0.92292742  0.92270001  0.89429769],0.918913275638
macro f1 scores = [ 0.87740319  0.91447845  0.94035369  0.93426223  0.92882225  0.92528969
  0.93666091  0.92394316  0.92356652  0.89484725],0.919962733514
weighted average precision scores = [ 0.88537495  0.9184492   0.94272333  0.93599817  0.929893    0.9294962
  0.94071911  0.92634486  0.92595189  0.90127748],0.923622816744
weighted average recall scores = [ 0.88537495  0.9184492   0.94272333  0.93599817  0.929893    0.9294962
  0.94071911  0.92634486  0.92595189  0.90127748],0.923622816744
weighted f1 scores = [ 0.88149787  0.91612303  0.94149013  0.93536461  0.92903296  0.92743174
  0.93958747  0.92506963  0.92505673  0.89860954],0.921926371766
ng20_raw_bigrams_stopwords  -->  precision  0.923366684879 recall  0.918913275638 f1  0.919962733514
loaded (160181) terms
vectorizing done, 160181 terms vocabulary tokenized
vectorizing done, 160181 terms vocabulary tokenized
accuracy scores = [ 0.86938128  0.90254237  0.93531283  0.92519894  0.92087095  0.92025518
  0.93088783  0.91750931  0.91746539  0.89445629],0.913388037481
macro precision scores = [ 0.87041168  0.90510083  0.93748923  0.92601894  0.92138433  0.920118
  0.93158667  0.91761588  0.91695591  0.89208084],0.913876231299
macro recall scores = [ 0.86195839  0.89873988  0.93266885  0.92336056  0.9188893   0.91761924
  0.92638723  0.91515882  0.91403347  0.89009285],0.909890857666
macro f1 scores = [ 0.86280626  0.90021559  0.93424999  0.92435074  0.91950913  0.91788898
  0.92787816  0.91587667  0.91493991  0.88999838],0.910771382413
weighted average precision scores = [ 0.87066182  0.90495768  0.93615428  0.92607444  0.92106279  0.92196125
  0.93181409  0.91853349  0.91810963  0.89627988],0.914560933723
weighted average recall scores = [ 0.87066182  0.90495768  0.93615428  0.92607444  0.92106279  0.92196125
  0.93181409  0.91853349  0.91810963  0.89627988],0.914560933723
weighted f1 scores = [ 0.86755345  0.90236363  0.93505176  0.92532026  0.9204048   0.92023247
  0.93038167  0.91754585  0.91730617  0.89431604],0.913047610545
ng20_raw_lemmas_unigrams_stopwords_df1_tf1  -->  precision  0.913876231299 recall  0.909890857666 f1  0.910771382413
loaded (1608107) terms
vectorizing done, 1608107 terms vocabulary tokenized
vectorizing done, 1608107 terms vocabulary tokenized
accuracy scores = [ 0.8852459   0.9157839   0.93955461  0.93209549  0.93096123  0.93035619
  0.9404572   0.92283129  0.91959531  0.89712154],0.921400267539
macro precision scores = [ 0.88733231  0.91993115  0.94106637  0.93343795  0.93195891  0.93054914
  0.94059528  0.92451369  0.91967689  0.89674026],0.922580196396
macro recall scores = [ 0.87804965  0.91219433  0.93651338  0.93030428  0.92939612  0.92715968
  0.93612932  0.92110306  0.91692541  0.89314163],0.918091685875
macro f1 scores = [ 0.87883646  0.91412574  0.93795602  0.93148755  0.93022202  0.92782667
  0.93736607  0.92208479  0.91781449  0.89339566],0.919111547672
weighted average precision scores = [ 0.88694722  0.9187666   0.94042038  0.9330656   0.93128272  0.93179783
  0.94159531  0.92447828  0.92071902  0.89996413],0.922903710833
weighted average recall scores = [ 0.88694722  0.9187666   0.94042038  0.9330656   0.93128272  0.93179783
  0.94159531  0.92447828  0.92071902  0.89996413],0.922903710833
weighted f1 scores = [ 0.8832972   0.91578454  0.93926402  0.9322185   0.93074407  0.93019448
  0.94010733  0.92295272  0.91968905  0.89708172],0.921133363126
ng20_raw_lemmas_bigrams_stopwords_df1_tf1  -->  precision  0.922580196396 recall  0.918091685875 f1  0.919111547672
loaded (210034) terms
done loading vocabulary
vectorizing done, 210034 terms vocabulary tokenized
vectorizing done, 210034 terms vocabulary tokenized
accuracy scores = [ 0.87361185  0.90413136  0.93796394  0.92997347  0.92511949  0.92450824
  0.93407762  0.91963811  0.91586794  0.89339019],0.915828221183
macro precision scores = [ 0.87573979  0.90681372  0.93917635  0.93133277  0.92572168  0.9239109
  0.93583565  0.92022597  0.91526053  0.89214305],0.916616039382
macro recall scores = [ 0.8660069   0.89979802  0.93487043  0.92804953  0.92321556  0.92163617
  0.92977203  0.91763286  0.91213152  0.88938   ],0.91224930173
macro f1 scores = [ 0.8667168   0.90149353  0.93630188  0.92929997  0.92388916  0.9219162
  0.93148441  0.9184426   0.91313709  0.88952931],0.913221095405
weighted average precision scores = [ 0.87563006  0.90685333  0.93864711  0.93089344  0.92541092  0.92579562
  0.93584818  0.92066188  0.91678365  0.89555055],0.917207472554
weighted average recall scores = [ 0.87563006  0.90685333  0.93864711  0.93089344  0.92541092  0.92579562
  0.93584818  0.92066188  0.91678365  0.89555055],0.917207472554
weighted f1 scores = [ 0.87155564  0.90405507  0.93768681  0.93007714  0.92473327  0.92439741
  0.93377091  0.91969804  0.91583092  0.89328657],0.915509177749
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.916616039382 recall  0.91224930173 f1  0.913221095405
loaded (49853) terms
extended to (67310) terms
done loading vocabulary
vectorizing done, 67310 terms vocabulary tokenized
vectorizing done, 67310 terms vocabulary tokenized
accuracy scores = [ 0.85087255  0.88135593  0.91622481  0.90769231  0.90122146  0.90111643
  0.91600213  0.90846195  0.89456869  0.86727079],0.894478704446
macro precision scores = [ 0.85260524  0.88302818  0.91754376  0.90846256  0.90073348  0.89999079
  0.91697664  0.91142393  0.89509537  0.86696719],0.895282712538
macro recall scores = [ 0.8449448   0.87703921  0.91328724  0.90575194  0.89957214  0.89836863
  0.91146122  0.90686805  0.89089954  0.86349435],0.891168711281
macro f1 scores = [ 0.84600218  0.87849009  0.91479345  0.90671915  0.89973867  0.89842398
  0.91305473  0.90803474  0.89229939  0.86344499],0.892100137604
weighted average precision scores = [ 0.85291049  0.88325791  0.91715496  0.90882002  0.90126083  0.90169317
  0.91720153  0.91042304  0.89637798  0.87128338],0.896038330104
weighted average recall scores = [ 0.85291049  0.88325791  0.91715496  0.90882002  0.90126083  0.90169317
  0.91720153  0.91042304  0.89637798  0.87128338],0.896038330104
weighted f1 scores = [ 0.84959236  0.88106711  0.91616109  0.90787706  0.90082836  0.90073621
  0.91559572  0.90839135  0.89481819  0.86754013],0.894260757353
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.895282712538 recall  0.891168711281 f1  0.892100137604
loaded (168259) terms
done loading vocabulary
vectorizing done, 168259 terms vocabulary tokenized
vectorizing done, 168259 terms vocabulary tokenized
accuracy scores = [ 0.8699101   0.90254237  0.93531283  0.92891247  0.92140202  0.92185008
  0.92822967  0.91910591  0.91640043  0.89339019],0.913705605974
macro precision scores = [ 0.87076808  0.90525499  0.93705307  0.93054494  0.9220978   0.92116022
  0.92918627  0.91922628  0.91566513  0.89174201],0.9142698781
macro recall scores = [ 0.86258921  0.89844602  0.93255405  0.92703886  0.91934973  0.9189755
  0.92395146  0.91710687  0.91289827  0.8894119 ],0.910232187737
macro f1 scores = [ 0.86331046  0.90000277  0.93404837  0.92836651  0.92000876  0.91920384
  0.92551569  0.91773215  0.91380224  0.88936383],0.911135462135
weighted average precision scores = [ 0.87127245  0.90527022  0.93609127  0.92993008  0.92175062  0.92314908
  0.92930194  0.9200486   0.91706176  0.89567401],0.914955002732
weighted average recall scores = [ 0.87127245  0.90527022  0.93609127  0.92993008  0.92175062  0.92314908
  0.92930194  0.9200486   0.91706176  0.89567401],0.914955002732
weighted f1 scores = [ 0.86813455  0.90241991  0.93506839  0.92903279  0.92092306  0.92171082
  0.92783809  0.91916887  0.91630671  0.89339387],0.913399704324
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.9142698781 recall  0.910232187737 f1  0.911135462135
loaded (8078) terms
extended to (13231) terms
done loading vocabulary
vectorizing done, 13231 terms vocabulary tokenized
vectorizing done, 13231 terms vocabulary tokenized
accuracy scores = [ 0.76573242  0.80402542  0.84146341  0.83076923  0.83908656  0.84210526
  0.84370016  0.83767962  0.80937167  0.78571429],0.819964804701
macro precision scores = [ 0.76262758  0.80599443  0.84073582  0.83252198  0.83610878  0.83992339
  0.84142749  0.83692433  0.80929469  0.78305969],0.818861816759
macro recall scores = [ 0.75698673  0.79826961  0.83604117  0.82702195  0.83595397  0.83833753
  0.83577382  0.83437161  0.80381837  0.77870412],0.814527885778
macro f1 scores = [ 0.75614313  0.79999059  0.83722577  0.82874706  0.83552257  0.83748931
  0.83672602  0.83453469  0.80445475  0.77903817],0.81498720632
weighted average precision scores = [ 0.76661744  0.80741744  0.84316964  0.83503403  0.83953161  0.84114671
  0.84450218  0.83820875  0.81139354  0.79010991],0.821713126593
weighted average recall scores = [ 0.76661744  0.80741744  0.84316964  0.83503403  0.83953161  0.84114671
  0.84450218  0.83820875  0.81139354  0.79010991],0.821713126593
weighted f1 scores = [ 0.76327393  0.80396127  0.84123111  0.83185682  0.83878561  0.84019689
  0.84247352  0.83690554  0.80846736  0.78602056],0.819317261003
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.818861816759 recall  0.814527885778 f1  0.81498720632
loaded (200143) terms
vectorizing done, 200143 terms vocabulary tokenized
vectorizing done, 200143 terms vocabulary tokenized
accuracy scores = [ 0.87414067  0.90360169  0.93584305  0.93050398  0.92087095  0.92397661
  0.93088783  0.91804151  0.91853035  0.89285714],0.914925378425
macro precision scores = [ 0.87641077  0.90545722  0.93792945  0.93121547  0.92160145  0.92347305
  0.93236349  0.91871515  0.91798255  0.89097337],0.915612196443
macro recall scores = [ 0.86650041  0.89952324  0.93318431  0.92842147  0.91882911  0.92124396
  0.92597516  0.9159471   0.91498416  0.88891759],0.91135265162
macro f1 scores = [ 0.8671792   0.90086688  0.93473245  0.92948302  0.91944751  0.92154328
  0.92782678  0.91683404  0.91592936  0.88878414],0.912262664948
weighted average precision scores = [ 0.87616906  0.90586726  0.9367285   0.93131083  0.92108155  0.92528457
  0.93215238  0.91927703  0.91950833  0.89491911],0.916229862844
weighted average recall scores = [ 0.87616906  0.90586726  0.9367285   0.93131083  0.92108155  0.92528457
  0.93215238  0.91927703  0.91950833  0.89491911],0.916229862844
weighted f1 scores = [ 0.87211136  0.90342001  0.93560124  0.9305909   0.92029254  0.92391836
  0.93038448  0.91819643  0.91851217  0.89276299],0.914579046195
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.915612196443 recall  0.91135265162 f1  0.912262664948
loaded (39962) terms
extended to (48275) terms
done loading vocabulary
vectorizing done, 48275 terms vocabulary tokenized
vectorizing done, 48275 terms vocabulary tokenized
accuracy scores = [ 0.82020095  0.85010593  0.89660657  0.8795756   0.87732342  0.87825625
  0.88729399  0.88078765  0.86048988  0.8326226 ],0.866326285211
macro precision scores = [ 0.81925658  0.85118823  0.89589584  0.87884443  0.8753455   0.8780697
  0.88794583  0.88150828  0.86284124  0.83096711],0.866186274565
macro recall scores = [ 0.81226069  0.84665123  0.89313195  0.8772025   0.87499495  0.87548796
  0.88221535  0.87816689  0.85700584  0.82708188],0.862419924442
macro f1 scores = [ 0.81215753  0.84762534  0.89396991  0.87766405  0.87445827  0.87570193
  0.88363627  0.8789833   0.85887775  0.82745778],0.863053213533
weighted average precision scores = [ 0.82107492  0.85163469  0.89705398  0.88013412  0.87706558  0.87921743
  0.88843335  0.88153768  0.86328473  0.83660238],0.867603884337
weighted average recall scores = [ 0.82107492  0.85163469  0.89705398  0.88013412  0.87706558  0.87921743
  0.88843335  0.88153768  0.86328473  0.83660238],0.867603884337
weighted f1 scores = [ 0.81780338  0.84971752  0.89632477  0.87950222  0.87646585  0.87769705
  0.88661233  0.88034437  0.86090489  0.83308138],0.865845376249
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.866186274565 recall  0.862419924442 f1  0.863053213533
loaded (211067) terms
vectorizing done, 211067 terms vocabulary tokenized
vectorizing done, 211067 terms vocabulary tokenized
accuracy scores = [ 0.87519831  0.90360169  0.93796394  0.93050398  0.92458842  0.92450824
  0.93407762  0.91963811  0.91693291  0.89285714],0.915987036322
macro precision scores = [ 0.87711245  0.90637446  0.93917635  0.93199144  0.92506832  0.9239109
  0.93583565  0.92058155  0.91630959  0.89150304],0.916786373936
macro recall scores = [ 0.86752721  0.89928782  0.93487043  0.92859898  0.92271556  0.92163617
  0.92977203  0.91774239  0.91327199  0.8888698 ],0.912429236478
macro f1 scores = [ 0.86816099  0.90100752  0.93630188  0.92989514  0.92332437  0.9219162
  0.93148441  0.91866393  0.91422281  0.88897492],0.913395216754
weighted average precision scores = [ 0.87705706  0.90639339  0.93864711  0.93144107  0.92485727  0.92579562
  0.93584818  0.92070032  0.91786719  0.89500472],0.917361192824
weighted average recall scores = [ 0.87705706  0.90639339  0.93864711  0.93144107  0.92485727  0.92579562
  0.93584818  0.92070032  0.91786719  0.89500472],0.917361192824
weighted f1 scores = [ 0.87306016  0.90354845  0.93768681  0.93060905  0.92420399  0.92439741
  0.93377091  0.91971961  0.91689756  0.8927628 ],0.915665675182
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.916786373936 recall  0.912429236478 f1  0.913395216754
loaded (50886) terms
extended to (68550) terms
done loading vocabulary
vectorizing done, 68550 terms vocabulary tokenized
vectorizing done, 68550 terms vocabulary tokenized
accuracy scores = [ 0.84822845  0.88347458  0.91622481  0.90822281  0.90122146  0.90217969
  0.91547049  0.90792975  0.89403621  0.86886994],0.894585818875
macro precision scores = [ 0.84959082  0.88510926  0.91800687  0.90900224  0.90083029  0.90131919
  0.91584085  0.91020049  0.89453398  0.86843196],0.895286594291
macro recall scores = [ 0.84194083  0.87919525  0.91388572  0.90630139  0.89948572  0.89937883
  0.91082559  0.90609019  0.88998792  0.86507495],0.891216637827
macro f1 scores = [ 0.84289355  0.88057476  0.9153166   0.90728267  0.89979381  0.89957191
  0.91227743  0.90707425  0.89141847  0.86491537],0.892111883824
weighted average precision scores = [ 0.84977277  0.88538473  0.91726392  0.90924391  0.90136355  0.90294222
  0.91645853  0.90964157  0.8958973   0.87280795],0.896077644829
weighted average recall scores = [ 0.84977277  0.88538473  0.91726392  0.90924391  0.90136355  0.90294222
  0.91645853  0.90964157  0.8958973   0.87280795],0.896077644829
weighted f1 scores = [ 0.84665944  0.88316136  0.91618546  0.90837431  0.90093188  0.90187231
  0.91504749  0.90777589  0.89418622  0.86905014],0.894324449621
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.895286594291 recall  0.891216637827 f1  0.892111883824
loaded (233813) terms
vectorizing done, 233813 terms vocabulary tokenized
vectorizing done, 233813 terms vocabulary tokenized
accuracy scores = [ 0.87414067  0.90413136  0.94008484  0.92997347  0.92140202  0.92397661
  0.93407762  0.9207025   0.91906283  0.89179104],0.915934295612
macro precision scores = [ 0.87618091  0.90648216  0.94137302  0.9313964   0.92204096  0.92344942
  0.93584955  0.92146721  0.91857317  0.89042704],0.916723984159
macro recall scores = [ 0.86639133  0.89979287  0.93696638  0.92805468  0.91954975  0.92125459
  0.92962226  0.91876806  0.91568097  0.88785465],0.912393553691
macro f1 scores = [ 0.86712779  0.90139941  0.93840664  0.9293121   0.92011787  0.92156028
  0.93133279  0.91961229  0.91662705  0.8879373 ],0.913343350327
weighted average precision scores = [ 0.87615293  0.90645578  0.94078072  0.93094397  0.92157016  0.92513091
  0.93585325  0.92197145  0.91994878  0.89388966],0.917269762127
weighted average recall scores = [ 0.87615293  0.90645578  0.94078072  0.93094397  0.92157016  0.92513091
  0.93585325  0.92197145  0.91994878  0.89388966],0.917269762127
weighted f1 scores = [ 0.87207924  0.90392638  0.93977879  0.9300794   0.92085145  0.92386601
  0.93370131  0.92086394  0.91903857  0.89168101],0.915586610365
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.916723984159 recall  0.912393553691 f1  0.913343350327
loaded (73632) terms
extended to (92101) terms
done loading vocabulary
vectorizing done, 92101 terms vocabulary tokenized
vectorizing done, 92101 terms vocabulary tokenized
accuracy scores = [ 0.84822845  0.88400424  0.91834571  0.90981432  0.90600106  0.90271132
  0.91812865  0.91112294  0.89829606  0.86993603],0.8966588789
macro precision scores = [ 0.85032472  0.88593514  0.91928173  0.90985156  0.90556309  0.90143923
  0.91809415  0.91399021  0.89964453  0.86928831],0.897341267504
macro recall scores = [ 0.84138491  0.87974667  0.91582938  0.90767302  0.90428095  0.89960505
  0.91343856  0.90945533  0.89495406  0.86593847],0.893230638645
macro f1 scores = [ 0.84213508  0.88110007  0.91702086  0.90844613  0.90456321  0.89957822
  0.91484714  0.91051878  0.89659687  0.86588787],0.894069422768
weighted average precision scores = [ 0.8508575   0.88612138  0.91891278  0.91061769  0.90592832  0.90351689
  0.91881038  0.91347815  0.90018484  0.87359722],0.898202515172
weighted average recall scores = [ 0.8508575   0.88612138  0.91891278  0.91061769  0.90592832  0.90351689
  0.91881038  0.91347815  0.90018484  0.87359722],0.898202515172
weighted f1 scores = [ 0.84653216  0.88368787  0.91815675  0.90990379  0.90560868  0.90229451
  0.91767317  0.91115665  0.89858944  0.87007272],0.896367574773
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.897341267504 recall  0.893230638645 f1  0.894069422768
loaded (203890) terms
vectorizing done, 203890 terms vocabulary tokenized
vectorizing done, 203890 terms vocabulary tokenized
accuracy scores = [ 0.87414067  0.90307203  0.93531283  0.93156499  0.92140202  0.92291334
  0.93088783  0.91857371  0.91853035  0.89232409],0.914872186066
macro precision scores = [ 0.87549358  0.90524988  0.93706582  0.93289923  0.92223144  0.92219067
  0.93270569  0.91923021  0.91793181  0.89065056],0.915564889516
macro recall scores = [ 0.86649536  0.89901809  0.93254342  0.92960118  0.91934984  0.92011391
  0.92610883  0.91659645  0.91498942  0.88839171],0.911320821071
macro f1 scores = [ 0.86706055  0.90049321  0.93401944  0.93086417  0.91997812  0.92043114
  0.92796268  0.9174295   0.91590692  0.88831607],0.912246181096
weighted average precision scores = [ 0.87575977  0.90540009  0.93618238  0.9324792   0.92170193  0.92416556
  0.9325149   0.91979531  0.91943049  0.8945861 ],0.916201572177
weighted average recall scores = [ 0.87575977  0.90540009  0.93618238  0.9324792   0.92170193  0.92416556
  0.9325149   0.91979531  0.91943049  0.8945861 ],0.916201572177
weighted f1 scores = [ 0.87212001  0.90292556  0.93507531  0.93167147  0.92082174  0.92289816
  0.93044561  0.91873878  0.9184731   0.89228486],0.914545460012
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.915564889516 recall  0.911320821071 f1  0.912246181096
loaded (43709) terms
extended to (53360) terms
done loading vocabulary
vectorizing done, 53360 terms vocabulary tokenized
vectorizing done, 53360 terms vocabulary tokenized
accuracy scores = [ 0.82178741  0.85752119  0.90243902  0.87904509  0.88263409  0.88038278
  0.89261031  0.88557743  0.8684771   0.83635394],0.870682838372
macro precision scores = [ 0.82283159  0.85861118  0.90280545  0.87831396  0.88011254  0.87950942
  0.89207897  0.88621298  0.87083362  0.83422447],0.870553417088
macro recall scores = [ 0.81481305  0.85358283  0.89932739  0.87658153  0.88052808  0.87778862
  0.88662963  0.88255937  0.8655936   0.82994279],0.866734689011
macro f1 scores = [ 0.81514357  0.85454355  0.90044835  0.8770636   0.87967128  0.87774172
  0.88784866  0.88337811  0.8672899   0.83050239],0.867363113295
weighted average precision scores = [ 0.82375332  0.85966077  0.90333745  0.87989161  0.88186056  0.8806869
  0.89360319  0.88641467  0.8713088   0.84008291],0.872060016814
weighted average recall scores = [ 0.82375332  0.85966077  0.90333745  0.87989161  0.88186056  0.8806869
  0.89360319  0.88641467  0.8713088   0.84008291],0.872060016814
weighted f1 scores = [ 0.81985577  0.85724013  0.90233014  0.87909646  0.88157866  0.87968968
  0.89179368  0.88506472  0.86899928  0.83666483],0.870231334621
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.870553417088 recall  0.866734689011 f1  0.867363113295
loaded (234652) terms
vectorizing done, 234652 terms vocabulary tokenized
vectorizing done, 234652 terms vocabulary tokenized
accuracy scores = [ 0.87466949  0.90413136  0.94008484  0.93050398  0.92087095  0.92397661
  0.93407762  0.9207025   0.91906283  0.89179104],0.915987121338
macro precision scores = [ 0.87666464  0.90648216  0.94137302  0.93205507  0.9213876   0.92344942
  0.93584955  0.92186965  0.91857317  0.89054902],0.916825330416
macro recall scores = [ 0.86689133  0.89979287  0.93696638  0.92860413  0.91904975  0.92125459
  0.92962226  0.91876806  0.91568097  0.88785465],0.912448498746
macro f1 scores = [ 0.86761284  0.90139941  0.93840664  0.92990727  0.91955307  0.92156028
  0.93133279  0.91975877  0.91662705  0.88797004],0.91341281551
weighted average precision scores = [ 0.8766504   0.90645578  0.94078072  0.9314916   0.92101652  0.92513091
  0.93585325  0.9220714   0.91994878  0.89388911],0.917328847507
weighted average recall scores = [ 0.8766504   0.90645578  0.94078072  0.9314916   0.92101652  0.92513091
  0.93585325  0.9220714   0.91994878  0.89388911],0.917328847507
weighted f1 scores = [ 0.87258522  0.90392638  0.93977879  0.93061132  0.92032216  0.92386601
  0.93370131  0.92087339  0.91903857  0.8916572 ],0.915636035442
ng20_raw_lemmas_unigrams_stopwords_df1_tf1 ^ ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.916825330416 recall  0.912448498746 f1  0.91341281551
loaded (74471) terms
extended to (93119) terms
done loading vocabulary
vectorizing done, 93119 terms vocabulary tokenized
vectorizing done, 93119 terms vocabulary tokenized
accuracy scores = [ 0.84981491  0.88506356  0.91887593  0.91140584  0.90653213  0.90324296
  0.91706539  0.91059074  0.89882854  0.86780384],0.896922383041
macro precision scores = [ 0.8518936   0.88707642  0.92012479  0.91169635  0.90598784  0.90170127
  0.9170777   0.91332605  0.90015085  0.86714329],0.897617815283
macro recall scores = [ 0.84313996  0.88080874  0.91650767  0.9093737   0.9048304   0.9002544
  0.91239689  0.90896091  0.89550877  0.86346226],0.893524369845
macro f1 scores = [ 0.84381014  0.88220668  0.91776047  0.91019446  0.90504533  0.90014283
  0.91379662  0.9100001   0.89712141  0.86347166],0.894354971491
weighted average precision scores = [ 0.85241843  0.88725611  0.91962612  0.91236419  0.90638716  0.90395863
  0.91776825  0.91280811  0.90070285  0.87160028],0.898489013871
weighted average recall scores = [ 0.85241843  0.88725611  0.91962612  0.91236419  0.90638716  0.90395863
  0.91776825  0.91280811  0.90070285  0.87160028],0.898489013871
weighted f1 scores = [ 0.84812172  0.88478961  0.91875249  0.91154734  0.90609892  0.90285177
  0.91659838  0.91061781  0.89910951  0.86789666],0.896638419727
ng20_raw_lemmas_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.897617815283 recall  0.893524369845 f1  0.894354971491
loaded (143329) terms
vectorizing done, 143329 terms vocabulary tokenized
vectorizing done, 143329 terms vocabulary tokenized
accuracy scores = [ 0.86303543  0.89989407  0.93107105  0.92360743  0.92352629  0.91972355
  0.92982456  0.91378393  0.90681576  0.88539446],0.909667652159
macro precision scores = [ 0.86520883  0.90205583  0.9325924   0.92455882  0.92450188  0.91956821
  0.93070718  0.91477578  0.90601978  0.88472681],0.91047155153
macro recall scores = [ 0.85593801  0.89613336  0.92852069  0.9212476   0.9217002   0.91762148
  0.92485805  0.91182107  0.90243191  0.88157486],0.906184722952
macro f1 scores = [ 0.85680071  0.89757249  0.92993144  0.92245953  0.92258104  0.9180013
  0.92648362  0.91282853  0.90355679  0.88183678],0.907205223554
weighted average precision scores = [ 0.86505992  0.90230562  0.93168324  0.92457152  0.92378097  0.92078409
  0.93099177  0.91490436  0.90780727  0.88790957],0.910979832293
weighted average recall scores = [ 0.86505992  0.90230562  0.93168324  0.92457152  0.92378097  0.92078409
  0.93099177  0.91490436  0.90780727  0.88790957],0.910979832293
weighted f1 scores = [ 0.86125033  0.8998365   0.93084927  0.92368487  0.92323119  0.91971171
  0.92929664  0.91389268  0.90674241  0.88535822],0.909385381571
ng20_raw_stems_unigrams_stopwords_df1_tf1  -->  precision  0.91047155153 recall  0.906184722952 f1  0.907205223554
loaded (1537054) terms
vectorizing done, 1537054 terms vocabulary tokenized
vectorizing done, 1537054 terms vocabulary tokenized
accuracy scores = [ 0.87572713  0.91260593  0.93902439  0.93793103  0.9346787   0.92982456
  0.93886231  0.9222991   0.91799787  0.89392324],0.920287426459
macro precision scores = [ 0.87700616  0.91587574  0.94013812  0.93937951  0.93589927  0.93100751
  0.9401481   0.9245239   0.91758681  0.89433688],0.921590199042
macro recall scores = [ 0.86750579  0.90882641  0.936554    0.93630499  0.93292378  0.92649697
  0.93398632  0.92055194  0.91421956  0.89083978],0.916820954606
macro f1 scores = [ 0.86760553  0.9106473   0.93773624  0.9374992   0.93389464  0.92766678
  0.93581188  0.92187154  0.91533438  0.89099486],0.91790623712
weighted average precision scores = [ 0.87706343  0.91541372  0.94003381  0.93883143  0.93526058  0.9316791
  0.94009296  0.92391352  0.91869569  0.89669944],0.921768368673
weighted average recall scores = [ 0.87706343  0.91541372  0.94003381  0.93883143  0.93526058  0.9316791
  0.94009296  0.92391352  0.91869569  0.89669944],0.921768368673
weighted f1 scores = [ 0.87295866  0.91265239  0.9389651   0.93806174  0.93455471  0.92981781
  0.93840934  0.92249456  0.91786353  0.89382504],0.919960287989
ng20_raw_stems_bigrams_stopwords_df1_tf1  -->  precision  0.921590199042 recall  0.916820954606 f1  0.91790623712
loaded (199661) terms
vectorizing done, 199661 terms vocabulary tokenized
vectorizing done, 199661 terms vocabulary tokenized
accuracy scores = [ 0.8699101   0.90201271  0.9321315   0.92785146  0.92777483  0.93035619
  0.93460925  0.91431613  0.91054313  0.891258  ],0.914076329009
macro precision scores = [ 0.87105183  0.90450184  0.93384571  0.92916091  0.92863748  0.92997163
  0.93549589  0.91559637  0.90954197  0.89047407],0.914827769344
macro recall scores = [ 0.8628415   0.89823524  0.92969735  0.92552757  0.92585549  0.92789469
  0.92945764  0.91257381  0.90631547  0.88781045],0.910620921626
macro f1 scores = [ 0.86342728  0.89973222  0.93112792  0.92680688  0.92677047  0.92828398
  0.93118403  0.9135687   0.90727985  0.88802727],0.91162085935
weighted average precision scores = [ 0.87157199  0.90463753  0.93290182  0.92900822  0.9280734   0.93154328
  0.93577236  0.91566428  0.91136008  0.89349837],0.915403132137
weighted average recall scores = [ 0.87157199  0.90463753  0.93290182  0.92900822  0.9280734   0.93154328
  0.93577236  0.91566428  0.91136008  0.89349837],0.915403132137
weighted f1 scores = [ 0.86809432  0.90198433  0.93197216  0.92794656  0.92754873  0.93035017
  0.93410431  0.91450171  0.91038451  0.89129855],0.913818534704
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams  -->  precision  0.914827769344 recall  0.910620921626 f1  0.91162085935
loaded (56332) terms
extended to (72162) terms
done loading vocabulary
vectorizing done, 72162 terms vocabulary tokenized
vectorizing done, 72162 terms vocabulary tokenized
accuracy scores = [ 0.84717081  0.8845339   0.91887593  0.91034483  0.90600106  0.90430622
  0.91866029  0.90686535  0.88658147  0.86460554],0.894794539946
macro precision scores = [ 0.84949885  0.8865461   0.92049389  0.91107108  0.90671957  0.9038331
  0.91931159  0.90878577  0.88637074  0.86460318],0.895723386638
macro recall scores = [ 0.84030729  0.88040118  0.91635757  0.9082171   0.90408249  0.90196746
  0.91372669  0.90549577  0.8822493   0.86033989],0.891314473773
macro f1 scores = [ 0.84131517  0.8818163   0.91780197  0.90923065  0.90476351  0.90241085
  0.91536649  0.90658747  0.88358123  0.86072434],0.892359798619
weighted average precision scores = [ 0.85055437  0.88684721  0.91951557  0.91144763  0.90617962  0.90444594
  0.9196217   0.90784712  0.88824152  0.86806816],0.896276883542
weighted average recall scores = [ 0.85055437  0.88684721  0.91951557  0.91144763  0.90617962  0.90444594
  0.9196217   0.90784712  0.88824152  0.86806816],0.896276883542
weighted f1 scores = [ 0.84593792  0.88433616  0.91868786  0.91049706  0.90554276  0.90391283
  0.91818901  0.90686324  0.8867387   0.86460573],0.894531127519
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_bigrams (extended unigrams) -->  precision  0.895723386638 recall  0.891314473773 f1  0.892359798619
loaded (152039) terms
vectorizing done, 152039 terms vocabulary tokenized
vectorizing done, 152039 terms vocabulary tokenized
accuracy scores = [ 0.86515071  0.90042373  0.93054083  0.92413793  0.92724376  0.92238171
  0.92929293  0.91271953  0.90947817  0.8869936 ],0.910836290535
macro precision scores = [ 0.86731379  0.90224174  0.93219022  0.92554395  0.92788612  0.92199934
  0.93056753  0.91367186  0.90860811  0.88615538],0.911617803993
macro recall scores = [ 0.85823026  0.8963398   0.92804153  0.92230944  0.92527731  0.92050319
  0.92435848  0.91092314  0.90527918  0.88330887],0.907457119787
macro f1 scores = [ 0.85898537  0.89758253  0.92943852  0.92345182  0.92608787  0.92069564
  0.92609563  0.91181938  0.90628882  0.88334009],0.908378568236
weighted average precision scores = [ 0.8673104   0.90261872  0.93134448  0.92522696  0.92739662  0.92333849
  0.93070701  0.91399062  0.91036843  0.88970204],0.912200376126
weighted average recall scores = [ 0.8673104   0.90261872  0.93134448  0.92522696  0.92739662  0.92333849
  0.93070701  0.91399062  0.91036843  0.88970204],0.912200376126
weighted f1 scores = [ 0.86342121  0.90011153  0.9303485   0.92424701  0.9269264   0.92234335
  0.92883026  0.91289418  0.90934873  0.88698929],0.910546045865
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams  -->  precision  0.911617803993 recall  0.907457119787 f1  0.908378568236
loaded (8710) terms
extended to (13472) terms
done loading vocabulary
vectorizing done, 13472 terms vocabulary tokenized
vectorizing done, 13472 terms vocabulary tokenized
accuracy scores = [ 0.7678477   0.82150424  0.84782609  0.8397878   0.83643123  0.84157363
  0.85911749  0.8430016   0.80777423  0.78837953],0.825324352621
macro precision scores = [ 0.76568328  0.82382842  0.84752792  0.84152093  0.83352956  0.84177316
  0.85544166  0.84216255  0.80820209  0.78635901],0.824602857324
macro recall scores = [ 0.76032471  0.81455154  0.84199447  0.83570533  0.8340049   0.8374618
  0.85206605  0.84043147  0.80200582  0.78250818],0.820105427307
macro f1 scores = [ 0.75995988  0.8162756   0.84302219  0.8375237   0.83285908  0.83771186
  0.85254098  0.84042172  0.80305913  0.78266089],0.820603502814
weighted average precision scores = [ 0.76866044  0.82525223  0.84942478  0.84368365  0.83555681  0.84139593
  0.85919674  0.84329675  0.81032344  0.79311807],0.826990885263
weighted average recall scores = [ 0.76866044  0.82525223  0.84942478  0.84368365  0.83555681  0.84139593
  0.85919674  0.84329675  0.81032344  0.79311807],0.826990885263
weighted f1 scores = [ 0.76592307  0.82122603  0.84702805  0.84062861  0.83508294  0.83994522
  0.85806888  0.84229197  0.80723482  0.78897136],0.824640093376
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_bigrams (extended unigrams) -->  precision  0.824602857324 recall  0.820105427307 f1  0.820603502814
loaded (190345) terms
vectorizing done, 190345 terms vocabulary tokenized
vectorizing done, 190345 terms vocabulary tokenized
accuracy scores = [ 0.86515071  0.90254237  0.93054083  0.92625995  0.92565056  0.92769803
  0.93035619  0.91218733  0.90788072  0.88752665],0.91157933553
macro precision scores = [ 0.86568855  0.90449958  0.93187315  0.92707755  0.92651801  0.92711423
  0.93161093  0.91326412  0.90736521  0.88726587],0.912227718035
macro recall scores = [ 0.85828046  0.89832682  0.92800217  0.92386076  0.92391108  0.92543743
  0.92525037  0.91029267  0.90327954  0.88408398],0.908072528146
macro f1 scores = [ 0.8584248   0.89980116  0.92935469  0.92504585  0.9246943   0.92570867
  0.92703014  0.9112059   0.90450331  0.88426479],0.909003361346
weighted average precision scores = [ 0.8663307   0.90499346  0.9311209   0.92723903  0.92581808  0.92854125
  0.93173007  0.91371864  0.90911918  0.89034373],0.912895503843
weighted average recall scores = [ 0.8663307   0.90499346  0.9311209   0.92723903  0.92581808  0.92854125
  0.93173007  0.91371864  0.90911918  0.89034373],0.912895503843
weighted f1 scores = [ 0.86305656  0.90244148  0.93034362  0.9263546   0.92531344  0.92760644
  0.92984903  0.91239883  0.90782273  0.88754903],0.911273576114
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams  -->  precision  0.912227718035 recall  0.908072528146 f1  0.909003361346
loaded (47016) terms
extended to (54812) terms
done loading vocabulary
vectorizing done, 54812 terms vocabulary tokenized
vectorizing done, 54812 terms vocabulary tokenized
accuracy scores = [ 0.81649921  0.85699153  0.90402969  0.88488064  0.87679235  0.88304094
  0.89261031  0.88557743  0.86261981  0.8336887 ],0.869673060571
macro precision scores = [ 0.81814047  0.85714393  0.90548961  0.88518183  0.87394986  0.88287461
  0.89301543  0.8862665   0.86233672  0.83396058],0.869835954928
macro recall scores = [ 0.80984749  0.85169263  0.90022697  0.88315309  0.87435138  0.88011063
  0.88680189  0.88316313  0.85912434  0.82848469],0.865695623274
macro f1 scores = [ 0.81061936  0.85305513  0.90189143  0.88377455  0.87295533  0.8802296
  0.88843571  0.88387479  0.86009914  0.82899728],0.866393232191
weighted average precision scores = [ 0.81949643  0.85901989  0.90518383  0.88632471  0.87564237  0.88407805
  0.89403937  0.88665418  0.86369917  0.83893879],0.871307678695
weighted average recall scores = [ 0.81949643  0.85901989  0.90518383  0.88632471  0.87564237  0.88407805
  0.89403937  0.88665418  0.86369917  0.83893879],0.871307678695
weighted f1 scores = [ 0.81529926  0.85682282  0.90379779  0.88521034  0.87507285  0.88239202
  0.89207803  0.8853093   0.86256861  0.83411735],0.869266837754
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ google_bigrams (extended unigrams) -->  precision  0.869835954928 recall  0.865695623274 f1  0.866393232191
loaded (200752) terms
vectorizing done, 200752 terms vocabulary tokenized
vectorizing done, 200752 terms vocabulary tokenized
accuracy scores = [ 0.86938128  0.90360169  0.93319194  0.92997347  0.92830589  0.92982456
  0.93460925  0.91431613  0.91001065  0.89179104],0.914500591673
macro precision scores = [ 0.8704874   0.90593372  0.93484921  0.93126483  0.92918185  0.92937144
  0.93549589  0.91559637  0.90910647  0.89108543],0.915237259781
macro recall scores = [ 0.86233645  0.8998051   0.93072302  0.92755828  0.92636054  0.92737923
  0.92945764  0.91257381  0.90580527  0.88832065],0.911031999756
macro f1 scores = [ 0.86291633  0.90119102  0.93213857  0.92882943  0.92726345  0.92775516
  0.93118403  0.9135687   0.90681043  0.88854853],0.912020564469
weighted average precision scores = [ 0.87098983  0.90615482  0.93392551  0.93117979  0.92863173  0.93091319
  0.93577236  0.91566428  0.91090021  0.89413711],0.915826883027
weighted average recall scores = [ 0.87098983  0.90615482  0.93392551  0.93117979  0.92863173  0.93091319
  0.93577236  0.91566428  0.91090021  0.89413711],0.915826883027
weighted f1 scores = [ 0.86756373  0.90349413  0.93300984  0.93004705  0.92806019  0.92979942
  0.93410431  0.91450171  0.90989173  0.89184314],0.914231525736
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw  -->  precision  0.915237259781 recall  0.911031999756 f1  0.912020564469
loaded (57423) terms
extended to (73391) terms
done loading vocabulary
vectorizing done, 73391 terms vocabulary tokenized
vectorizing done, 73391 terms vocabulary tokenized
accuracy scores = [ 0.84717081  0.88506356  0.9204666   0.90981432  0.90759426  0.90536948
  0.91919192  0.90792975  0.88711395  0.86247335],0.89521880044
macro precision scores = [ 0.84862335  0.88751005  0.92207392  0.91062044  0.90841634  0.90506298
  0.91980931  0.90969169  0.88687172  0.86254459],0.896122438806
macro recall scores = [ 0.84019271  0.88133628  0.91790407  0.907832    0.90575694  0.90296693
  0.9142369   0.90653273  0.88278834  0.85829393],0.891784081541
macro f1 scores = [ 0.84112889  0.88284508  0.91935034  0.90878864  0.90644884  0.90344863
  0.91586075  0.90757428  0.88407226  0.85864337],0.89281610672
weighted average precision scores = [ 0.85010015  0.8875382   0.92116453  0.91097032  0.90781082  0.90547333
  0.92013467  0.90874073  0.88875966  0.86584646],0.896653886243
weighted average recall scores = [ 0.85010015  0.8875382   0.92116453  0.91097032  0.90781082  0.90547333
  0.92013467  0.90874073  0.88875966  0.86584646],0.896653886243
weighted f1 scores = [ 0.84593991  0.88499921  0.92029145  0.90996411  0.90715397  0.90489305
  0.9187015   0.90785786  0.88723526  0.86241465],0.89494509833
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_bigrams_vw (extended unigrams) -->  precision  0.896122438806 recall  0.891784081541 f1  0.89281610672
loaded (228162) terms
vectorizing done, 228162 terms vocabulary tokenized
vectorizing done, 228162 terms vocabulary tokenized
accuracy scores = [ 0.86885246  0.90307203  0.93266172  0.92838196  0.92724376  0.93088783
  0.93301435  0.91538052  0.90841321  0.89179104],0.913969888522
macro precision scores = [ 0.86995671  0.90551285  0.93432536  0.92944262  0.92825611  0.93068685
  0.9341319   0.91689763  0.90752513  0.89091121],0.914764636689
macro recall scores = [ 0.86127678  0.89913261  0.93021281  0.92590705  0.92533466  0.92838922
  0.927756    0.91356045  0.90428849  0.88831539],0.91041734597
macro f1 scores = [ 0.86155365  0.9005786   0.93164807  0.92719648  0.9263035   0.92889609
  0.92951647  0.9146318   0.9053169   0.88846802],0.911410957188
weighted average precision scores = [ 0.87028335  0.90568195  0.93339951  0.92933979  0.92768204  0.9319776
  0.93434973  0.91703481  0.90923978  0.89397058],0.915295915054
weighted average recall scores = [ 0.87028335  0.90568195  0.93339951  0.92933979  0.92768204  0.9319776
  0.93434973  0.91703481  0.90923978  0.89397058],0.915295915054
weighted f1 scores = [ 0.86655788  0.90294399  0.93250987  0.92843899  0.92707098  0.93085899
  0.93246918  0.91563453  0.90831234  0.89176865],0.913656540953
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw  -->  precision  0.914764636689 recall  0.91041734597 f1  0.911410957188
loaded (84833) terms
extended to (101486) terms
done loading vocabulary
vectorizing done, 101486 terms vocabulary tokenized
vectorizing done, 101486 terms vocabulary tokenized
accuracy scores = [ 0.85034373  0.88029661  0.92364793  0.91193634  0.90759426  0.90590112
  0.92078682  0.90686535  0.88817891  0.86407249],0.895962357404
macro precision scores = [ 0.8528504   0.88210289  0.92511328  0.91217596  0.9081816   0.90527066
  0.9209527   0.90863923  0.88764887  0.86345017],0.89663857647
macro recall scores = [ 0.84373636  0.87604741  0.92080323  0.90987312  0.90558655  0.9032438
  0.91553363  0.90549587  0.88375921  0.85993646],0.892401564812
macro f1 scores = [ 0.84474474  0.87751774  0.92227561  0.91067775  0.90626982  0.90352619
  0.91711714  0.90644147  0.8849284   0.86002871],0.893352758533
weighted average precision scores = [ 0.85330545  0.88273466  0.92440038  0.91285509  0.90772011  0.90657548
  0.92144333  0.90766151  0.88968414  0.86727471],0.897365485857
weighted average recall scores = [ 0.85330545  0.88273466  0.92440038  0.91285509  0.90772011  0.90657548
  0.92144333  0.90766151  0.88968414  0.86727471],0.897365485857
weighted f1 scores = [ 0.84896648  0.88023486  0.92344347  0.91205366  0.90713346  0.9055557
  0.92019396  0.90669458  0.88821879  0.86401982],0.895651477345
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_google_bigrams_vw (extended unigrams) -->  precision  0.89663857647 recall  0.892401564812 f1  0.893352758533
loaded (194359) terms
vectorizing done, 194359 terms vocabulary tokenized
vectorizing done, 194359 terms vocabulary tokenized
accuracy scores = [ 0.86567953  0.90095339  0.93160127  0.92679045  0.92458842  0.9271664
  0.93088783  0.91271953  0.90841321  0.88752665],0.911632668679
macro precision scores = [ 0.86629279  0.90291747  0.93293653  0.92827684  0.92528523  0.92627949
  0.93231784  0.91399812  0.9076877   0.88669739],0.912268940633
macro recall scores = [ 0.85884516  0.89677965  0.92907772  0.9243816   0.92275459  0.92470815
  0.9256108   0.91091767  0.90439266  0.88379825],0.908126624132
macro f1 scores = [ 0.85907626  0.89820057  0.93040645  0.92578279  0.92351643  0.9249129
  0.92744553  0.91186238  0.90543377  0.88399421],0.90906312986
weighted average precision scores = [ 0.86695638  0.90346741  0.93227417  0.92802272  0.92468665  0.92802024
  0.93249905  0.91446396  0.90940885  0.89001969],0.912981912544
weighted average recall scores = [ 0.86695638  0.90346741  0.93227417  0.92802272  0.92468665  0.92802024
  0.93249905  0.91446396  0.90940885  0.89001969],0.912981912544
weighted f1 scores = [ 0.86370343  0.90085363  0.93141783  0.92691589  0.924234    0.92704845
  0.93039207  0.91301088  0.90838022  0.8875502 ],0.911350661518
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw  -->  precision  0.912268940633 recall  0.908126624132 f1  0.90906312986
loaded (51030) terms
extended to (59828) terms
done loading vocabulary
vectorizing done, 59828 terms vocabulary tokenized
vectorizing done, 59828 terms vocabulary tokenized
accuracy scores = [ 0.82496034  0.85963983  0.90349947  0.88753316  0.8858205   0.88197767
  0.89952153  0.88344864  0.86368477  0.83848614],0.872857205164
macro precision scores = [ 0.82573499  0.86036366  0.90484283  0.88758851  0.8839827   0.881373
  0.89963965  0.88396969  0.86417906  0.83836415],0.873003824806
macro recall scores = [ 0.81836986  0.85415795  0.89974988  0.88570191  0.88377866  0.87890183
  0.89405517  0.88139184  0.86035073  0.83257206],0.868902987823
macro f1 scores = [ 0.81919954  0.85557255  0.90139186  0.8863425   0.88298479  0.87898825
  0.89548575  0.8820772   0.86146122  0.83317434],0.869667802639
weighted average precision scores = [ 0.82803924  0.86216825  0.90445335  0.88852407  0.88500008  0.88260026
  0.90077121  0.88445277  0.86533123  0.84354684],0.874488728975
weighted average recall scores = [ 0.82803924  0.86216825  0.90445335  0.88852407  0.88500008  0.88260026
  0.90077121  0.88445277  0.86533123  0.84354684],0.874488728975
weighted f1 scores = [ 0.82410322  0.85946744  0.90322842  0.88772211  0.88457118  0.88121684
  0.89895333  0.88337184  0.86374748  0.83876098],0.872514283199
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.873003824806 recall  0.868902987823 f1  0.869667802639
loaded (229029) terms
vectorizing done, 229029 terms vocabulary tokenized
vectorizing done, 229029 terms vocabulary tokenized
accuracy scores = [ 0.86885246  0.90413136  0.93319194  0.92891247  0.92724376  0.93035619
  0.93301435  0.91538052  0.90894569  0.89179104],0.914181978318
macro precision scores = [ 0.87014377  0.9064983   0.93482543  0.92997973  0.92828521  0.9301404
  0.9341319   0.91689763  0.90801606  0.89085314],0.914977157387
macro recall scores = [ 0.86127678  0.90029447  0.93072302  0.92641726  0.92534507  0.92787902
  0.927756    0.91356045  0.90479869  0.88831539],0.910636614025
macro f1 scores = [ 0.861648    0.90174137  0.93214909  0.9277068   0.92633828  0.92835853
  0.92951647  0.9146318   0.90580879  0.88842696],0.911632608511
weighted average precision scores = [ 0.87036026  0.90670963  0.93390989  0.92990282  0.92771066  0.9314082
  0.93434973  0.91703481  0.90975243  0.89403626],0.91551746936
weighted average recall scores = [ 0.87036026  0.90670963  0.93390989  0.92990282  0.92771066  0.9314082
  0.93434973  0.91703481  0.90975243  0.89403626],0.91551746936
weighted f1 scores = [ 0.86659683  0.90406034  0.93302572  0.92897191  0.92710101  0.93029886
  0.93246918  0.91563453  0.90882573  0.89178194],0.913876605443
ng20_raw_stems_unigrams_stopwords_df1_tf1 ^ ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw  -->  precision  0.914977157387 recall  0.910636614025 f1  0.911632608511
loaded (85700) terms
extended to (102466) terms
done loading vocabulary
vectorizing done, 102466 terms vocabulary tokenized
vectorizing done, 102466 terms vocabulary tokenized
accuracy scores = [ 0.84928609  0.88188559  0.92364793  0.91352785  0.90971853  0.90590112
  0.92238171  0.90739755  0.8887114   0.86407249],0.896653027302
macro precision scores = [ 0.85122777  0.88390238  0.92493272  0.9138215   0.91038567  0.90539508
  0.92277143  0.90925213  0.88877131  0.86366611],0.89741260918
macro recall scores = [ 0.8424325   0.8778721   0.92082406  0.91153979  0.90777626  0.90322254
  0.9171843   0.90601671  0.88459965  0.85994183],0.893140973708
macro f1 scores = [ 0.84323465  0.87932618  0.92223489  0.91233258  0.9084746   0.90352715
  0.91878029  0.90698786  0.88587943  0.86010828],0.894088591074
weighted average precision scores = [ 0.85218686  0.88431776  0.9243424   0.9142337   0.90984648  0.90667988
  0.92314863  0.90831416  0.89052149  0.86751263],0.898110399392
weighted average recall scores = [ 0.85218686  0.88431776  0.9243424   0.9142337   0.90984648  0.90667988
  0.92314863  0.90831416  0.89052149  0.86751263],0.898110399392
weighted f1 scores = [ 0.84779987  0.88180985  0.92345215  0.91354083  0.90926636  0.90555693
  0.92178175  0.90726586  0.88887467  0.864108  ],0.896345626543
ng20_raw_stems_bigrams_stopwords_df1_tf1 ^ wiki_wiktionary_google_bigrams_vw (extended unigrams) -->  precision  0.89741260918 recall  0.893140973708 f1  0.894088591074
done!

