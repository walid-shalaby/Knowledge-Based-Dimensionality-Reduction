{
 "metadata": {
  "name": "",
  "signature": "sha256:98ed8afc7d11fc08978f69f9bbcafc2c041008837c2c12fa3fa1850f5f81789e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tokenizer with Lemmatizer"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "A tokenizer that lemmatize tokenized documents text using nltk wordnet lemmatizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import RegexpTokenizer\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "class LemmaTokenizer(object):\n",
      "    pattern = u'(?u)\\b[a-z]+\\-*[a-z]+|\\b(?u)\\b[a-z]\\b'\n",
      "    def __init__(self):\n",
      "        self.tokenizer = RegexpTokenizer(pattern)\n",
      "        self.wnl = WordNetLemmatizer()\n",
      "    def __call__(self, doc):\n",
      "        return [self.wnl.lemmatize(t) for t in self.tokenizer.tokenize(doc)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}